{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15fdf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75d00a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stage_path = '/home/rliu/Desktop/cvfiler04/ruoshi/github/stable-diffusion/models/first_stage_models/kl-f8/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "959734d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ckpt = torch.load(first_stage_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80b2b284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_keys = []\n",
    "keys = copy.copy(list(first_ckpt['state_dict'].keys()))\n",
    "for key in keys:\n",
    "#     if key.startswith('first_sta|ge_model'):\n",
    "    newkey = 'first_stage_model.' + key\n",
    "    first_ckpt['state_dict'][newkey] = first_ckpt['state_dict'].pop(key)\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0cb3f2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['first_stage_model.first_stage_model.encoder.down.0.block.0.norm1.weight', 'first_stage_model.first_stage_model.encoder.down.0.block.0.norm1.bias', 'first_stage_model.first_stage_model.encoder.down.0.block.0.conv1.weight', 'first_stage_model.first_stage_model.encoder.down.0.block.0.conv1.bias', 'first_stage_model.first_stage_model.encoder.down.0.block.0.norm2.weight', 'first_stage_model.first_stage_model.encoder.down.0.block.0.norm2.bias', 'first_stage_model.first_stage_model.encoder.down.0.block.0.conv2.weight', 'first_stage_model.first_stage_model.encoder.down.0.block.0.conv2.bias', 'first_stage_model.first_stage_model.encoder.down.0.block.1.norm1.weight', 'first_stage_model.first_stage_model.encoder.down.0.block.1.norm1.bias', 'first_stage_model.first_stage_model.encoder.down.0.block.1.conv1.weight', 'first_stage_model.first_stage_model.encoder.down.0.block.1.conv1.bias', 'first_stage_model.first_stage_model.encoder.down.0.block.1.norm2.weight', 'first_stage_model.first_stage_model.encoder.down.0.block.1.norm2.bias', 'first_stage_model.first_stage_model.encoder.down.0.block.1.conv2.weight', 'first_stage_model.first_stage_model.encoder.down.0.block.1.conv2.bias', 'first_stage_model.first_stage_model.encoder.down.0.downsample.conv.weight', 'first_stage_model.first_stage_model.encoder.down.0.downsample.conv.bias', 'first_stage_model.first_stage_model.encoder.down.1.block.0.norm1.weight', 'first_stage_model.first_stage_model.encoder.down.1.block.0.norm1.bias', 'first_stage_model.first_stage_model.encoder.down.1.block.0.conv1.weight', 'first_stage_model.first_stage_model.encoder.down.1.block.0.conv1.bias', 'first_stage_model.first_stage_model.encoder.down.1.block.0.norm2.weight', 'first_stage_model.first_stage_model.encoder.down.1.block.0.norm2.bias', 'first_stage_model.first_stage_model.encoder.down.1.block.0.conv2.weight', 'first_stage_model.first_stage_model.encoder.down.1.block.0.conv2.bias', 'first_stage_model.first_stage_model.encoder.down.1.block.0.nin_shortcut.weight', 'first_stage_model.first_stage_model.encoder.down.1.block.0.nin_shortcut.bias', 'first_stage_model.first_stage_model.encoder.down.1.block.1.norm1.weight', 'first_stage_model.first_stage_model.encoder.down.1.block.1.norm1.bias', 'first_stage_model.first_stage_model.encoder.down.1.block.1.conv1.weight', 'first_stage_model.first_stage_model.encoder.down.1.block.1.conv1.bias', 'first_stage_model.first_stage_model.encoder.down.1.block.1.norm2.weight', 'first_stage_model.first_stage_model.encoder.down.1.block.1.norm2.bias', 'first_stage_model.first_stage_model.encoder.down.1.block.1.conv2.weight', 'first_stage_model.first_stage_model.encoder.down.1.block.1.conv2.bias', 'first_stage_model.first_stage_model.encoder.down.1.downsample.conv.weight', 'first_stage_model.first_stage_model.encoder.down.1.downsample.conv.bias', 'first_stage_model.first_stage_model.encoder.down.2.block.0.norm1.weight', 'first_stage_model.first_stage_model.encoder.down.2.block.0.norm1.bias', 'first_stage_model.first_stage_model.encoder.down.2.block.0.conv1.weight', 'first_stage_model.first_stage_model.encoder.down.2.block.0.conv1.bias', 'first_stage_model.first_stage_model.encoder.down.2.block.0.norm2.weight', 'first_stage_model.first_stage_model.encoder.down.2.block.0.norm2.bias', 'first_stage_model.first_stage_model.encoder.down.2.block.0.conv2.weight', 'first_stage_model.first_stage_model.encoder.down.2.block.0.conv2.bias', 'first_stage_model.first_stage_model.encoder.down.2.block.0.nin_shortcut.weight', 'first_stage_model.first_stage_model.encoder.down.2.block.0.nin_shortcut.bias', 'first_stage_model.first_stage_model.encoder.down.2.block.1.norm1.weight', 'first_stage_model.first_stage_model.encoder.down.2.block.1.norm1.bias', 'first_stage_model.first_stage_model.encoder.down.2.block.1.conv1.weight', 'first_stage_model.first_stage_model.encoder.down.2.block.1.conv1.bias', 'first_stage_model.first_stage_model.encoder.down.2.block.1.norm2.weight', 'first_stage_model.first_stage_model.encoder.down.2.block.1.norm2.bias', 'first_stage_model.first_stage_model.encoder.down.2.block.1.conv2.weight', 'first_stage_model.first_stage_model.encoder.down.2.block.1.conv2.bias', 'first_stage_model.first_stage_model.encoder.down.2.downsample.conv.weight', 'first_stage_model.first_stage_model.encoder.down.2.downsample.conv.bias', 'first_stage_model.first_stage_model.encoder.down.3.block.0.norm1.weight', 'first_stage_model.first_stage_model.encoder.down.3.block.0.norm1.bias', 'first_stage_model.first_stage_model.encoder.down.3.block.0.conv1.weight', 'first_stage_model.first_stage_model.encoder.down.3.block.0.conv1.bias', 'first_stage_model.first_stage_model.encoder.down.3.block.0.norm2.weight', 'first_stage_model.first_stage_model.encoder.down.3.block.0.norm2.bias', 'first_stage_model.first_stage_model.encoder.down.3.block.0.conv2.weight', 'first_stage_model.first_stage_model.encoder.down.3.block.0.conv2.bias', 'first_stage_model.first_stage_model.encoder.down.3.block.1.norm1.weight', 'first_stage_model.first_stage_model.encoder.down.3.block.1.norm1.bias', 'first_stage_model.first_stage_model.encoder.down.3.block.1.conv1.weight', 'first_stage_model.first_stage_model.encoder.down.3.block.1.conv1.bias', 'first_stage_model.first_stage_model.encoder.down.3.block.1.norm2.weight', 'first_stage_model.first_stage_model.encoder.down.3.block.1.norm2.bias', 'first_stage_model.first_stage_model.encoder.down.3.block.1.conv2.weight', 'first_stage_model.first_stage_model.encoder.down.3.block.1.conv2.bias', 'first_stage_model.first_stage_model.encoder.mid.block_1.norm1.weight', 'first_stage_model.first_stage_model.encoder.mid.block_1.norm1.bias', 'first_stage_model.first_stage_model.encoder.mid.block_1.conv1.weight', 'first_stage_model.first_stage_model.encoder.mid.block_1.conv1.bias', 'first_stage_model.first_stage_model.encoder.mid.block_1.norm2.weight', 'first_stage_model.first_stage_model.encoder.mid.block_1.norm2.bias', 'first_stage_model.first_stage_model.encoder.mid.block_1.conv2.weight', 'first_stage_model.first_stage_model.encoder.mid.block_1.conv2.bias', 'first_stage_model.first_stage_model.encoder.mid.attn_1.norm.weight', 'first_stage_model.first_stage_model.encoder.mid.attn_1.norm.bias', 'first_stage_model.first_stage_model.encoder.mid.attn_1.q.weight', 'first_stage_model.first_stage_model.encoder.mid.attn_1.q.bias', 'first_stage_model.first_stage_model.encoder.mid.attn_1.k.weight', 'first_stage_model.first_stage_model.encoder.mid.attn_1.k.bias', 'first_stage_model.first_stage_model.encoder.mid.attn_1.v.weight', 'first_stage_model.first_stage_model.encoder.mid.attn_1.v.bias', 'first_stage_model.first_stage_model.encoder.mid.attn_1.proj_out.weight', 'first_stage_model.first_stage_model.encoder.mid.attn_1.proj_out.bias', 'first_stage_model.first_stage_model.encoder.mid.block_2.norm1.weight', 'first_stage_model.first_stage_model.encoder.mid.block_2.norm1.bias', 'first_stage_model.first_stage_model.encoder.mid.block_2.conv1.weight', 'first_stage_model.first_stage_model.encoder.mid.block_2.conv1.bias', 'first_stage_model.first_stage_model.encoder.mid.block_2.norm2.weight', 'first_stage_model.first_stage_model.encoder.mid.block_2.norm2.bias', 'first_stage_model.first_stage_model.encoder.mid.block_2.conv2.weight', 'first_stage_model.first_stage_model.encoder.mid.block_2.conv2.bias', 'first_stage_model.first_stage_model.encoder.norm_out.weight', 'first_stage_model.first_stage_model.encoder.norm_out.bias', 'first_stage_model.first_stage_model.encoder.conv_out.weight', 'first_stage_model.first_stage_model.encoder.conv_out.bias', 'first_stage_model.first_stage_model.decoder.conv_in.weight', 'first_stage_model.first_stage_model.decoder.conv_in.bias', 'first_stage_model.first_stage_model.decoder.mid.block_1.norm1.weight', 'first_stage_model.first_stage_model.decoder.mid.block_1.norm1.bias', 'first_stage_model.first_stage_model.decoder.mid.block_1.conv1.weight', 'first_stage_model.first_stage_model.decoder.mid.block_1.conv1.bias', 'first_stage_model.first_stage_model.decoder.mid.block_1.norm2.weight', 'first_stage_model.first_stage_model.decoder.mid.block_1.norm2.bias', 'first_stage_model.first_stage_model.decoder.mid.block_1.conv2.weight', 'first_stage_model.first_stage_model.decoder.mid.block_1.conv2.bias', 'first_stage_model.first_stage_model.decoder.mid.attn_1.norm.weight', 'first_stage_model.first_stage_model.decoder.mid.attn_1.norm.bias', 'first_stage_model.first_stage_model.decoder.mid.attn_1.q.weight', 'first_stage_model.first_stage_model.decoder.mid.attn_1.q.bias', 'first_stage_model.first_stage_model.decoder.mid.attn_1.k.weight', 'first_stage_model.first_stage_model.decoder.mid.attn_1.k.bias', 'first_stage_model.first_stage_model.decoder.mid.attn_1.v.weight', 'first_stage_model.first_stage_model.decoder.mid.attn_1.v.bias', 'first_stage_model.first_stage_model.decoder.mid.attn_1.proj_out.weight', 'first_stage_model.first_stage_model.decoder.mid.attn_1.proj_out.bias', 'first_stage_model.first_stage_model.decoder.mid.block_2.norm1.weight', 'first_stage_model.first_stage_model.decoder.mid.block_2.norm1.bias', 'first_stage_model.first_stage_model.decoder.mid.block_2.conv1.weight', 'first_stage_model.first_stage_model.decoder.mid.block_2.conv1.bias', 'first_stage_model.first_stage_model.decoder.mid.block_2.norm2.weight', 'first_stage_model.first_stage_model.decoder.mid.block_2.norm2.bias', 'first_stage_model.first_stage_model.decoder.mid.block_2.conv2.weight', 'first_stage_model.first_stage_model.decoder.mid.block_2.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.0.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.0.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.0.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.0.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.0.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.0.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.0.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.0.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.0.nin_shortcut.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.0.nin_shortcut.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.1.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.1.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.1.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.1.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.1.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.1.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.1.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.1.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.2.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.2.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.2.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.2.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.2.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.2.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.0.block.2.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.0.block.2.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.0.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.0.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.0.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.0.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.0.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.0.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.0.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.0.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.0.nin_shortcut.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.0.nin_shortcut.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.1.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.1.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.1.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.1.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.1.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.1.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.1.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.1.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.2.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.2.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.2.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.2.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.2.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.2.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.1.block.2.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.1.block.2.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.1.upsample.conv.weight', 'first_stage_model.first_stage_model.decoder.up.1.upsample.conv.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.0.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.0.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.0.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.0.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.0.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.0.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.0.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.0.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.1.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.1.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.1.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.1.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.1.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.1.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.1.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.1.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.2.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.2.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.2.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.2.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.2.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.2.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.2.block.2.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.2.block.2.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.2.upsample.conv.weight', 'first_stage_model.first_stage_model.decoder.up.2.upsample.conv.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.0.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.0.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.0.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.0.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.0.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.0.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.0.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.0.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.1.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.1.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.1.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.1.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.1.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.1.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.1.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.1.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.2.norm1.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.2.norm1.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.2.conv1.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.2.conv1.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.2.norm2.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.2.norm2.bias', 'first_stage_model.first_stage_model.decoder.up.3.block.2.conv2.weight', 'first_stage_model.first_stage_model.decoder.up.3.block.2.conv2.bias', 'first_stage_model.first_stage_model.decoder.up.3.upsample.conv.weight', 'first_stage_model.first_stage_model.decoder.up.3.upsample.conv.bias', 'first_stage_model.first_stage_model.decoder.norm_out.weight', 'first_stage_model.first_stage_model.decoder.norm_out.bias', 'first_stage_model.first_stage_model.decoder.conv_out.weight', 'first_stage_model.first_stage_model.decoder.conv_out.bias', 'first_stage_model.first_stage_model.loss.logvar', 'first_stage_model.first_stage_model.loss.perceptual_loss.scaling_layer.shift', 'first_stage_model.first_stage_model.loss.perceptual_loss.scaling_layer.scale', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice1.0.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice1.0.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice1.2.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice1.2.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice2.5.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice2.5.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice2.7.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice2.7.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice3.10.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice3.10.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice3.12.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice3.12.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice3.14.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice3.14.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice4.17.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice4.17.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice4.19.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice4.19.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice4.21.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice4.21.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice5.24.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice5.24.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice5.26.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice5.26.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice5.28.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.net.slice5.28.bias', 'first_stage_model.first_stage_model.loss.perceptual_loss.lin0.model.1.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.lin1.model.1.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.lin2.model.1.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.lin3.model.1.weight', 'first_stage_model.first_stage_model.loss.perceptual_loss.lin4.model.1.weight', 'first_stage_model.first_stage_model.loss.discriminator.main.0.weight', 'first_stage_model.first_stage_model.loss.discriminator.main.0.bias', 'first_stage_model.first_stage_model.loss.discriminator.main.2.weight', 'first_stage_model.first_stage_model.loss.discriminator.main.3.weight', 'first_stage_model.first_stage_model.loss.discriminator.main.3.bias', 'first_stage_model.first_stage_model.loss.discriminator.main.3.running_mean', 'first_stage_model.first_stage_model.loss.discriminator.main.3.running_var', 'first_stage_model.first_stage_model.loss.discriminator.main.3.num_batches_tracked', 'first_stage_model.first_stage_model.loss.discriminator.main.5.weight', 'first_stage_model.first_stage_model.loss.discriminator.main.6.weight', 'first_stage_model.first_stage_model.loss.discriminator.main.6.bias', 'first_stage_model.first_stage_model.loss.discriminator.main.6.running_mean', 'first_stage_model.first_stage_model.loss.discriminator.main.6.running_var', 'first_stage_model.first_stage_model.loss.discriminator.main.6.num_batches_tracked', 'first_stage_model.first_stage_model.loss.discriminator.main.8.weight', 'first_stage_model.first_stage_model.loss.discriminator.main.9.weight', 'first_stage_model.first_stage_model.loss.discriminator.main.9.bias', 'first_stage_model.first_stage_model.loss.discriminator.main.9.running_mean', 'first_stage_model.first_stage_model.loss.discriminator.main.9.running_var', 'first_stage_model.first_stage_model.loss.discriminator.main.9.num_batches_tracked', 'first_stage_model.first_stage_model.loss.discriminator.main.11.weight', 'first_stage_model.first_stage_model.loss.discriminator.main.11.bias', 'first_stage_model.first_stage_model.quant_conv.weight', 'first_stage_model.first_stage_model.quant_conv.bias', 'first_stage_model.first_stage_model.post_quant_conv.weight', 'first_stage_model.first_stage_model.post_quant_conv.bias', 'first_stage_model.first_stage_model.first_stage_model.encoder.conv_in.weight', 'first_stage_model.first_stage_model.first_stage_model.encoder.conv_in.bias'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_ckpt['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2355364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = '/home/rliu/Desktop/cvfiler04/ruoshi/github/stable-diffusion/logs/2023-02-20T19-13-12_sd-objaverse-finetune-c_concat/checkpoints/last.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43d78dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_v1 = torch.load(ckpt_path, map_location='cpu')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c14e55ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas torch.Size([1000])\n",
      "alphas_cumprod torch.Size([1000])\n",
      "alphas_cumprod_prev torch.Size([1000])\n",
      "sqrt_alphas_cumprod torch.Size([1000])\n",
      "sqrt_one_minus_alphas_cumprod torch.Size([1000])\n",
      "log_one_minus_alphas_cumprod torch.Size([1000])\n",
      "sqrt_recip_alphas_cumprod torch.Size([1000])\n",
      "sqrt_recipm1_alphas_cumprod torch.Size([1000])\n",
      "posterior_variance torch.Size([1000])\n",
      "posterior_log_variance_clipped torch.Size([1000])\n",
      "posterior_mean_coef1 torch.Size([1000])\n",
      "posterior_mean_coef2 torch.Size([1000])\n",
      "model.diffusion_model.time_embed.0.weight torch.Size([1280, 320])\n",
      "model.diffusion_model.time_embed.0.bias torch.Size([1280])\n",
      "model.diffusion_model.time_embed.2.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.time_embed.2.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.0.0.weight torch.Size([320, 8, 3, 3])\n",
      "model.diffusion_model.input_blocks.0.0.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.0.in_layers.0.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.0.in_layers.0.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.0.in_layers.2.weight torch.Size([320, 320, 3, 3])\n",
      "model.diffusion_model.input_blocks.1.0.in_layers.2.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.0.emb_layers.1.weight torch.Size([320, 1280])\n",
      "model.diffusion_model.input_blocks.1.0.emb_layers.1.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.0.out_layers.0.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.0.out_layers.0.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.0.out_layers.3.weight torch.Size([320, 320, 3, 3])\n",
      "model.diffusion_model.input_blocks.1.0.out_layers.3.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.norm.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.norm.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.proj_in.weight torch.Size([320, 320, 1, 1])\n",
      "model.diffusion_model.input_blocks.1.1.proj_in.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([2560, 320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([2560])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight torch.Size([320, 1280])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight torch.Size([320, 768])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight torch.Size([320, 768])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.1.1.proj_out.weight torch.Size([320, 320, 1, 1])\n",
      "model.diffusion_model.input_blocks.1.1.proj_out.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.0.in_layers.0.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.0.in_layers.0.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.0.in_layers.2.weight torch.Size([320, 320, 3, 3])\n",
      "model.diffusion_model.input_blocks.2.0.in_layers.2.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.0.emb_layers.1.weight torch.Size([320, 1280])\n",
      "model.diffusion_model.input_blocks.2.0.emb_layers.1.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.0.out_layers.0.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.0.out_layers.0.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.0.out_layers.3.weight torch.Size([320, 320, 3, 3])\n",
      "model.diffusion_model.input_blocks.2.0.out_layers.3.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.norm.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.norm.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.proj_in.weight torch.Size([320, 320, 1, 1])\n",
      "model.diffusion_model.input_blocks.2.1.proj_in.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([2560, 320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([2560])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight torch.Size([320, 1280])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight torch.Size([320, 768])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight torch.Size([320, 768])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([320, 320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.2.1.proj_out.weight torch.Size([320, 320, 1, 1])\n",
      "model.diffusion_model.input_blocks.2.1.proj_out.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.3.0.op.weight torch.Size([320, 320, 3, 3])\n",
      "model.diffusion_model.input_blocks.3.0.op.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.4.0.in_layers.0.weight torch.Size([320])\n",
      "model.diffusion_model.input_blocks.4.0.in_layers.0.bias torch.Size([320])\n",
      "model.diffusion_model.input_blocks.4.0.in_layers.2.weight torch.Size([640, 320, 3, 3])\n",
      "model.diffusion_model.input_blocks.4.0.in_layers.2.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.0.emb_layers.1.weight torch.Size([640, 1280])\n",
      "model.diffusion_model.input_blocks.4.0.emb_layers.1.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.0.out_layers.0.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.0.out_layers.0.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.0.out_layers.3.weight torch.Size([640, 640, 3, 3])\n",
      "model.diffusion_model.input_blocks.4.0.out_layers.3.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.0.skip_connection.weight torch.Size([640, 320, 1, 1])\n",
      "model.diffusion_model.input_blocks.4.0.skip_connection.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.norm.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.norm.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.proj_in.weight torch.Size([640, 640, 1, 1])\n",
      "model.diffusion_model.input_blocks.4.1.proj_in.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([5120, 640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([5120])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight torch.Size([640, 2560])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight torch.Size([640, 768])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight torch.Size([640, 768])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.4.1.proj_out.weight torch.Size([640, 640, 1, 1])\n",
      "model.diffusion_model.input_blocks.4.1.proj_out.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.0.in_layers.0.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.0.in_layers.0.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.0.in_layers.2.weight torch.Size([640, 640, 3, 3])\n",
      "model.diffusion_model.input_blocks.5.0.in_layers.2.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.0.emb_layers.1.weight torch.Size([640, 1280])\n",
      "model.diffusion_model.input_blocks.5.0.emb_layers.1.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.0.out_layers.0.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.0.out_layers.0.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.0.out_layers.3.weight torch.Size([640, 640, 3, 3])\n",
      "model.diffusion_model.input_blocks.5.0.out_layers.3.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.norm.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.norm.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.proj_in.weight torch.Size([640, 640, 1, 1])\n",
      "model.diffusion_model.input_blocks.5.1.proj_in.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([5120, 640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([5120])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight torch.Size([640, 2560])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight torch.Size([640, 768])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight torch.Size([640, 768])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([640, 640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.5.1.proj_out.weight torch.Size([640, 640, 1, 1])\n",
      "model.diffusion_model.input_blocks.5.1.proj_out.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.6.0.op.weight torch.Size([640, 640, 3, 3])\n",
      "model.diffusion_model.input_blocks.6.0.op.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.7.0.in_layers.0.weight torch.Size([640])\n",
      "model.diffusion_model.input_blocks.7.0.in_layers.0.bias torch.Size([640])\n",
      "model.diffusion_model.input_blocks.7.0.in_layers.2.weight torch.Size([1280, 640, 3, 3])\n",
      "model.diffusion_model.input_blocks.7.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.7.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.input_blocks.7.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.0.skip_connection.weight torch.Size([1280, 640, 1, 1])\n",
      "model.diffusion_model.input_blocks.7.0.skip_connection.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.norm.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.norm.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.proj_in.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.input_blocks.7.1.proj_in.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([10240, 1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([10240])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight torch.Size([1280, 5120])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.7.1.proj_out.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.input_blocks.7.1.proj_out.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.0.in_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.0.in_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.0.in_layers.2.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.input_blocks.8.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.8.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.input_blocks.8.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.norm.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.norm.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.proj_in.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.input_blocks.8.1.proj_in.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([10240, 1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([10240])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight torch.Size([1280, 5120])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.8.1.proj_out.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.input_blocks.8.1.proj_out.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.9.0.op.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.input_blocks.9.0.op.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.10.0.in_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.10.0.in_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.10.0.in_layers.2.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.input_blocks.10.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.10.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.10.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.10.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.10.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.10.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.input_blocks.10.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.11.0.in_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.11.0.in_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.11.0.in_layers.2.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.input_blocks.11.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.11.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.input_blocks.11.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.11.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.11.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.input_blocks.11.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.input_blocks.11.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.0.in_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.middle_block.0.in_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.0.in_layers.2.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.middle_block.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.middle_block.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.middle_block.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.middle_block.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.norm.weight torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.norm.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.proj_in.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.middle_block.1.proj_in.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([10240, 1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([10240])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight torch.Size([1280, 5120])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.1.proj_out.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.middle_block.1.proj_out.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.2.in_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.middle_block.2.in_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.2.in_layers.2.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.middle_block.2.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.2.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.middle_block.2.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.2.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.middle_block.2.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.middle_block.2.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.middle_block.2.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.0.0.in_layers.0.weight torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.0.0.in_layers.0.bias torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.0.0.in_layers.2.weight torch.Size([1280, 2560, 3, 3])\n",
      "model.diffusion_model.output_blocks.0.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.0.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.0.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.0.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.0.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.0.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.output_blocks.0.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.0.0.skip_connection.weight torch.Size([1280, 2560, 1, 1])\n",
      "model.diffusion_model.output_blocks.0.0.skip_connection.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.1.0.in_layers.0.weight torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.1.0.in_layers.0.bias torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.1.0.in_layers.2.weight torch.Size([1280, 2560, 3, 3])\n",
      "model.diffusion_model.output_blocks.1.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.1.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.1.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.1.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.1.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.1.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.output_blocks.1.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.1.0.skip_connection.weight torch.Size([1280, 2560, 1, 1])\n",
      "model.diffusion_model.output_blocks.1.0.skip_connection.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.2.0.in_layers.0.weight torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.2.0.in_layers.0.bias torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.2.0.in_layers.2.weight torch.Size([1280, 2560, 3, 3])\n",
      "model.diffusion_model.output_blocks.2.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.2.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.2.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.2.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.2.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.2.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.output_blocks.2.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.2.0.skip_connection.weight torch.Size([1280, 2560, 1, 1])\n",
      "model.diffusion_model.output_blocks.2.0.skip_connection.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.2.1.conv.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.output_blocks.2.1.conv.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.0.in_layers.0.weight torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.3.0.in_layers.0.bias torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.3.0.in_layers.2.weight torch.Size([1280, 2560, 3, 3])\n",
      "model.diffusion_model.output_blocks.3.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.3.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.output_blocks.3.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.0.skip_connection.weight torch.Size([1280, 2560, 1, 1])\n",
      "model.diffusion_model.output_blocks.3.0.skip_connection.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.norm.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.norm.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.proj_in.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.output_blocks.3.1.proj_in.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([10240, 1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([10240])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight torch.Size([1280, 5120])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.3.1.proj_out.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.output_blocks.3.1.proj_out.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.0.in_layers.0.weight torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.4.0.in_layers.0.bias torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.4.0.in_layers.2.weight torch.Size([1280, 2560, 3, 3])\n",
      "model.diffusion_model.output_blocks.4.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.4.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.output_blocks.4.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.0.skip_connection.weight torch.Size([1280, 2560, 1, 1])\n",
      "model.diffusion_model.output_blocks.4.0.skip_connection.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.norm.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.norm.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.proj_in.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.output_blocks.4.1.proj_in.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([10240, 1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([10240])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight torch.Size([1280, 5120])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.4.1.proj_out.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.output_blocks.4.1.proj_out.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.0.in_layers.0.weight torch.Size([1920])\n",
      "model.diffusion_model.output_blocks.5.0.in_layers.0.bias torch.Size([1920])\n",
      "model.diffusion_model.output_blocks.5.0.in_layers.2.weight torch.Size([1280, 1920, 3, 3])\n",
      "model.diffusion_model.output_blocks.5.0.in_layers.2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.0.emb_layers.1.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.5.0.emb_layers.1.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.0.out_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.0.out_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.0.out_layers.3.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.output_blocks.5.0.out_layers.3.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.0.skip_connection.weight torch.Size([1280, 1920, 1, 1])\n",
      "model.diffusion_model.output_blocks.5.0.skip_connection.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.norm.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.norm.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.proj_in.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.output_blocks.5.1.proj_in.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([10240, 1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([10240])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight torch.Size([1280, 5120])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight torch.Size([1280, 768])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([1280, 1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.1.proj_out.weight torch.Size([1280, 1280, 1, 1])\n",
      "model.diffusion_model.output_blocks.5.1.proj_out.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.5.2.conv.weight torch.Size([1280, 1280, 3, 3])\n",
      "model.diffusion_model.output_blocks.5.2.conv.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.6.0.in_layers.0.weight torch.Size([1920])\n",
      "model.diffusion_model.output_blocks.6.0.in_layers.0.bias torch.Size([1920])\n",
      "model.diffusion_model.output_blocks.6.0.in_layers.2.weight torch.Size([640, 1920, 3, 3])\n",
      "model.diffusion_model.output_blocks.6.0.in_layers.2.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.0.emb_layers.1.weight torch.Size([640, 1280])\n",
      "model.diffusion_model.output_blocks.6.0.emb_layers.1.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.0.out_layers.0.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.0.out_layers.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.0.out_layers.3.weight torch.Size([640, 640, 3, 3])\n",
      "model.diffusion_model.output_blocks.6.0.out_layers.3.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.0.skip_connection.weight torch.Size([640, 1920, 1, 1])\n",
      "model.diffusion_model.output_blocks.6.0.skip_connection.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.norm.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.norm.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.proj_in.weight torch.Size([640, 640, 1, 1])\n",
      "model.diffusion_model.output_blocks.6.1.proj_in.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([5120, 640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([5120])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight torch.Size([640, 2560])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight torch.Size([640, 768])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight torch.Size([640, 768])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.6.1.proj_out.weight torch.Size([640, 640, 1, 1])\n",
      "model.diffusion_model.output_blocks.6.1.proj_out.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.0.in_layers.0.weight torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.7.0.in_layers.0.bias torch.Size([1280])\n",
      "model.diffusion_model.output_blocks.7.0.in_layers.2.weight torch.Size([640, 1280, 3, 3])\n",
      "model.diffusion_model.output_blocks.7.0.in_layers.2.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.0.emb_layers.1.weight torch.Size([640, 1280])\n",
      "model.diffusion_model.output_blocks.7.0.emb_layers.1.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.0.out_layers.0.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.0.out_layers.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.0.out_layers.3.weight torch.Size([640, 640, 3, 3])\n",
      "model.diffusion_model.output_blocks.7.0.out_layers.3.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.0.skip_connection.weight torch.Size([640, 1280, 1, 1])\n",
      "model.diffusion_model.output_blocks.7.0.skip_connection.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.norm.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.norm.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.proj_in.weight torch.Size([640, 640, 1, 1])\n",
      "model.diffusion_model.output_blocks.7.1.proj_in.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([5120, 640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([5120])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight torch.Size([640, 2560])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight torch.Size([640, 768])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight torch.Size([640, 768])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.7.1.proj_out.weight torch.Size([640, 640, 1, 1])\n",
      "model.diffusion_model.output_blocks.7.1.proj_out.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.0.in_layers.0.weight torch.Size([960])\n",
      "model.diffusion_model.output_blocks.8.0.in_layers.0.bias torch.Size([960])\n",
      "model.diffusion_model.output_blocks.8.0.in_layers.2.weight torch.Size([640, 960, 3, 3])\n",
      "model.diffusion_model.output_blocks.8.0.in_layers.2.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.0.emb_layers.1.weight torch.Size([640, 1280])\n",
      "model.diffusion_model.output_blocks.8.0.emb_layers.1.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.0.out_layers.0.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.0.out_layers.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.0.out_layers.3.weight torch.Size([640, 640, 3, 3])\n",
      "model.diffusion_model.output_blocks.8.0.out_layers.3.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.0.skip_connection.weight torch.Size([640, 960, 1, 1])\n",
      "model.diffusion_model.output_blocks.8.0.skip_connection.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.norm.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.norm.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.proj_in.weight torch.Size([640, 640, 1, 1])\n",
      "model.diffusion_model.output_blocks.8.1.proj_in.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([5120, 640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([5120])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight torch.Size([640, 2560])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight torch.Size([640, 768])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight torch.Size([640, 768])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([640, 640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.1.proj_out.weight torch.Size([640, 640, 1, 1])\n",
      "model.diffusion_model.output_blocks.8.1.proj_out.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.8.2.conv.weight torch.Size([640, 640, 3, 3])\n",
      "model.diffusion_model.output_blocks.8.2.conv.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.9.0.in_layers.0.weight torch.Size([960])\n",
      "model.diffusion_model.output_blocks.9.0.in_layers.0.bias torch.Size([960])\n",
      "model.diffusion_model.output_blocks.9.0.in_layers.2.weight torch.Size([320, 960, 3, 3])\n",
      "model.diffusion_model.output_blocks.9.0.in_layers.2.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.0.emb_layers.1.weight torch.Size([320, 1280])\n",
      "model.diffusion_model.output_blocks.9.0.emb_layers.1.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.0.out_layers.0.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.0.out_layers.0.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.0.out_layers.3.weight torch.Size([320, 320, 3, 3])\n",
      "model.diffusion_model.output_blocks.9.0.out_layers.3.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.0.skip_connection.weight torch.Size([320, 960, 1, 1])\n",
      "model.diffusion_model.output_blocks.9.0.skip_connection.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.norm.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.norm.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.proj_in.weight torch.Size([320, 320, 1, 1])\n",
      "model.diffusion_model.output_blocks.9.1.proj_in.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([2560, 320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight torch.Size([320, 1280])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight torch.Size([320, 768])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight torch.Size([320, 768])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.9.1.proj_out.weight torch.Size([320, 320, 1, 1])\n",
      "model.diffusion_model.output_blocks.9.1.proj_out.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.0.in_layers.0.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.10.0.in_layers.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.10.0.in_layers.2.weight torch.Size([320, 640, 3, 3])\n",
      "model.diffusion_model.output_blocks.10.0.in_layers.2.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.0.emb_layers.1.weight torch.Size([320, 1280])\n",
      "model.diffusion_model.output_blocks.10.0.emb_layers.1.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.0.out_layers.0.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.0.out_layers.0.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.0.out_layers.3.weight torch.Size([320, 320, 3, 3])\n",
      "model.diffusion_model.output_blocks.10.0.out_layers.3.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.0.skip_connection.weight torch.Size([320, 640, 1, 1])\n",
      "model.diffusion_model.output_blocks.10.0.skip_connection.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.norm.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.norm.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.proj_in.weight torch.Size([320, 320, 1, 1])\n",
      "model.diffusion_model.output_blocks.10.1.proj_in.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([2560, 320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight torch.Size([320, 1280])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight torch.Size([320, 768])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight torch.Size([320, 768])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.10.1.proj_out.weight torch.Size([320, 320, 1, 1])\n",
      "model.diffusion_model.output_blocks.10.1.proj_out.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.0.in_layers.0.weight torch.Size([640])\n",
      "model.diffusion_model.output_blocks.11.0.in_layers.0.bias torch.Size([640])\n",
      "model.diffusion_model.output_blocks.11.0.in_layers.2.weight torch.Size([320, 640, 3, 3])\n",
      "model.diffusion_model.output_blocks.11.0.in_layers.2.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.0.emb_layers.1.weight torch.Size([320, 1280])\n",
      "model.diffusion_model.output_blocks.11.0.emb_layers.1.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.0.out_layers.0.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.0.out_layers.0.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.0.out_layers.3.weight torch.Size([320, 320, 3, 3])\n",
      "model.diffusion_model.output_blocks.11.0.out_layers.3.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.0.skip_connection.weight torch.Size([320, 640, 1, 1])\n",
      "model.diffusion_model.output_blocks.11.0.skip_connection.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.norm.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.norm.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.proj_in.weight torch.Size([320, 320, 1, 1])\n",
      "model.diffusion_model.output_blocks.11.1.proj_in.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight torch.Size([2560, 320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias torch.Size([2560])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight torch.Size([320, 1280])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight torch.Size([320, 768])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight torch.Size([320, 768])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight torch.Size([320, 320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias torch.Size([320])\n",
      "model.diffusion_model.output_blocks.11.1.proj_out.weight torch.Size([320, 320, 1, 1])\n",
      "model.diffusion_model.output_blocks.11.1.proj_out.bias torch.Size([320])\n",
      "model.diffusion_model.out.0.weight torch.Size([320])\n",
      "model.diffusion_model.out.0.bias torch.Size([320])\n",
      "model.diffusion_model.out.2.weight torch.Size([4, 320, 3, 3])\n",
      "model.diffusion_model.out.2.bias torch.Size([4])\n",
      "model_ema.decay torch.Size([])\n",
      "model_ema.num_updates torch.Size([])\n",
      "model_ema.diffusion_modeltime_embed0weight torch.Size([1280, 320])\n",
      "model_ema.diffusion_modeltime_embed0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeltime_embed2weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeltime_embed2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks00weight torch.Size([320, 8, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks00bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks10in_layers0weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks10in_layers0bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks10in_layers2weight torch.Size([320, 320, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks10in_layers2bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks10emb_layers1weight torch.Size([320, 1280])\n",
      "model_ema.diffusion_modelinput_blocks10emb_layers1bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks10out_layers0weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks10out_layers0bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks10out_layers3weight torch.Size([320, 320, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks10out_layers3bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11normweight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11normbias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11proj_inweight torch.Size([320, 320, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks11proj_inbias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_qweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_kweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_vweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0weight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projweight torch.Size([2560, 320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projbias torch.Size([2560])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2weight torch.Size([320, 1280])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_qweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_kweight torch.Size([320, 768])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_vweight torch.Size([320, 768])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0weight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks11proj_outweight torch.Size([320, 320, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks11proj_outbias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks20in_layers0weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks20in_layers0bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks20in_layers2weight torch.Size([320, 320, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks20in_layers2bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks20emb_layers1weight torch.Size([320, 1280])\n",
      "model_ema.diffusion_modelinput_blocks20emb_layers1bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks20out_layers0weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks20out_layers0bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks20out_layers3weight torch.Size([320, 320, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks20out_layers3bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21normweight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21normbias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21proj_inweight torch.Size([320, 320, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks21proj_inbias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_qweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_kweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_vweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0weight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projweight torch.Size([2560, 320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projbias torch.Size([2560])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2weight torch.Size([320, 1280])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_qweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_kweight torch.Size([320, 768])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_vweight torch.Size([320, 768])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0weight torch.Size([320, 320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks21proj_outweight torch.Size([320, 320, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks21proj_outbias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks30opweight torch.Size([320, 320, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks30opbias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks40in_layers0weight torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks40in_layers0bias torch.Size([320])\n",
      "model_ema.diffusion_modelinput_blocks40in_layers2weight torch.Size([640, 320, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks40in_layers2bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks40emb_layers1weight torch.Size([640, 1280])\n",
      "model_ema.diffusion_modelinput_blocks40emb_layers1bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks40out_layers0weight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks40out_layers0bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks40out_layers3weight torch.Size([640, 640, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks40out_layers3bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks40skip_connectionweight torch.Size([640, 320, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks40skip_connectionbias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41normweight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41normbias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41proj_inweight torch.Size([640, 640, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks41proj_inbias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_qweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_kweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_vweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0weight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projweight torch.Size([5120, 640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projbias torch.Size([5120])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2weight torch.Size([640, 2560])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_qweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_kweight torch.Size([640, 768])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_vweight torch.Size([640, 768])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0weight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1weight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2weight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3weight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks41proj_outweight torch.Size([640, 640, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks41proj_outbias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks50in_layers0weight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks50in_layers0bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks50in_layers2weight torch.Size([640, 640, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks50in_layers2bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks50emb_layers1weight torch.Size([640, 1280])\n",
      "model_ema.diffusion_modelinput_blocks50emb_layers1bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks50out_layers0weight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks50out_layers0bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks50out_layers3weight torch.Size([640, 640, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks50out_layers3bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51normweight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51normbias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51proj_inweight torch.Size([640, 640, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks51proj_inbias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_qweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_kweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_vweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0weight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projweight torch.Size([5120, 640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projbias torch.Size([5120])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2weight torch.Size([640, 2560])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_qweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_kweight torch.Size([640, 768])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_vweight torch.Size([640, 768])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0weight torch.Size([640, 640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1weight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2weight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3weight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks51proj_outweight torch.Size([640, 640, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks51proj_outbias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks60opweight torch.Size([640, 640, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks60opbias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks70in_layers0weight torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks70in_layers0bias torch.Size([640])\n",
      "model_ema.diffusion_modelinput_blocks70in_layers2weight torch.Size([1280, 640, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks70in_layers2bias torch.Size([1280])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_ema.diffusion_modelinput_blocks70emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks70emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks70out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks70out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks70out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks70out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks70skip_connectionweight torch.Size([1280, 640, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks70skip_connectionbias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71normweight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71normbias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71proj_inweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks71proj_inbias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_kweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_vweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projweight torch.Size([10240, 1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projbias torch.Size([10240])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2weight torch.Size([1280, 5120])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_kweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_vweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks71proj_outweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks71proj_outbias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks80in_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks80in_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks80in_layers2weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks80in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks80emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks80emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks80out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks80out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks80out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks80out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81normweight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81normbias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81proj_inweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks81proj_inbias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_kweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_vweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projweight torch.Size([10240, 1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projbias torch.Size([10240])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2weight torch.Size([1280, 5120])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_kweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_vweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks81proj_outweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modelinput_blocks81proj_outbias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks90opweight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks90opbias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks100in_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks100in_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks100in_layers2weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks100in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks100emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks100emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks100out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks100out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks100out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks100out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks110in_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks110in_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks110in_layers2weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks110in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks110emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelinput_blocks110emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks110out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks110out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelinput_blocks110out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelinput_blocks110out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block0in_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block0in_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block0in_layers2weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelmiddle_block0in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block0emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelmiddle_block0emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block0out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block0out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block0out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelmiddle_block0out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1normweight torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1normbias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1proj_inweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modelmiddle_block1proj_inbias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_kweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_vweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projweight torch.Size([10240, 1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projbias torch.Size([10240])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2weight torch.Size([1280, 5120])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_kweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_vweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1weight torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2weight torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3weight torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block1proj_outweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modelmiddle_block1proj_outbias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block2in_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block2in_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block2in_layers2weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelmiddle_block2in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block2emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modelmiddle_block2emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block2out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block2out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modelmiddle_block2out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modelmiddle_block2out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks00in_layers0weight torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks00in_layers0bias torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks00in_layers2weight torch.Size([1280, 2560, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks00in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks00emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks00emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks00out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks00out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks00out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks00out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks00skip_connectionweight torch.Size([1280, 2560, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks00skip_connectionbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks10in_layers0weight torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks10in_layers0bias torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks10in_layers2weight torch.Size([1280, 2560, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks10in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks10emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks10emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks10out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks10out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks10out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks10out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks10skip_connectionweight torch.Size([1280, 2560, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks10skip_connectionbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks20in_layers0weight torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks20in_layers0bias torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks20in_layers2weight torch.Size([1280, 2560, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks20in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks20emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks20emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks20out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks20out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks20out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks20out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks20skip_connectionweight torch.Size([1280, 2560, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks20skip_connectionbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks21convweight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks21convbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks30in_layers0weight torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks30in_layers0bias torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks30in_layers2weight torch.Size([1280, 2560, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks30in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks30emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks30emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks30out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks30out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks30out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks30out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks30skip_connectionweight torch.Size([1280, 2560, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks30skip_connectionbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31normweight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31normbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31proj_inweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks31proj_inbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_kweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_vweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projweight torch.Size([10240, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projbias torch.Size([10240])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2weight torch.Size([1280, 5120])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_kweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_vweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks31proj_outweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks31proj_outbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks40in_layers0weight torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks40in_layers0bias torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks40in_layers2weight torch.Size([1280, 2560, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks40in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks40emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks40emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks40out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks40out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks40out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks40out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks40skip_connectionweight torch.Size([1280, 2560, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks40skip_connectionbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41normweight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41normbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41proj_inweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks41proj_inbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_kweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_vweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projweight torch.Size([10240, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projbias torch.Size([10240])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2weight torch.Size([1280, 5120])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_kweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_vweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks41proj_outweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks41proj_outbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks50in_layers0weight torch.Size([1920])\n",
      "model_ema.diffusion_modeloutput_blocks50in_layers0bias torch.Size([1920])\n",
      "model_ema.diffusion_modeloutput_blocks50in_layers2weight torch.Size([1280, 1920, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks50in_layers2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks50emb_layers1weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks50emb_layers1bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks50out_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks50out_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks50out_layers3weight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks50out_layers3bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks50skip_connectionweight torch.Size([1280, 1920, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks50skip_connectionbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51normweight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51normbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51proj_inweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks51proj_inbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_kweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_vweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projweight torch.Size([10240, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projbias torch.Size([10240])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2weight torch.Size([1280, 5120])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_qweight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_kweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_vweight torch.Size([1280, 768])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0weight torch.Size([1280, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks51proj_outweight torch.Size([1280, 1280, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks51proj_outbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks52convweight torch.Size([1280, 1280, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks52convbias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks60in_layers0weight torch.Size([1920])\n",
      "model_ema.diffusion_modeloutput_blocks60in_layers0bias torch.Size([1920])\n",
      "model_ema.diffusion_modeloutput_blocks60in_layers2weight torch.Size([640, 1920, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks60in_layers2bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks60emb_layers1weight torch.Size([640, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks60emb_layers1bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks60out_layers0weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks60out_layers0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks60out_layers3weight torch.Size([640, 640, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks60out_layers3bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks60skip_connectionweight torch.Size([640, 1920, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks60skip_connectionbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61normweight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61normbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61proj_inweight torch.Size([640, 640, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks61proj_inbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_qweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_kweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_vweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0weight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projweight torch.Size([5120, 640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projbias torch.Size([5120])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2weight torch.Size([640, 2560])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_qweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_kweight torch.Size([640, 768])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_vweight torch.Size([640, 768])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0weight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks61proj_outweight torch.Size([640, 640, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks61proj_outbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks70in_layers0weight torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks70in_layers0bias torch.Size([1280])\n",
      "model_ema.diffusion_modeloutput_blocks70in_layers2weight torch.Size([640, 1280, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks70in_layers2bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks70emb_layers1weight torch.Size([640, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks70emb_layers1bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks70out_layers0weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks70out_layers0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks70out_layers3weight torch.Size([640, 640, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks70out_layers3bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks70skip_connectionweight torch.Size([640, 1280, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks70skip_connectionbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71normweight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71normbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71proj_inweight torch.Size([640, 640, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks71proj_inbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_qweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_kweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_vweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0weight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projweight torch.Size([5120, 640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projbias torch.Size([5120])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2weight torch.Size([640, 2560])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_qweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_kweight torch.Size([640, 768])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_vweight torch.Size([640, 768])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0weight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks71proj_outweight torch.Size([640, 640, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks71proj_outbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks80in_layers0weight torch.Size([960])\n",
      "model_ema.diffusion_modeloutput_blocks80in_layers0bias torch.Size([960])\n",
      "model_ema.diffusion_modeloutput_blocks80in_layers2weight torch.Size([640, 960, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks80in_layers2bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks80emb_layers1weight torch.Size([640, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks80emb_layers1bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks80out_layers0weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks80out_layers0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks80out_layers3weight torch.Size([640, 640, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks80out_layers3bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks80skip_connectionweight torch.Size([640, 960, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks80skip_connectionbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81normweight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81normbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81proj_inweight torch.Size([640, 640, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks81proj_inbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_qweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_kweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_vweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0weight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projweight torch.Size([5120, 640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projbias torch.Size([5120])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2weight torch.Size([640, 2560])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_qweight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_kweight torch.Size([640, 768])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_vweight torch.Size([640, 768])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0weight torch.Size([640, 640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks81proj_outweight torch.Size([640, 640, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks81proj_outbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks82convweight torch.Size([640, 640, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks82convbias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks90in_layers0weight torch.Size([960])\n",
      "model_ema.diffusion_modeloutput_blocks90in_layers0bias torch.Size([960])\n",
      "model_ema.diffusion_modeloutput_blocks90in_layers2weight torch.Size([320, 960, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks90in_layers2bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks90emb_layers1weight torch.Size([320, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks90emb_layers1bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks90out_layers0weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks90out_layers0bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks90out_layers3weight torch.Size([320, 320, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks90out_layers3bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks90skip_connectionweight torch.Size([320, 960, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks90skip_connectionbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91normweight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91normbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91proj_inweight torch.Size([320, 320, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks91proj_inbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_qweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_kweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_vweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0weight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projweight torch.Size([2560, 320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projbias torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2weight torch.Size([320, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_qweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_kweight torch.Size([320, 768])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_vweight torch.Size([320, 768])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0weight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks91proj_outweight torch.Size([320, 320, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks91proj_outbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks100in_layers0weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks100in_layers0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks100in_layers2weight torch.Size([320, 640, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks100in_layers2bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks100emb_layers1weight torch.Size([320, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks100emb_layers1bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks100out_layers0weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks100out_layers0bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks100out_layers3weight torch.Size([320, 320, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks100out_layers3bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks100skip_connectionweight torch.Size([320, 640, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks100skip_connectionbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101normweight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101normbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101proj_inweight torch.Size([320, 320, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks101proj_inbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_qweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_kweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_vweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0weight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projweight torch.Size([2560, 320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projbias torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2weight torch.Size([320, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_qweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_kweight torch.Size([320, 768])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_vweight torch.Size([320, 768])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0weight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks101proj_outweight torch.Size([320, 320, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks101proj_outbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks110in_layers0weight torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks110in_layers0bias torch.Size([640])\n",
      "model_ema.diffusion_modeloutput_blocks110in_layers2weight torch.Size([320, 640, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks110in_layers2bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks110emb_layers1weight torch.Size([320, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks110emb_layers1bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks110out_layers0weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks110out_layers0bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks110out_layers3weight torch.Size([320, 320, 3, 3])\n",
      "model_ema.diffusion_modeloutput_blocks110out_layers3bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks110skip_connectionweight torch.Size([320, 640, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks110skip_connectionbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111normweight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111normbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111proj_inweight torch.Size([320, 320, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks111proj_inbias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_qweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_kweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_vweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0weight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projweight torch.Size([2560, 320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projbias torch.Size([2560])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2weight torch.Size([320, 1280])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_qweight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_kweight torch.Size([320, 768])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_vweight torch.Size([320, 768])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0weight torch.Size([320, 320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3weight torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3bias torch.Size([320])\n",
      "model_ema.diffusion_modeloutput_blocks111proj_outweight torch.Size([320, 320, 1, 1])\n",
      "model_ema.diffusion_modeloutput_blocks111proj_outbias torch.Size([320])\n",
      "model_ema.diffusion_modelout0weight torch.Size([320])\n",
      "model_ema.diffusion_modelout0bias torch.Size([320])\n",
      "model_ema.diffusion_modelout2weight torch.Size([4, 320, 3, 3])\n",
      "model_ema.diffusion_modelout2bias torch.Size([4])\n",
      "first_stage_model.encoder.conv_in.weight torch.Size([128, 3, 3, 3])\n",
      "first_stage_model.encoder.conv_in.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.0.norm1.weight torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.0.norm1.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.0.conv1.weight torch.Size([128, 128, 3, 3])\n",
      "first_stage_model.encoder.down.0.block.0.conv1.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.0.norm2.weight torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.0.norm2.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "first_stage_model.encoder.down.0.block.0.conv2.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.1.norm1.weight torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.1.norm1.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.1.conv1.weight torch.Size([128, 128, 3, 3])\n",
      "first_stage_model.encoder.down.0.block.1.conv1.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.1.norm2.weight torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.1.norm2.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.0.block.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "first_stage_model.encoder.down.0.block.1.conv2.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.0.downsample.conv.weight torch.Size([128, 128, 3, 3])\n",
      "first_stage_model.encoder.down.0.downsample.conv.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.1.block.0.norm1.weight torch.Size([128])\n",
      "first_stage_model.encoder.down.1.block.0.norm1.bias torch.Size([128])\n",
      "first_stage_model.encoder.down.1.block.0.conv1.weight torch.Size([256, 128, 3, 3])\n",
      "first_stage_model.encoder.down.1.block.0.conv1.bias torch.Size([256])\n",
      "first_stage_model.encoder.down.1.block.0.norm2.weight torch.Size([256])\n",
      "first_stage_model.encoder.down.1.block.0.norm2.bias torch.Size([256])\n",
      "first_stage_model.encoder.down.1.block.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "first_stage_model.encoder.down.1.block.0.conv2.bias torch.Size([256])\n",
      "first_stage_model.encoder.down.1.block.0.nin_shortcut.weight torch.Size([256, 128, 1, 1])\n",
      "first_stage_model.encoder.down.1.block.0.nin_shortcut.bias torch.Size([256])\n",
      "first_stage_model.encoder.down.1.block.1.norm1.weight torch.Size([256])\n",
      "first_stage_model.encoder.down.1.block.1.norm1.bias torch.Size([256])\n",
      "first_stage_model.encoder.down.1.block.1.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "first_stage_model.encoder.down.1.block.1.conv1.bias torch.Size([256])\n",
      "first_stage_model.encoder.down.1.block.1.norm2.weight torch.Size([256])\n",
      "first_stage_model.encoder.down.1.block.1.norm2.bias torch.Size([256])\n",
      "first_stage_model.encoder.down.1.block.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "first_stage_model.encoder.down.1.block.1.conv2.bias torch.Size([256])\n",
      "first_stage_model.encoder.down.1.downsample.conv.weight torch.Size([256, 256, 3, 3])\n",
      "first_stage_model.encoder.down.1.downsample.conv.bias torch.Size([256])\n",
      "first_stage_model.encoder.down.2.block.0.norm1.weight torch.Size([256])\n",
      "first_stage_model.encoder.down.2.block.0.norm1.bias torch.Size([256])\n",
      "first_stage_model.encoder.down.2.block.0.conv1.weight torch.Size([512, 256, 3, 3])\n",
      "first_stage_model.encoder.down.2.block.0.conv1.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.2.block.0.norm2.weight torch.Size([512])\n",
      "first_stage_model.encoder.down.2.block.0.norm2.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.2.block.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.down.2.block.0.conv2.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.2.block.0.nin_shortcut.weight torch.Size([512, 256, 1, 1])\n",
      "first_stage_model.encoder.down.2.block.0.nin_shortcut.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.2.block.1.norm1.weight torch.Size([512])\n",
      "first_stage_model.encoder.down.2.block.1.norm1.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.2.block.1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.down.2.block.1.conv1.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.2.block.1.norm2.weight torch.Size([512])\n",
      "first_stage_model.encoder.down.2.block.1.norm2.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.2.block.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.down.2.block.1.conv2.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.2.downsample.conv.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.down.2.downsample.conv.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.0.norm1.weight torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.0.norm1.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.0.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.down.3.block.0.conv1.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.0.norm2.weight torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.0.norm2.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.down.3.block.0.conv2.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.1.norm1.weight torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.1.norm1.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.down.3.block.1.conv1.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.1.norm2.weight torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.1.norm2.bias torch.Size([512])\n",
      "first_stage_model.encoder.down.3.block.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.down.3.block.1.conv2.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_1.norm1.weight torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_1.norm1.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.mid.block_1.conv1.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_1.norm2.weight torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_1.norm2.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.mid.block_1.conv2.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.attn_1.norm.weight torch.Size([512])\n",
      "first_stage_model.encoder.mid.attn_1.norm.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.attn_1.q.weight torch.Size([512, 512, 1, 1])\n",
      "first_stage_model.encoder.mid.attn_1.q.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.attn_1.k.weight torch.Size([512, 512, 1, 1])\n",
      "first_stage_model.encoder.mid.attn_1.k.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.attn_1.v.weight torch.Size([512, 512, 1, 1])\n",
      "first_stage_model.encoder.mid.attn_1.v.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.attn_1.proj_out.weight torch.Size([512, 512, 1, 1])\n",
      "first_stage_model.encoder.mid.attn_1.proj_out.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_2.norm1.weight torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_2.norm1.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_2.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.mid.block_2.conv1.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_2.norm2.weight torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_2.norm2.bias torch.Size([512])\n",
      "first_stage_model.encoder.mid.block_2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.encoder.mid.block_2.conv2.bias torch.Size([512])\n",
      "first_stage_model.encoder.norm_out.weight torch.Size([512])\n",
      "first_stage_model.encoder.norm_out.bias torch.Size([512])\n",
      "first_stage_model.encoder.conv_out.weight torch.Size([8, 512, 3, 3])\n",
      "first_stage_model.encoder.conv_out.bias torch.Size([8])\n",
      "first_stage_model.decoder.conv_in.weight torch.Size([512, 4, 3, 3])\n",
      "first_stage_model.decoder.conv_in.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_1.norm1.weight torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_1.norm1.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.mid.block_1.conv1.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_1.norm2.weight torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_1.norm2.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.mid.block_1.conv2.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.attn_1.norm.weight torch.Size([512])\n",
      "first_stage_model.decoder.mid.attn_1.norm.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.attn_1.q.weight torch.Size([512, 512, 1, 1])\n",
      "first_stage_model.decoder.mid.attn_1.q.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.attn_1.k.weight torch.Size([512, 512, 1, 1])\n",
      "first_stage_model.decoder.mid.attn_1.k.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.attn_1.v.weight torch.Size([512, 512, 1, 1])\n",
      "first_stage_model.decoder.mid.attn_1.v.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.attn_1.proj_out.weight torch.Size([512, 512, 1, 1])\n",
      "first_stage_model.decoder.mid.attn_1.proj_out.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_2.norm1.weight torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_2.norm1.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_2.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.mid.block_2.conv1.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_2.norm2.weight torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_2.norm2.bias torch.Size([512])\n",
      "first_stage_model.decoder.mid.block_2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.mid.block_2.conv2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.0.block.0.norm1.weight torch.Size([256])\n",
      "first_stage_model.decoder.up.0.block.0.norm1.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.0.block.0.conv1.weight torch.Size([128, 256, 3, 3])\n",
      "first_stage_model.decoder.up.0.block.0.conv1.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.0.norm2.weight torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.0.norm2.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "first_stage_model.decoder.up.0.block.0.conv2.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.0.nin_shortcut.weight torch.Size([128, 256, 1, 1])\n",
      "first_stage_model.decoder.up.0.block.0.nin_shortcut.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.1.norm1.weight torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.1.norm1.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.1.conv1.weight torch.Size([128, 128, 3, 3])\n",
      "first_stage_model.decoder.up.0.block.1.conv1.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.1.norm2.weight torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.1.norm2.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "first_stage_model.decoder.up.0.block.1.conv2.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.2.norm1.weight torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.2.norm1.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.2.conv1.weight torch.Size([128, 128, 3, 3])\n",
      "first_stage_model.decoder.up.0.block.2.conv1.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.2.norm2.weight torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.2.norm2.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.0.block.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "first_stage_model.decoder.up.0.block.2.conv2.bias torch.Size([128])\n",
      "first_stage_model.decoder.up.1.block.0.norm1.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.1.block.0.norm1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.1.block.0.conv1.weight torch.Size([256, 512, 3, 3])\n",
      "first_stage_model.decoder.up.1.block.0.conv1.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.0.norm2.weight torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.0.norm2.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "first_stage_model.decoder.up.1.block.0.conv2.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.0.nin_shortcut.weight torch.Size([256, 512, 1, 1])\n",
      "first_stage_model.decoder.up.1.block.0.nin_shortcut.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.1.norm1.weight torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.1.norm1.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.1.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "first_stage_model.decoder.up.1.block.1.conv1.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.1.norm2.weight torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.1.norm2.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "first_stage_model.decoder.up.1.block.1.conv2.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.2.norm1.weight torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.2.norm1.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.2.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "first_stage_model.decoder.up.1.block.2.conv1.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.2.norm2.weight torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.2.norm2.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.block.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "first_stage_model.decoder.up.1.block.2.conv2.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.1.upsample.conv.weight torch.Size([256, 256, 3, 3])\n",
      "first_stage_model.decoder.up.1.upsample.conv.bias torch.Size([256])\n",
      "first_stage_model.decoder.up.2.block.0.norm1.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.0.norm1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.0.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.2.block.0.conv1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.0.norm2.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.0.norm2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.2.block.0.conv2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.1.norm1.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.1.norm1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.2.block.1.conv1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.1.norm2.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.1.norm2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.2.block.1.conv2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.2.norm1.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.2.norm1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.2.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.2.block.2.conv1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.2.norm2.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.2.norm2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.block.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.2.block.2.conv2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.2.upsample.conv.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.2.upsample.conv.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.0.norm1.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.0.norm1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.0.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.3.block.0.conv1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.0.norm2.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.0.norm2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.3.block.0.conv2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.1.norm1.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.1.norm1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.3.block.1.conv1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.1.norm2.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.1.norm2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.3.block.1.conv2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.2.norm1.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.2.norm1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.2.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.3.block.2.conv1.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.2.norm2.weight torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.2.norm2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.block.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.3.block.2.conv2.bias torch.Size([512])\n",
      "first_stage_model.decoder.up.3.upsample.conv.weight torch.Size([512, 512, 3, 3])\n",
      "first_stage_model.decoder.up.3.upsample.conv.bias torch.Size([512])\n",
      "first_stage_model.decoder.norm_out.weight torch.Size([128])\n",
      "first_stage_model.decoder.norm_out.bias torch.Size([128])\n",
      "first_stage_model.decoder.conv_out.weight torch.Size([3, 128, 3, 3])\n",
      "first_stage_model.decoder.conv_out.bias torch.Size([3])\n",
      "first_stage_model.quant_conv.weight torch.Size([8, 8, 1, 1])\n",
      "first_stage_model.quant_conv.bias torch.Size([8])\n",
      "first_stage_model.post_quant_conv.weight torch.Size([4, 4, 1, 1])\n",
      "first_stage_model.post_quant_conv.bias torch.Size([4])\n",
      "cond_stage_model.model.positional_embedding torch.Size([77, 768])\n",
      "cond_stage_model.model.text_projection torch.Size([768, 768])\n",
      "cond_stage_model.model.logit_scale torch.Size([])\n",
      "cond_stage_model.model.visual.class_embedding torch.Size([1024])\n",
      "cond_stage_model.model.visual.positional_embedding torch.Size([257, 1024])\n",
      "cond_stage_model.model.visual.proj torch.Size([1024, 768])\n",
      "cond_stage_model.model.visual.conv1.weight torch.Size([1024, 3, 14, 14])\n",
      "cond_stage_model.model.visual.ln_pre.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.ln_pre.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.0.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.1.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.2.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.3.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.4.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.5.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.6.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.7.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.8.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.9.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.10.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.11.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.12.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.13.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.14.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.15.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.16.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.attn.out_proj.weight torch.Size([1024, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_stage_model.model.visual.transformer.resblocks.17.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.17.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.18.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.19.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.20.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.21.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.22.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.attn.in_proj_weight torch.Size([3072, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.attn.in_proj_bias torch.Size([3072])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.attn.out_proj.weight torch.Size([1024, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.attn.out_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.ln_1.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.ln_1.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.mlp.c_fc.weight torch.Size([4096, 1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.mlp.c_fc.bias torch.Size([4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.mlp.c_proj.weight torch.Size([1024, 4096])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.mlp.c_proj.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.ln_2.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.transformer.resblocks.23.ln_2.bias torch.Size([1024])\n",
      "cond_stage_model.model.visual.ln_post.weight torch.Size([1024])\n",
      "cond_stage_model.model.visual.ln_post.bias torch.Size([1024])\n",
      "cond_stage_model.model.token_embedding.weight torch.Size([49408, 768])\n",
      "cond_stage_model.model.ln_final.weight torch.Size([768])\n",
      "cond_stage_model.model.ln_final.bias torch.Size([768])\n",
      "cc_projection.weight torch.Size([768, 772])\n",
      "cc_projection.bias torch.Size([768])\n",
      "1938\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "ckpt_keys = []\n",
    "for key in ckpt_v1.keys():\n",
    "#     if key.startswith('first_stage_model'):\n",
    "    print(key, ckpt_v1[key].shape)\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1ab8a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 8, 3, 3])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_v1['model.diffusion_model.input_blocks.0.0.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd7e2eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0232)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_v1['model.diffusion_model.input_blocks.0.0.weight'][:, 4:, :, :].norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f440c4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9793)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_v1['model.diffusion_model.input_blocks.0.0.weight'][:, :4, :, :].norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23c5b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss.discriminator.main.0.bias',\n",
       " 'loss.discriminator.main.0.weight',\n",
       " 'loss.discriminator.main.11.bias',\n",
       " 'loss.discriminator.main.11.weight',\n",
       " 'loss.discriminator.main.2.weight',\n",
       " 'loss.discriminator.main.3.bias',\n",
       " 'loss.discriminator.main.3.num_batches_tracked',\n",
       " 'loss.discriminator.main.3.running_mean',\n",
       " 'loss.discriminator.main.3.running_var',\n",
       " 'loss.discriminator.main.3.weight',\n",
       " 'loss.discriminator.main.5.weight',\n",
       " 'loss.discriminator.main.6.bias',\n",
       " 'loss.discriminator.main.6.num_batches_tracked',\n",
       " 'loss.discriminator.main.6.running_mean',\n",
       " 'loss.discriminator.main.6.running_var',\n",
       " 'loss.discriminator.main.6.weight',\n",
       " 'loss.discriminator.main.8.weight',\n",
       " 'loss.discriminator.main.9.bias',\n",
       " 'loss.discriminator.main.9.num_batches_tracked',\n",
       " 'loss.discriminator.main.9.running_mean',\n",
       " 'loss.discriminator.main.9.running_var',\n",
       " 'loss.discriminator.main.9.weight',\n",
       " 'loss.logvar',\n",
       " 'loss.perceptual_loss.lin0.model.1.weight',\n",
       " 'loss.perceptual_loss.lin1.model.1.weight',\n",
       " 'loss.perceptual_loss.lin2.model.1.weight',\n",
       " 'loss.perceptual_loss.lin3.model.1.weight',\n",
       " 'loss.perceptual_loss.lin4.model.1.weight',\n",
       " 'loss.perceptual_loss.net.slice1.0.bias',\n",
       " 'loss.perceptual_loss.net.slice1.0.weight',\n",
       " 'loss.perceptual_loss.net.slice1.2.bias',\n",
       " 'loss.perceptual_loss.net.slice1.2.weight',\n",
       " 'loss.perceptual_loss.net.slice2.5.bias',\n",
       " 'loss.perceptual_loss.net.slice2.5.weight',\n",
       " 'loss.perceptual_loss.net.slice2.7.bias',\n",
       " 'loss.perceptual_loss.net.slice2.7.weight',\n",
       " 'loss.perceptual_loss.net.slice3.10.bias',\n",
       " 'loss.perceptual_loss.net.slice3.10.weight',\n",
       " 'loss.perceptual_loss.net.slice3.12.bias',\n",
       " 'loss.perceptual_loss.net.slice3.12.weight',\n",
       " 'loss.perceptual_loss.net.slice3.14.bias',\n",
       " 'loss.perceptual_loss.net.slice3.14.weight',\n",
       " 'loss.perceptual_loss.net.slice4.17.bias',\n",
       " 'loss.perceptual_loss.net.slice4.17.weight',\n",
       " 'loss.perceptual_loss.net.slice4.19.bias',\n",
       " 'loss.perceptual_loss.net.slice4.19.weight',\n",
       " 'loss.perceptual_loss.net.slice4.21.bias',\n",
       " 'loss.perceptual_loss.net.slice4.21.weight',\n",
       " 'loss.perceptual_loss.net.slice5.24.bias',\n",
       " 'loss.perceptual_loss.net.slice5.24.weight',\n",
       " 'loss.perceptual_loss.net.slice5.26.bias',\n",
       " 'loss.perceptual_loss.net.slice5.26.weight',\n",
       " 'loss.perceptual_loss.net.slice5.28.bias',\n",
       " 'loss.perceptual_loss.net.slice5.28.weight',\n",
       " 'loss.perceptual_loss.scaling_layer.scale',\n",
       " 'loss.perceptual_loss.scaling_layer.shift'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(first_keys) - set(ckpt_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57775925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e69a9ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1280, 320])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([320, 4, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([2560, 320])\n",
      "torch.Size([2560])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([2560, 320])\n",
      "torch.Size([2560])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([640, 320, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 320, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([5120, 640])\n",
      "torch.Size([5120])\n",
      "torch.Size([640, 2560])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([5120, 640])\n",
      "torch.Size([5120])\n",
      "torch.Size([640, 2560])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([1280, 640, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 640, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n",
      "torch.Size([1280, 2560, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 2560, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n",
      "torch.Size([1280, 2560, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 2560, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n",
      "torch.Size([1280, 2560, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 2560, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n",
      "torch.Size([1280, 2560, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 2560, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n",
      "torch.Size([1280, 2560, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 2560, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1920])\n",
      "torch.Size([1920])\n",
      "torch.Size([1280, 1920, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1920, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1920])\n",
      "torch.Size([1920])\n",
      "torch.Size([640, 1920, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1920, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([5120, 640])\n",
      "torch.Size([5120])\n",
      "torch.Size([640, 2560])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([640, 1280, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([5120, 640])\n",
      "torch.Size([5120])\n",
      "torch.Size([640, 2560])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([960])\n",
      "torch.Size([960])\n",
      "torch.Size([640, 960, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 960, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([5120, 640])\n",
      "torch.Size([5120])\n",
      "torch.Size([640, 2560])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([960])\n",
      "torch.Size([960])\n",
      "torch.Size([320, 960, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 960, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([2560, 320])\n",
      "torch.Size([2560])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([320, 640, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 640, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([2560, 320])\n",
      "torch.Size([2560])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([320, 640, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 640, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([2560, 320])\n",
      "torch.Size([2560])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([4, 320, 3, 3])\n",
      "torch.Size([4])\n",
      "torch.Size([])\n",
      "torch.Size([])\n",
      "torch.Size([1280, 320])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([320, 4, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([2560, 320])\n",
      "torch.Size([2560])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([2560, 320])\n",
      "torch.Size([2560])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([640, 320, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 320, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([5120, 640])\n",
      "torch.Size([5120])\n",
      "torch.Size([640, 2560])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([5120, 640])\n",
      "torch.Size([5120])\n",
      "torch.Size([640, 2560])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([1280, 640, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 640, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n",
      "torch.Size([1280, 2560, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 2560, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n",
      "torch.Size([1280, 2560, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 2560, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n",
      "torch.Size([1280, 2560, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 2560, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n",
      "torch.Size([1280, 2560, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 2560, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n",
      "torch.Size([1280, 2560, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 2560, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1920])\n",
      "torch.Size([1920])\n",
      "torch.Size([1280, 1920, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1920, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([10240, 1280])\n",
      "torch.Size([10240])\n",
      "torch.Size([1280, 5120])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 768])\n",
      "torch.Size([1280, 1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 1, 1])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280, 1280, 3, 3])\n",
      "torch.Size([1280])\n",
      "torch.Size([1920])\n",
      "torch.Size([1920])\n",
      "torch.Size([640, 1920, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1920, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([5120, 640])\n",
      "torch.Size([5120])\n",
      "torch.Size([640, 2560])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([1280])\n",
      "torch.Size([1280])\n",
      "torch.Size([640, 1280, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([5120, 640])\n",
      "torch.Size([5120])\n",
      "torch.Size([640, 2560])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([960])\n",
      "torch.Size([960])\n",
      "torch.Size([640, 960, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 1280])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 960, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([5120, 640])\n",
      "torch.Size([5120])\n",
      "torch.Size([640, 2560])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 768])\n",
      "torch.Size([640, 640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([960])\n",
      "torch.Size([960])\n",
      "torch.Size([320, 960, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 960, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([2560, 320])\n",
      "torch.Size([2560])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([320, 640, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 640, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([2560, 320])\n",
      "torch.Size([2560])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([320, 640, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 640, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([2560, 320])\n",
      "torch.Size([2560])\n",
      "torch.Size([320, 1280])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 768])\n",
      "torch.Size([320, 320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([4, 320, 3, 3])\n",
      "torch.Size([4])\n",
      "torch.Size([128, 3, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([8, 512, 3, 3])\n",
      "torch.Size([8])\n",
      "torch.Size([512, 4, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([3, 128, 3, 3])\n",
      "torch.Size([3])\n",
      "torch.Size([8, 8, 1, 1])\n",
      "torch.Size([8])\n",
      "torch.Size([4, 4, 1, 1])\n",
      "torch.Size([4])\n",
      "torch.Size([77, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([])\n",
      "torch.Size([1024])\n",
      "torch.Size([257, 1024])\n",
      "torch.Size([1024, 768])\n",
      "torch.Size([1024, 3, 14, 14])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([3072, 1024])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([4096])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([49408, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 771])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for layer in ckpt_v1['state_dict'].keys():\n",
    "    print(ckpt_v1['state_dict'][layer].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6e7c3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['betas', 'alphas_cumprod', 'alphas_cumprod_prev', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod', 'log_one_minus_alphas_cumprod', 'sqrt_recip_alphas_cumprod', 'sqrt_recipm1_alphas_cumprod', 'posterior_variance', 'posterior_log_variance_clipped', 'posterior_mean_coef1', 'posterior_mean_coef2', 'model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1.norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.4.0.skip_connection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.2.weight', 'model.diffusion_model.middle_block.0.in_layers.2.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.3.weight', 'model.diffusion_model.middle_block.0.out_layers.3.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.2.weight', 'model.diffusion_model.middle_block.2.in_layers.2.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.3.weight', 'model.diffusion_model.middle_block.2.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bias', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6.1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.output_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.2.weight', 'model.diffusion_model.out.2.bias', 'model_ema.decay', 'model_ema.num_updates', 'model_ema.diffusion_modeltime_embed0weight', 'model_ema.diffusion_modeltime_embed0bias', 'model_ema.diffusion_modeltime_embed2weight', 'model_ema.diffusion_modeltime_embed2bias', 'model_ema.diffusion_modelinput_blocks00weight', 'model_ema.diffusion_modelinput_blocks00bias', 'model_ema.diffusion_modelinput_blocks10in_layers0weight', 'model_ema.diffusion_modelinput_blocks10in_layers0bias', 'model_ema.diffusion_modelinput_blocks10in_layers2weight', 'model_ema.diffusion_modelinput_blocks10in_layers2bias', 'model_ema.diffusion_modelinput_blocks10emb_layers1weight', 'model_ema.diffusion_modelinput_blocks10emb_layers1bias', 'model_ema.diffusion_modelinput_blocks10out_layers0weight', 'model_ema.diffusion_modelinput_blocks10out_layers0bias', 'model_ema.diffusion_modelinput_blocks10out_layers3weight', 'model_ema.diffusion_modelinput_blocks10out_layers3bias', 'model_ema.diffusion_modelinput_blocks11normweight', 'model_ema.diffusion_modelinput_blocks11normbias', 'model_ema.diffusion_modelinput_blocks11proj_inweight', 'model_ema.diffusion_modelinput_blocks11proj_inbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks11proj_outweight', 'model_ema.diffusion_modelinput_blocks11proj_outbias', 'model_ema.diffusion_modelinput_blocks20in_layers0weight', 'model_ema.diffusion_modelinput_blocks20in_layers0bias', 'model_ema.diffusion_modelinput_blocks20in_layers2weight', 'model_ema.diffusion_modelinput_blocks20in_layers2bias', 'model_ema.diffusion_modelinput_blocks20emb_layers1weight', 'model_ema.diffusion_modelinput_blocks20emb_layers1bias', 'model_ema.diffusion_modelinput_blocks20out_layers0weight', 'model_ema.diffusion_modelinput_blocks20out_layers0bias', 'model_ema.diffusion_modelinput_blocks20out_layers3weight', 'model_ema.diffusion_modelinput_blocks20out_layers3bias', 'model_ema.diffusion_modelinput_blocks21normweight', 'model_ema.diffusion_modelinput_blocks21normbias', 'model_ema.diffusion_modelinput_blocks21proj_inweight', 'model_ema.diffusion_modelinput_blocks21proj_inbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks21proj_outweight', 'model_ema.diffusion_modelinput_blocks21proj_outbias', 'model_ema.diffusion_modelinput_blocks30opweight', 'model_ema.diffusion_modelinput_blocks30opbias', 'model_ema.diffusion_modelinput_blocks40in_layers0weight', 'model_ema.diffusion_modelinput_blocks40in_layers0bias', 'model_ema.diffusion_modelinput_blocks40in_layers2weight', 'model_ema.diffusion_modelinput_blocks40in_layers2bias', 'model_ema.diffusion_modelinput_blocks40emb_layers1weight', 'model_ema.diffusion_modelinput_blocks40emb_layers1bias', 'model_ema.diffusion_modelinput_blocks40out_layers0weight', 'model_ema.diffusion_modelinput_blocks40out_layers0bias', 'model_ema.diffusion_modelinput_blocks40out_layers3weight', 'model_ema.diffusion_modelinput_blocks40out_layers3bias', 'model_ema.diffusion_modelinput_blocks40skip_connectionweight', 'model_ema.diffusion_modelinput_blocks40skip_connectionbias', 'model_ema.diffusion_modelinput_blocks41normweight', 'model_ema.diffusion_modelinput_blocks41normbias', 'model_ema.diffusion_modelinput_blocks41proj_inweight', 'model_ema.diffusion_modelinput_blocks41proj_inbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks41proj_outweight', 'model_ema.diffusion_modelinput_blocks41proj_outbias', 'model_ema.diffusion_modelinput_blocks50in_layers0weight', 'model_ema.diffusion_modelinput_blocks50in_layers0bias', 'model_ema.diffusion_modelinput_blocks50in_layers2weight', 'model_ema.diffusion_modelinput_blocks50in_layers2bias', 'model_ema.diffusion_modelinput_blocks50emb_layers1weight', 'model_ema.diffusion_modelinput_blocks50emb_layers1bias', 'model_ema.diffusion_modelinput_blocks50out_layers0weight', 'model_ema.diffusion_modelinput_blocks50out_layers0bias', 'model_ema.diffusion_modelinput_blocks50out_layers3weight', 'model_ema.diffusion_modelinput_blocks50out_layers3bias', 'model_ema.diffusion_modelinput_blocks51normweight', 'model_ema.diffusion_modelinput_blocks51normbias', 'model_ema.diffusion_modelinput_blocks51proj_inweight', 'model_ema.diffusion_modelinput_blocks51proj_inbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks51proj_outweight', 'model_ema.diffusion_modelinput_blocks51proj_outbias', 'model_ema.diffusion_modelinput_blocks60opweight', 'model_ema.diffusion_modelinput_blocks60opbias', 'model_ema.diffusion_modelinput_blocks70in_layers0weight', 'model_ema.diffusion_modelinput_blocks70in_layers0bias', 'model_ema.diffusion_modelinput_blocks70in_layers2weight', 'model_ema.diffusion_modelinput_blocks70in_layers2bias', 'model_ema.diffusion_modelinput_blocks70emb_layers1weight', 'model_ema.diffusion_modelinput_blocks70emb_layers1bias', 'model_ema.diffusion_modelinput_blocks70out_layers0weight', 'model_ema.diffusion_modelinput_blocks70out_layers0bias', 'model_ema.diffusion_modelinput_blocks70out_layers3weight', 'model_ema.diffusion_modelinput_blocks70out_layers3bias', 'model_ema.diffusion_modelinput_blocks70skip_connectionweight', 'model_ema.diffusion_modelinput_blocks70skip_connectionbias', 'model_ema.diffusion_modelinput_blocks71normweight', 'model_ema.diffusion_modelinput_blocks71normbias', 'model_ema.diffusion_modelinput_blocks71proj_inweight', 'model_ema.diffusion_modelinput_blocks71proj_inbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks71proj_outweight', 'model_ema.diffusion_modelinput_blocks71proj_outbias', 'model_ema.diffusion_modelinput_blocks80in_layers0weight', 'model_ema.diffusion_modelinput_blocks80in_layers0bias', 'model_ema.diffusion_modelinput_blocks80in_layers2weight', 'model_ema.diffusion_modelinput_blocks80in_layers2bias', 'model_ema.diffusion_modelinput_blocks80emb_layers1weight', 'model_ema.diffusion_modelinput_blocks80emb_layers1bias', 'model_ema.diffusion_modelinput_blocks80out_layers0weight', 'model_ema.diffusion_modelinput_blocks80out_layers0bias', 'model_ema.diffusion_modelinput_blocks80out_layers3weight', 'model_ema.diffusion_modelinput_blocks80out_layers3bias', 'model_ema.diffusion_modelinput_blocks81normweight', 'model_ema.diffusion_modelinput_blocks81normbias', 'model_ema.diffusion_modelinput_blocks81proj_inweight', 'model_ema.diffusion_modelinput_blocks81proj_inbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks81proj_outweight', 'model_ema.diffusion_modelinput_blocks81proj_outbias', 'model_ema.diffusion_modelinput_blocks90opweight', 'model_ema.diffusion_modelinput_blocks90opbias', 'model_ema.diffusion_modelinput_blocks100in_layers0weight', 'model_ema.diffusion_modelinput_blocks100in_layers0bias', 'model_ema.diffusion_modelinput_blocks100in_layers2weight', 'model_ema.diffusion_modelinput_blocks100in_layers2bias', 'model_ema.diffusion_modelinput_blocks100emb_layers1weight', 'model_ema.diffusion_modelinput_blocks100emb_layers1bias', 'model_ema.diffusion_modelinput_blocks100out_layers0weight', 'model_ema.diffusion_modelinput_blocks100out_layers0bias', 'model_ema.diffusion_modelinput_blocks100out_layers3weight', 'model_ema.diffusion_modelinput_blocks100out_layers3bias', 'model_ema.diffusion_modelinput_blocks110in_layers0weight', 'model_ema.diffusion_modelinput_blocks110in_layers0bias', 'model_ema.diffusion_modelinput_blocks110in_layers2weight', 'model_ema.diffusion_modelinput_blocks110in_layers2bias', 'model_ema.diffusion_modelinput_blocks110emb_layers1weight', 'model_ema.diffusion_modelinput_blocks110emb_layers1bias', 'model_ema.diffusion_modelinput_blocks110out_layers0weight', 'model_ema.diffusion_modelinput_blocks110out_layers0bias', 'model_ema.diffusion_modelinput_blocks110out_layers3weight', 'model_ema.diffusion_modelinput_blocks110out_layers3bias', 'model_ema.diffusion_modelmiddle_block0in_layers0weight', 'model_ema.diffusion_modelmiddle_block0in_layers0bias', 'model_ema.diffusion_modelmiddle_block0in_layers2weight', 'model_ema.diffusion_modelmiddle_block0in_layers2bias', 'model_ema.diffusion_modelmiddle_block0emb_layers1weight', 'model_ema.diffusion_modelmiddle_block0emb_layers1bias', 'model_ema.diffusion_modelmiddle_block0out_layers0weight', 'model_ema.diffusion_modelmiddle_block0out_layers0bias', 'model_ema.diffusion_modelmiddle_block0out_layers3weight', 'model_ema.diffusion_modelmiddle_block0out_layers3bias', 'model_ema.diffusion_modelmiddle_block1normweight', 'model_ema.diffusion_modelmiddle_block1normbias', 'model_ema.diffusion_modelmiddle_block1proj_inweight', 'model_ema.diffusion_modelmiddle_block1proj_inbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3bias', 'model_ema.diffusion_modelmiddle_block1proj_outweight', 'model_ema.diffusion_modelmiddle_block1proj_outbias', 'model_ema.diffusion_modelmiddle_block2in_layers0weight', 'model_ema.diffusion_modelmiddle_block2in_layers0bias', 'model_ema.diffusion_modelmiddle_block2in_layers2weight', 'model_ema.diffusion_modelmiddle_block2in_layers2bias', 'model_ema.diffusion_modelmiddle_block2emb_layers1weight', 'model_ema.diffusion_modelmiddle_block2emb_layers1bias', 'model_ema.diffusion_modelmiddle_block2out_layers0weight', 'model_ema.diffusion_modelmiddle_block2out_layers0bias', 'model_ema.diffusion_modelmiddle_block2out_layers3weight', 'model_ema.diffusion_modelmiddle_block2out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00in_layers0weight', 'model_ema.diffusion_modeloutput_blocks00in_layers0bias', 'model_ema.diffusion_modeloutput_blocks00in_layers2weight', 'model_ema.diffusion_modeloutput_blocks00in_layers2bias', 'model_ema.diffusion_modeloutput_blocks00emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks00emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks00out_layers0weight', 'model_ema.diffusion_modeloutput_blocks00out_layers0bias', 'model_ema.diffusion_modeloutput_blocks00out_layers3weight', 'model_ema.diffusion_modeloutput_blocks00out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks00skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks10in_layers0weight', 'model_ema.diffusion_modeloutput_blocks10in_layers0bias', 'model_ema.diffusion_modeloutput_blocks10in_layers2weight', 'model_ema.diffusion_modeloutput_blocks10in_layers2bias', 'model_ema.diffusion_modeloutput_blocks10emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks10emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks10out_layers0weight', 'model_ema.diffusion_modeloutput_blocks10out_layers0bias', 'model_ema.diffusion_modeloutput_blocks10out_layers3weight', 'model_ema.diffusion_modeloutput_blocks10out_layers3bias', 'model_ema.diffusion_modeloutput_blocks10skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks10skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks20in_layers0weight', 'model_ema.diffusion_modeloutput_blocks20in_layers0bias', 'model_ema.diffusion_modeloutput_blocks20in_layers2weight', 'model_ema.diffusion_modeloutput_blocks20in_layers2bias', 'model_ema.diffusion_modeloutput_blocks20emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks20emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks20out_layers0weight', 'model_ema.diffusion_modeloutput_blocks20out_layers0bias', 'model_ema.diffusion_modeloutput_blocks20out_layers3weight', 'model_ema.diffusion_modeloutput_blocks20out_layers3bias', 'model_ema.diffusion_modeloutput_blocks20skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks20skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks21convweight', 'model_ema.diffusion_modeloutput_blocks21convbias', 'model_ema.diffusion_modeloutput_blocks30in_layers0weight', 'model_ema.diffusion_modeloutput_blocks30in_layers0bias', 'model_ema.diffusion_modeloutput_blocks30in_layers2weight', 'model_ema.diffusion_modeloutput_blocks30in_layers2bias', 'model_ema.diffusion_modeloutput_blocks30emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks30emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks30out_layers0weight', 'model_ema.diffusion_modeloutput_blocks30out_layers0bias', 'model_ema.diffusion_modeloutput_blocks30out_layers3weight', 'model_ema.diffusion_modeloutput_blocks30out_layers3bias', 'model_ema.diffusion_modeloutput_blocks30skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks30skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks31normweight', 'model_ema.diffusion_modeloutput_blocks31normbias', 'model_ema.diffusion_modeloutput_blocks31proj_inweight', 'model_ema.diffusion_modeloutput_blocks31proj_inbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks31proj_outweight', 'model_ema.diffusion_modeloutput_blocks31proj_outbias', 'model_ema.diffusion_modeloutput_blocks40in_layers0weight', 'model_ema.diffusion_modeloutput_blocks40in_layers0bias', 'model_ema.diffusion_modeloutput_blocks40in_layers2weight', 'model_ema.diffusion_modeloutput_blocks40in_layers2bias', 'model_ema.diffusion_modeloutput_blocks40emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks40emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks40out_layers0weight', 'model_ema.diffusion_modeloutput_blocks40out_layers0bias', 'model_ema.diffusion_modeloutput_blocks40out_layers3weight', 'model_ema.diffusion_modeloutput_blocks40out_layers3bias', 'model_ema.diffusion_modeloutput_blocks40skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks40skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks41normweight', 'model_ema.diffusion_modeloutput_blocks41normbias', 'model_ema.diffusion_modeloutput_blocks41proj_inweight', 'model_ema.diffusion_modeloutput_blocks41proj_inbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks41proj_outweight', 'model_ema.diffusion_modeloutput_blocks41proj_outbias', 'model_ema.diffusion_modeloutput_blocks50in_layers0weight', 'model_ema.diffusion_modeloutput_blocks50in_layers0bias', 'model_ema.diffusion_modeloutput_blocks50in_layers2weight', 'model_ema.diffusion_modeloutput_blocks50in_layers2bias', 'model_ema.diffusion_modeloutput_blocks50emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks50emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks50out_layers0weight', 'model_ema.diffusion_modeloutput_blocks50out_layers0bias', 'model_ema.diffusion_modeloutput_blocks50out_layers3weight', 'model_ema.diffusion_modeloutput_blocks50out_layers3bias', 'model_ema.diffusion_modeloutput_blocks50skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks50skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks51normweight', 'model_ema.diffusion_modeloutput_blocks51normbias', 'model_ema.diffusion_modeloutput_blocks51proj_inweight', 'model_ema.diffusion_modeloutput_blocks51proj_inbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks51proj_outweight', 'model_ema.diffusion_modeloutput_blocks51proj_outbias', 'model_ema.diffusion_modeloutput_blocks52convweight', 'model_ema.diffusion_modeloutput_blocks52convbias', 'model_ema.diffusion_modeloutput_blocks60in_layers0weight', 'model_ema.diffusion_modeloutput_blocks60in_layers0bias', 'model_ema.diffusion_modeloutput_blocks60in_layers2weight', 'model_ema.diffusion_modeloutput_blocks60in_layers2bias', 'model_ema.diffusion_modeloutput_blocks60emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks60emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks60out_layers0weight', 'model_ema.diffusion_modeloutput_blocks60out_layers0bias', 'model_ema.diffusion_modeloutput_blocks60out_layers3weight', 'model_ema.diffusion_modeloutput_blocks60out_layers3bias', 'model_ema.diffusion_modeloutput_blocks60skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks60skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks61normweight', 'model_ema.diffusion_modeloutput_blocks61normbias', 'model_ema.diffusion_modeloutput_blocks61proj_inweight', 'model_ema.diffusion_modeloutput_blocks61proj_inbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks61proj_outweight', 'model_ema.diffusion_modeloutput_blocks61proj_outbias', 'model_ema.diffusion_modeloutput_blocks70in_layers0weight', 'model_ema.diffusion_modeloutput_blocks70in_layers0bias', 'model_ema.diffusion_modeloutput_blocks70in_layers2weight', 'model_ema.diffusion_modeloutput_blocks70in_layers2bias', 'model_ema.diffusion_modeloutput_blocks70emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks70emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks70out_layers0weight', 'model_ema.diffusion_modeloutput_blocks70out_layers0bias', 'model_ema.diffusion_modeloutput_blocks70out_layers3weight', 'model_ema.diffusion_modeloutput_blocks70out_layers3bias', 'model_ema.diffusion_modeloutput_blocks70skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks70skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks71normweight', 'model_ema.diffusion_modeloutput_blocks71normbias', 'model_ema.diffusion_modeloutput_blocks71proj_inweight', 'model_ema.diffusion_modeloutput_blocks71proj_inbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks71proj_outweight', 'model_ema.diffusion_modeloutput_blocks71proj_outbias', 'model_ema.diffusion_modeloutput_blocks80in_layers0weight', 'model_ema.diffusion_modeloutput_blocks80in_layers0bias', 'model_ema.diffusion_modeloutput_blocks80in_layers2weight', 'model_ema.diffusion_modeloutput_blocks80in_layers2bias', 'model_ema.diffusion_modeloutput_blocks80emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks80emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks80out_layers0weight', 'model_ema.diffusion_modeloutput_blocks80out_layers0bias', 'model_ema.diffusion_modeloutput_blocks80out_layers3weight', 'model_ema.diffusion_modeloutput_blocks80out_layers3bias', 'model_ema.diffusion_modeloutput_blocks80skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks80skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks81normweight', 'model_ema.diffusion_modeloutput_blocks81normbias', 'model_ema.diffusion_modeloutput_blocks81proj_inweight', 'model_ema.diffusion_modeloutput_blocks81proj_inbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks81proj_outweight', 'model_ema.diffusion_modeloutput_blocks81proj_outbias', 'model_ema.diffusion_modeloutput_blocks82convweight', 'model_ema.diffusion_modeloutput_blocks82convbias', 'model_ema.diffusion_modeloutput_blocks90in_layers0weight', 'model_ema.diffusion_modeloutput_blocks90in_layers0bias', 'model_ema.diffusion_modeloutput_blocks90in_layers2weight', 'model_ema.diffusion_modeloutput_blocks90in_layers2bias', 'model_ema.diffusion_modeloutput_blocks90emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks90emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks90out_layers0weight', 'model_ema.diffusion_modeloutput_blocks90out_layers0bias', 'model_ema.diffusion_modeloutput_blocks90out_layers3weight', 'model_ema.diffusion_modeloutput_blocks90out_layers3bias', 'model_ema.diffusion_modeloutput_blocks90skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks90skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks91normweight', 'model_ema.diffusion_modeloutput_blocks91normbias', 'model_ema.diffusion_modeloutput_blocks91proj_inweight', 'model_ema.diffusion_modeloutput_blocks91proj_inbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks91proj_outweight', 'model_ema.diffusion_modeloutput_blocks91proj_outbias', 'model_ema.diffusion_modeloutput_blocks100in_layers0weight', 'model_ema.diffusion_modeloutput_blocks100in_layers0bias', 'model_ema.diffusion_modeloutput_blocks100in_layers2weight', 'model_ema.diffusion_modeloutput_blocks100in_layers2bias', 'model_ema.diffusion_modeloutput_blocks100emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks100emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks100out_layers0weight', 'model_ema.diffusion_modeloutput_blocks100out_layers0bias', 'model_ema.diffusion_modeloutput_blocks100out_layers3weight', 'model_ema.diffusion_modeloutput_blocks100out_layers3bias', 'model_ema.diffusion_modeloutput_blocks100skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks100skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks101normweight', 'model_ema.diffusion_modeloutput_blocks101normbias', 'model_ema.diffusion_modeloutput_blocks101proj_inweight', 'model_ema.diffusion_modeloutput_blocks101proj_inbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks101proj_outweight', 'model_ema.diffusion_modeloutput_blocks101proj_outbias', 'model_ema.diffusion_modeloutput_blocks110in_layers0weight', 'model_ema.diffusion_modeloutput_blocks110in_layers0bias', 'model_ema.diffusion_modeloutput_blocks110in_layers2weight', 'model_ema.diffusion_modeloutput_blocks110in_layers2bias', 'model_ema.diffusion_modeloutput_blocks110emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks110emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks110out_layers0weight', 'model_ema.diffusion_modeloutput_blocks110out_layers0bias', 'model_ema.diffusion_modeloutput_blocks110out_layers3weight', 'model_ema.diffusion_modeloutput_blocks110out_layers3bias', 'model_ema.diffusion_modeloutput_blocks110skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks110skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks111normweight', 'model_ema.diffusion_modeloutput_blocks111normbias', 'model_ema.diffusion_modeloutput_blocks111proj_inweight', 'model_ema.diffusion_modeloutput_blocks111proj_inbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks111proj_outweight', 'model_ema.diffusion_modeloutput_blocks111proj_outbias', 'model_ema.diffusion_modelout0weight', 'model_ema.diffusion_modelout0bias', 'model_ema.diffusion_modelout2weight', 'model_ema.diffusion_modelout2bias', 'first_stage_model.encoder.conv_in.weight', 'first_stage_model.encoder.conv_in.bias', 'first_stage_model.encoder.down.0.block.0.norm1.weight', 'first_stage_model.encoder.down.0.block.0.norm1.bias', 'first_stage_model.encoder.down.0.block.0.conv1.weight', 'first_stage_model.encoder.down.0.block.0.conv1.bias', 'first_stage_model.encoder.down.0.block.0.norm2.weight', 'first_stage_model.encoder.down.0.block.0.norm2.bias', 'first_stage_model.encoder.down.0.block.0.conv2.weight', 'first_stage_model.encoder.down.0.block.0.conv2.bias', 'first_stage_model.encoder.down.0.block.1.norm1.weight', 'first_stage_model.encoder.down.0.block.1.norm1.bias', 'first_stage_model.encoder.down.0.block.1.conv1.weight', 'first_stage_model.encoder.down.0.block.1.conv1.bias', 'first_stage_model.encoder.down.0.block.1.norm2.weight', 'first_stage_model.encoder.down.0.block.1.norm2.bias', 'first_stage_model.encoder.down.0.block.1.conv2.weight', 'first_stage_model.encoder.down.0.block.1.conv2.bias', 'first_stage_model.encoder.down.0.downsample.conv.weight', 'first_stage_model.encoder.down.0.downsample.conv.bias', 'first_stage_model.encoder.down.1.block.0.norm1.weight', 'first_stage_model.encoder.down.1.block.0.norm1.bias', 'first_stage_model.encoder.down.1.block.0.conv1.weight', 'first_stage_model.encoder.down.1.block.0.conv1.bias', 'first_stage_model.encoder.down.1.block.0.norm2.weight', 'first_stage_model.encoder.down.1.block.0.norm2.bias', 'first_stage_model.encoder.down.1.block.0.conv2.weight', 'first_stage_model.encoder.down.1.block.0.conv2.bias', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.1.block.1.norm1.weight', 'first_stage_model.encoder.down.1.block.1.norm1.bias', 'first_stage_model.encoder.down.1.block.1.conv1.weight', 'first_stage_model.encoder.down.1.block.1.conv1.bias', 'first_stage_model.encoder.down.1.block.1.norm2.weight', 'first_stage_model.encoder.down.1.block.1.norm2.bias', 'first_stage_model.encoder.down.1.block.1.conv2.weight', 'first_stage_model.encoder.down.1.block.1.conv2.bias', 'first_stage_model.encoder.down.1.downsample.conv.weight', 'first_stage_model.encoder.down.1.downsample.conv.bias', 'first_stage_model.encoder.down.2.block.0.norm1.weight', 'first_stage_model.encoder.down.2.block.0.norm1.bias', 'first_stage_model.encoder.down.2.block.0.conv1.weight', 'first_stage_model.encoder.down.2.block.0.conv1.bias', 'first_stage_model.encoder.down.2.block.0.norm2.weight', 'first_stage_model.encoder.down.2.block.0.norm2.bias', 'first_stage_model.encoder.down.2.block.0.conv2.weight', 'first_stage_model.encoder.down.2.block.0.conv2.bias', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.2.block.1.norm1.weight', 'first_stage_model.encoder.down.2.block.1.norm1.bias', 'first_stage_model.encoder.down.2.block.1.conv1.weight', 'first_stage_model.encoder.down.2.block.1.conv1.bias', 'first_stage_model.encoder.down.2.block.1.norm2.weight', 'first_stage_model.encoder.down.2.block.1.norm2.bias', 'first_stage_model.encoder.down.2.block.1.conv2.weight', 'first_stage_model.encoder.down.2.block.1.conv2.bias', 'first_stage_model.encoder.down.2.downsample.conv.weight', 'first_stage_model.encoder.down.2.downsample.conv.bias', 'first_stage_model.encoder.down.3.block.0.norm1.weight', 'first_stage_model.encoder.down.3.block.0.norm1.bias', 'first_stage_model.encoder.down.3.block.0.conv1.weight', 'first_stage_model.encoder.down.3.block.0.conv1.bias', 'first_stage_model.encoder.down.3.block.0.norm2.weight', 'first_stage_model.encoder.down.3.block.0.norm2.bias', 'first_stage_model.encoder.down.3.block.0.conv2.weight', 'first_stage_model.encoder.down.3.block.0.conv2.bias', 'first_stage_model.encoder.down.3.block.1.norm1.weight', 'first_stage_model.encoder.down.3.block.1.norm1.bias', 'first_stage_model.encoder.down.3.block.1.conv1.weight', 'first_stage_model.encoder.down.3.block.1.conv1.bias', 'first_stage_model.encoder.down.3.block.1.norm2.weight', 'first_stage_model.encoder.down.3.block.1.norm2.bias', 'first_stage_model.encoder.down.3.block.1.conv2.weight', 'first_stage_model.encoder.down.3.block.1.conv2.bias', 'first_stage_model.encoder.mid.block_1.norm1.weight', 'first_stage_model.encoder.mid.block_1.norm1.bias', 'first_stage_model.encoder.mid.block_1.conv1.weight', 'first_stage_model.encoder.mid.block_1.conv1.bias', 'first_stage_model.encoder.mid.block_1.norm2.weight', 'first_stage_model.encoder.mid.block_1.norm2.bias', 'first_stage_model.encoder.mid.block_1.conv2.weight', 'first_stage_model.encoder.mid.block_1.conv2.bias', 'first_stage_model.encoder.mid.attn_1.norm.weight', 'first_stage_model.encoder.mid.attn_1.norm.bias', 'first_stage_model.encoder.mid.attn_1.q.weight', 'first_stage_model.encoder.mid.attn_1.q.bias', 'first_stage_model.encoder.mid.attn_1.k.weight', 'first_stage_model.encoder.mid.attn_1.k.bias', 'first_stage_model.encoder.mid.attn_1.v.weight', 'first_stage_model.encoder.mid.attn_1.v.bias', 'first_stage_model.encoder.mid.attn_1.proj_out.weight', 'first_stage_model.encoder.mid.attn_1.proj_out.bias', 'first_stage_model.encoder.mid.block_2.norm1.weight', 'first_stage_model.encoder.mid.block_2.norm1.bias', 'first_stage_model.encoder.mid.block_2.conv1.weight', 'first_stage_model.encoder.mid.block_2.conv1.bias', 'first_stage_model.encoder.mid.block_2.norm2.weight', 'first_stage_model.encoder.mid.block_2.norm2.bias', 'first_stage_model.encoder.mid.block_2.conv2.weight', 'first_stage_model.encoder.mid.block_2.conv2.bias', 'first_stage_model.encoder.norm_out.weight', 'first_stage_model.encoder.norm_out.bias', 'first_stage_model.encoder.conv_out.weight', 'first_stage_model.encoder.conv_out.bias', 'first_stage_model.decoder.conv_in.weight', 'first_stage_model.decoder.conv_in.bias', 'first_stage_model.decoder.mid.block_1.norm1.weight', 'first_stage_model.decoder.mid.block_1.norm1.bias', 'first_stage_model.decoder.mid.block_1.conv1.weight', 'first_stage_model.decoder.mid.block_1.conv1.bias', 'first_stage_model.decoder.mid.block_1.norm2.weight', 'first_stage_model.decoder.mid.block_1.norm2.bias', 'first_stage_model.decoder.mid.block_1.conv2.weight', 'first_stage_model.decoder.mid.block_1.conv2.bias', 'first_stage_model.decoder.mid.attn_1.norm.weight', 'first_stage_model.decoder.mid.attn_1.norm.bias', 'first_stage_model.decoder.mid.attn_1.q.weight', 'first_stage_model.decoder.mid.attn_1.q.bias', 'first_stage_model.decoder.mid.attn_1.k.weight', 'first_stage_model.decoder.mid.attn_1.k.bias', 'first_stage_model.decoder.mid.attn_1.v.weight', 'first_stage_model.decoder.mid.attn_1.v.bias', 'first_stage_model.decoder.mid.attn_1.proj_out.weight', 'first_stage_model.decoder.mid.attn_1.proj_out.bias', 'first_stage_model.decoder.mid.block_2.norm1.weight', 'first_stage_model.decoder.mid.block_2.norm1.bias', 'first_stage_model.decoder.mid.block_2.conv1.weight', 'first_stage_model.decoder.mid.block_2.conv1.bias', 'first_stage_model.decoder.mid.block_2.norm2.weight', 'first_stage_model.decoder.mid.block_2.norm2.bias', 'first_stage_model.decoder.mid.block_2.conv2.weight', 'first_stage_model.decoder.mid.block_2.conv2.bias', 'first_stage_model.decoder.up.0.block.0.norm1.weight', 'first_stage_model.decoder.up.0.block.0.norm1.bias', 'first_stage_model.decoder.up.0.block.0.conv1.weight', 'first_stage_model.decoder.up.0.block.0.conv1.bias', 'first_stage_model.decoder.up.0.block.0.norm2.weight', 'first_stage_model.decoder.up.0.block.0.norm2.bias', 'first_stage_model.decoder.up.0.block.0.conv2.weight', 'first_stage_model.decoder.up.0.block.0.conv2.bias', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.0.block.1.norm1.weight', 'first_stage_model.decoder.up.0.block.1.norm1.bias', 'first_stage_model.decoder.up.0.block.1.conv1.weight', 'first_stage_model.decoder.up.0.block.1.conv1.bias', 'first_stage_model.decoder.up.0.block.1.norm2.weight', 'first_stage_model.decoder.up.0.block.1.norm2.bias', 'first_stage_model.decoder.up.0.block.1.conv2.weight', 'first_stage_model.decoder.up.0.block.1.conv2.bias', 'first_stage_model.decoder.up.0.block.2.norm1.weight', 'first_stage_model.decoder.up.0.block.2.norm1.bias', 'first_stage_model.decoder.up.0.block.2.conv1.weight', 'first_stage_model.decoder.up.0.block.2.conv1.bias', 'first_stage_model.decoder.up.0.block.2.norm2.weight', 'first_stage_model.decoder.up.0.block.2.norm2.bias', 'first_stage_model.decoder.up.0.block.2.conv2.weight', 'first_stage_model.decoder.up.0.block.2.conv2.bias', 'first_stage_model.decoder.up.1.block.0.norm1.weight', 'first_stage_model.decoder.up.1.block.0.norm1.bias', 'first_stage_model.decoder.up.1.block.0.conv1.weight', 'first_stage_model.decoder.up.1.block.0.conv1.bias', 'first_stage_model.decoder.up.1.block.0.norm2.weight', 'first_stage_model.decoder.up.1.block.0.norm2.bias', 'first_stage_model.decoder.up.1.block.0.conv2.weight', 'first_stage_model.decoder.up.1.block.0.conv2.bias', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.1.block.1.norm1.weight', 'first_stage_model.decoder.up.1.block.1.norm1.bias', 'first_stage_model.decoder.up.1.block.1.conv1.weight', 'first_stage_model.decoder.up.1.block.1.conv1.bias', 'first_stage_model.decoder.up.1.block.1.norm2.weight', 'first_stage_model.decoder.up.1.block.1.norm2.bias', 'first_stage_model.decoder.up.1.block.1.conv2.weight', 'first_stage_model.decoder.up.1.block.1.conv2.bias', 'first_stage_model.decoder.up.1.block.2.norm1.weight', 'first_stage_model.decoder.up.1.block.2.norm1.bias', 'first_stage_model.decoder.up.1.block.2.conv1.weight', 'first_stage_model.decoder.up.1.block.2.conv1.bias', 'first_stage_model.decoder.up.1.block.2.norm2.weight', 'first_stage_model.decoder.up.1.block.2.norm2.bias', 'first_stage_model.decoder.up.1.block.2.conv2.weight', 'first_stage_model.decoder.up.1.block.2.conv2.bias', 'first_stage_model.decoder.up.1.upsample.conv.weight', 'first_stage_model.decoder.up.1.upsample.conv.bias', 'first_stage_model.decoder.up.2.block.0.norm1.weight', 'first_stage_model.decoder.up.2.block.0.norm1.bias', 'first_stage_model.decoder.up.2.block.0.conv1.weight', 'first_stage_model.decoder.up.2.block.0.conv1.bias', 'first_stage_model.decoder.up.2.block.0.norm2.weight', 'first_stage_model.decoder.up.2.block.0.norm2.bias', 'first_stage_model.decoder.up.2.block.0.conv2.weight', 'first_stage_model.decoder.up.2.block.0.conv2.bias', 'first_stage_model.decoder.up.2.block.1.norm1.weight', 'first_stage_model.decoder.up.2.block.1.norm1.bias', 'first_stage_model.decoder.up.2.block.1.conv1.weight', 'first_stage_model.decoder.up.2.block.1.conv1.bias', 'first_stage_model.decoder.up.2.block.1.norm2.weight', 'first_stage_model.decoder.up.2.block.1.norm2.bias', 'first_stage_model.decoder.up.2.block.1.conv2.weight', 'first_stage_model.decoder.up.2.block.1.conv2.bias', 'first_stage_model.decoder.up.2.block.2.norm1.weight', 'first_stage_model.decoder.up.2.block.2.norm1.bias', 'first_stage_model.decoder.up.2.block.2.conv1.weight', 'first_stage_model.decoder.up.2.block.2.conv1.bias', 'first_stage_model.decoder.up.2.block.2.norm2.weight', 'first_stage_model.decoder.up.2.block.2.norm2.bias', 'first_stage_model.decoder.up.2.block.2.conv2.weight', 'first_stage_model.decoder.up.2.block.2.conv2.bias', 'first_stage_model.decoder.up.2.upsample.conv.weight', 'first_stage_model.decoder.up.2.upsample.conv.bias', 'first_stage_model.decoder.up.3.block.0.norm1.weight', 'first_stage_model.decoder.up.3.block.0.norm1.bias', 'first_stage_model.decoder.up.3.block.0.conv1.weight', 'first_stage_model.decoder.up.3.block.0.conv1.bias', 'first_stage_model.decoder.up.3.block.0.norm2.weight', 'first_stage_model.decoder.up.3.block.0.norm2.bias', 'first_stage_model.decoder.up.3.block.0.conv2.weight', 'first_stage_model.decoder.up.3.block.0.conv2.bias', 'first_stage_model.decoder.up.3.block.1.norm1.weight', 'first_stage_model.decoder.up.3.block.1.norm1.bias', 'first_stage_model.decoder.up.3.block.1.conv1.weight', 'first_stage_model.decoder.up.3.block.1.conv1.bias', 'first_stage_model.decoder.up.3.block.1.norm2.weight', 'first_stage_model.decoder.up.3.block.1.norm2.bias', 'first_stage_model.decoder.up.3.block.1.conv2.weight', 'first_stage_model.decoder.up.3.block.1.conv2.bias', 'first_stage_model.decoder.up.3.block.2.norm1.weight', 'first_stage_model.decoder.up.3.block.2.norm1.bias', 'first_stage_model.decoder.up.3.block.2.conv1.weight', 'first_stage_model.decoder.up.3.block.2.conv1.bias', 'first_stage_model.decoder.up.3.block.2.norm2.weight', 'first_stage_model.decoder.up.3.block.2.norm2.bias', 'first_stage_model.decoder.up.3.block.2.conv2.weight', 'first_stage_model.decoder.up.3.block.2.conv2.bias', 'first_stage_model.decoder.up.3.upsample.conv.weight', 'first_stage_model.decoder.up.3.upsample.conv.bias', 'first_stage_model.decoder.norm_out.weight', 'first_stage_model.decoder.norm_out.bias', 'first_stage_model.decoder.conv_out.weight', 'first_stage_model.decoder.conv_out.bias', 'first_stage_model.quant_conv.weight', 'first_stage_model.quant_conv.bias', 'first_stage_model.post_quant_conv.weight', 'first_stage_model.post_quant_conv.bias', 'cond_stage_model.model.positional_embedding', 'cond_stage_model.model.text_projection', 'cond_stage_model.model.logit_scale', 'cond_stage_model.model.visual.class_embedding', 'cond_stage_model.model.visual.positional_embedding', 'cond_stage_model.model.visual.proj', 'cond_stage_model.model.visual.conv1.weight', 'cond_stage_model.model.visual.ln_pre.weight', 'cond_stage_model.model.visual.ln_pre.bias', 'cond_stage_model.model.visual.transformer.resblocks.0.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.0.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.0.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.0.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.0.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.0.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.0.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.0.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.1.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.1.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.1.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.1.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.1.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.1.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.1.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.1.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.2.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.2.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.2.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.2.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.2.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.2.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.2.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.2.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.3.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.3.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.3.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.3.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.3.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.3.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.3.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.3.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.4.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.4.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.4.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.4.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.4.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.4.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.4.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.4.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.5.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.5.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.5.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.5.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.5.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.5.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.5.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.5.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.6.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.6.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.6.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.6.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.6.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.6.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.6.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.6.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.7.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.7.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.7.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.7.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.7.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.7.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.7.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.7.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.8.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.8.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.8.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.8.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.8.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.8.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.8.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.8.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.9.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.9.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.9.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.9.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.9.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.9.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.9.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.9.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.10.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.10.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.10.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.10.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.10.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.10.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.10.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.10.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.11.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.11.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.11.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.11.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.11.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.11.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.11.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.11.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.12.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.12.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.12.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.12.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.12.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.12.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.12.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.12.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.12.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.12.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.12.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.12.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.13.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.13.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.13.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.13.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.13.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.13.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.13.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.13.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.13.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.13.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.13.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.13.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.14.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.14.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.14.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.14.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.14.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.14.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.14.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.14.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.14.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.14.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.14.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.14.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.15.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.15.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.15.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.15.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.15.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.15.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.15.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.15.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.15.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.15.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.15.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.15.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.16.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.16.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.16.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.16.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.16.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.16.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.16.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.16.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.16.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.16.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.16.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.16.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.17.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.17.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.17.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.17.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.17.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.17.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.17.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.17.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.17.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.17.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.17.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.17.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.18.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.18.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.18.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.18.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.18.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.18.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.18.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.18.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.18.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.18.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.18.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.18.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.19.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.19.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.19.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.19.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.19.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.19.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.19.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.19.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.19.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.19.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.19.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.19.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.20.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.20.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.20.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.20.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.20.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.20.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.20.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.20.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.20.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.20.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.20.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.20.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.21.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.21.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.21.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.21.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.21.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.21.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.21.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.21.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.21.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.21.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.21.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.21.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.22.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.22.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.22.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.22.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.22.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.22.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.22.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.22.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.22.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.22.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.22.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.22.ln_2.bias', 'cond_stage_model.model.visual.transformer.resblocks.23.attn.in_proj_weight', 'cond_stage_model.model.visual.transformer.resblocks.23.attn.in_proj_bias', 'cond_stage_model.model.visual.transformer.resblocks.23.attn.out_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.23.attn.out_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.23.ln_1.weight', 'cond_stage_model.model.visual.transformer.resblocks.23.ln_1.bias', 'cond_stage_model.model.visual.transformer.resblocks.23.mlp.c_fc.weight', 'cond_stage_model.model.visual.transformer.resblocks.23.mlp.c_fc.bias', 'cond_stage_model.model.visual.transformer.resblocks.23.mlp.c_proj.weight', 'cond_stage_model.model.visual.transformer.resblocks.23.mlp.c_proj.bias', 'cond_stage_model.model.visual.transformer.resblocks.23.ln_2.weight', 'cond_stage_model.model.visual.transformer.resblocks.23.ln_2.bias', 'cond_stage_model.model.visual.ln_post.weight', 'cond_stage_model.model.visual.ln_post.bias', 'cond_stage_model.model.token_embedding.weight', 'cond_stage_model.model.ln_final.weight', 'cond_stage_model.model.ln_final.bias', 'cc_projection.weight', 'cc_projection.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_v1['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d7864fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'model_ema.diffusion_model.input_blocks.0.0.weight' in ckpt['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3759312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_v2 = torch.load('/home/rliu/Desktop/cvfiler04/ruoshi/github/sjc/stable-diffusion/models/ldm/stable-diffusion-v1/sd-image-conditioned-v2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14800efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ckpt_v2['state_dict'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6e7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
