{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c551cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f1d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = '/local/vondrick/ruoshi/objaverse/views_whole_sphere'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e249060",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee399ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-9a652f559f71>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-9a652f559f71>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    self.paths = json.load(f)import clip\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class objaverse_sfm(Dataset):\n",
    "    def __init__(self, root_dir, total_view, train=True, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        with open(os.path.join(root_dir, 'valid_paths.json')) as f:\n",
    "            self.paths = json.load(f)import clip\n",
    "        random.shuffle(self.paths)\n",
    "        self.total_view = total_view\n",
    "        self.train = train\n",
    "        total_objects = len(self.paths)\n",
    "        if train:\n",
    "            self.paths = self.paths[:math.floor(total_objects / 100. * 99.)] # used first 99% as training|\n",
    "        else:\n",
    "            self.paths = self.paths[math.floor(total_objects / 100. * 99.):] # used last 1% as validation\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "        \n",
    "    def cartesian_to_spherical(self, xyz):\n",
    "        ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))\n",
    "        xy = xyz[:,0]**2 + xyz[:,1]**2\n",
    "        z = np.sqrt(xy + xyz[:,2]**2)\n",
    "        theta = np.arctan2(np.sqrt(xy), xyz[:,2]) # for elevation angle defined from Z-axis down\n",
    "        #ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy)) # for elevation angle defined from XY-plane up\n",
    "        azimuth = np.arctan2(xyz[:,1], xyz[:,0])\n",
    "        return np.array([theta, azimuth, z])\n",
    "\n",
    "    def get_T(self, target_RT, cond_RT):\n",
    "        R, T = target_RT[:3, :3], target_RT[:, -1]\n",
    "        T_target = -R.T @ T\n",
    "\n",
    "        R, T = cond_RT[:3, :3], cond_RT[:, -1]\n",
    "        T_cond = -R.T @ T\n",
    "\n",
    "        theta_cond, azimuth_cond, z_cond = self.cartesian_to_spherical(T_cond[None, :])\n",
    "        theta_target, azimuth_target, z_target = self.cartesian_to_spherical(T_target[None, :])\n",
    "        \n",
    "        d_theta = theta_target - theta_cond\n",
    "        d_azimuth = (azimuth_target - azimuth_cond) % (2 * math.pi)\n",
    "        d_z = z_target - z_cond\n",
    "        \n",
    "        d_T = torch.tensor([d_theta.item(), math.sin(d_azimuth.item()), math.cos(d_azimuth.item()), d_z.item()])\n",
    "#         d_T = torch.tensor([d_theta.item(), d_azimuth.item(), d_z.item()])\n",
    "        return d_T\n",
    "\n",
    "    def load_im(self, path):\n",
    "        '''\n",
    "        replace background pixel with white in rendering\n",
    "        '''\n",
    "        img = plt.imread(path)\n",
    "        img[img[:, :, -1] == 0.] = [1., 1., 1., 1.]\n",
    "        img = Image.fromarray(np.uint8(img[:, :, :3] * 255.))\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = {}\n",
    "        index_target, index_cond = random.sample(range(self.total_view), 2) # without replacement\n",
    "        filename = os.path.join(self.root_dir, self.paths[index])\n",
    "\n",
    "        # print(self.paths[index])\n",
    "\n",
    "#         if self.return_paths:\n",
    "#             data[\"path\"] = str(filename)\n",
    "            \n",
    "        target_im = self.process_im(self.load_im(os.path.join(filename, '%03d.png' % index_target)))\n",
    "        target_RT = np.load(os.path.join(filename, '%03d.npy' % index_target))\n",
    "        cond_im = self.process_im(self.load_im(os.path.join(filename, '%03d.png' % index_cond)))\n",
    "        cond_RT = np.load(os.path.join(filename, '%03d.npy' % index_cond))\n",
    "\n",
    "        data[\"image_target\"] = target_im\n",
    "        data[\"image_cond\"] = cond_im\n",
    "        data[\"T\"] = self.get_T(target_RT, cond_RT)\n",
    "        return data\n",
    "    \n",
    "    def process_im(self, im):\n",
    "        im = im.convert(\"RGB\")\n",
    "        im = self.transform(im)\n",
    "        im = torchvision.transforms.functional.resize(im, 224)\n",
    "        im = im * 2. - 1.\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ece0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = objaverse_sfm(dataset_root, 4, train=True, transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9763b7bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['image_target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96b1e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(objaverse_sfm(dataset_root, 4, train=True, transform = ToTensor()),\\\n",
    "                              batch_size=16, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(objaverse_sfm(dataset_root, 4, train=False, transform = ToTensor()),\\\n",
    "                             batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4058c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c57baf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['image_target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c1dbd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rliu/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05e861d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer3 = torch.nn.Sequential()\n",
    "model.layer4 = torch.nn.Sequential()\n",
    "model.fc = torch.nn.Sequential()\n",
    "model.avgpool = torch.nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a33bc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = model(image_cond.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f57aea72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100352])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70cc6bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 14, 14])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_layer(feature.reshape([64, 128, 28, 28])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9052aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_layer = torch.nn.Conv2d(256, 32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b915ab",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb126ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sfm(torch.nn.Module):\n",
    "    def __init__(self, resnet=True):\n",
    "        super(sfm, self).__init__()\n",
    "        \n",
    "        if resnet:\n",
    "            print('initializing resnet weights')\n",
    "            self.cnn = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "            self.cnn.conv1 = torch.nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.cnn.layer3 = torch.nn.Sequential()\n",
    "            self.cnn.layer4 = torch.nn.Sequential()\n",
    "            self.cnn.avgpool = torch.nn.Sequential()\n",
    "            self.cnn.fc = torch.nn.Sequential()\n",
    "            self.proj_layer = torch.nn.Conv2d(128, 16, 1, bias=False)\n",
    "            self.linear1 = torch.nn.Linear(12544, 64)\n",
    "            self.activation = torch.nn.ReLU()\n",
    "            self.linear2 = torch.nn.Linear(64, 4)\n",
    "    \n",
    "        else:\n",
    "            print('initializing vit weights')\n",
    "            self.cond_net = torchvision.models.vit_b_16(torchvision.models.ViT_B_16_Weights.DEFAULT)\n",
    "            self.cond_net.heads.head = torch.nn.Sequential()\n",
    "            self.target_net = torchvision.models.vit_b_16(torchvision.models.ViT_B_16_Weights.DEFAULT)\n",
    "            self.target_net.heads.head = torch.nn.Sequential()\n",
    "            self.linear1 = torch.nn.Linear(768 * 2, 768 * 2)\n",
    "            self.activation = torch.nn.ReLU()\n",
    "            self.linear2 = torch.nn.Linear(768 * 2, 768 * 2)\n",
    "            self.activation = torch.nn.ReLU()\n",
    "            self.linear3 = torch.nn.Linear(768 * 2, 4)\n",
    "\n",
    "    def forward(self, cond, target):\n",
    "        B = cond.shape[0]\n",
    "        x = torch.cat([cond, target], dim=1)\n",
    "        x = self.cnn(x)\n",
    "        x = self.proj_layer(x.reshape([B, 128, 28, 28]))\n",
    "        x = self.linear1(x.reshape(B, -1))\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d9cbf562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing resnet weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rliu/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = sfm(True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d9c81993",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_target, image_cond, T = batch['image_target'].to(device), batch['image_cond'].to(device), batch['T'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6b0be2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 224, 224]),\n",
       " torch.Size([64, 3, 224, 224]),\n",
       " torch.Size([64, 4]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_target.shape, image_cond.shape, T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "87630e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model(image_cond, image_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0469e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ((pred - T) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0fe180d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be0d1b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(objaverse_sfm(dataset_root, 4, train=True, transform = ToTensor()),\\\n",
    "#                               batch_size=64, shuffle=True, num_workers=8)\n",
    "# test_dataloader = DataLoader(objaverse_sfm(dataset_root, 4, train=False, transform = ToTensor()),\\\n",
    "#                              batch_size=64, shuffle=False, num_workers=8)\n",
    "# azimuth = []\n",
    "# sin = []\n",
    "# cos = []\n",
    "# for i, batch in tqdm(enumerate(train_dataloader, 0), total=50):\n",
    "#     sin.append(batch['T'][:, 1])\n",
    "#     cos.append(batch['T'][:, 2])\n",
    "#     if i == 50:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cd0ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(torch.cat(azimuth).numpy(), bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9c16b",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ffbe7f",
   "metadata": {},
   "source": [
    "## unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cafa4511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sh import gunzip\n",
    "# import json\n",
    "# from tqdm.notebook import tqdm\n",
    "# import os\n",
    "\n",
    "# path = '/home/rliu/Desktop/cvfiler04/datasets/objaverse/hf-objaverse-v1/views_whole_sphere'\n",
    "# with open('/home/rliu/Desktop/cvfiler04/datasets/objaverse/hf-objaverse-v1/views_whole_sphere/valid_paths.json') as f:\n",
    "#     paths = json.load(f)\n",
    "# total_view = 4\n",
    "# gz = []\n",
    "# for i, id in tqdm(enumerate(paths), total = len(paths)):\n",
    "#     for filename in os.listdir(os.path.join(path, id)):\n",
    "        \n",
    "#         if 'gz' in filename:\n",
    "# #             print(filename[:-3])\n",
    "#             gz.append(id)\n",
    "# #             gunzip(os.path.join(path, id, filename[:-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9631a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c92b4ede",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing resnet weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rliu/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/rliu/ruoshi/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== total trainable parameters: 7119620 ==================\n",
      "\n",
      "cnn.conv1.weight torch.Size([64, 6, 7, 7])\n",
      "cnn.bn1.weight torch.Size([64])\n",
      "cnn.bn1.bias torch.Size([64])\n",
      "cnn.layer1.0.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "cnn.layer1.0.bn1.weight torch.Size([64])\n",
      "cnn.layer1.0.bn1.bias torch.Size([64])\n",
      "cnn.layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "cnn.layer1.0.bn2.weight torch.Size([64])\n",
      "cnn.layer1.0.bn2.bias torch.Size([64])\n",
      "cnn.layer1.1.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "cnn.layer1.1.bn1.weight torch.Size([64])\n",
      "cnn.layer1.1.bn1.bias torch.Size([64])\n",
      "cnn.layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "cnn.layer1.1.bn2.weight torch.Size([64])\n",
      "cnn.layer1.1.bn2.bias torch.Size([64])\n",
      "cnn.layer2.0.conv1.weight torch.Size([128, 64, 3, 3])\n",
      "cnn.layer2.0.bn1.weight torch.Size([128])\n",
      "cnn.layer2.0.bn1.bias torch.Size([128])\n",
      "cnn.layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "cnn.layer2.0.bn2.weight torch.Size([128])\n",
      "cnn.layer2.0.bn2.bias torch.Size([128])\n",
      "cnn.layer2.0.downsample.0.weight torch.Size([128, 64, 1, 1])\n",
      "cnn.layer2.0.downsample.1.weight torch.Size([128])\n",
      "cnn.layer2.0.downsample.1.bias torch.Size([128])\n",
      "cnn.layer2.1.conv1.weight torch.Size([128, 128, 3, 3])\n",
      "cnn.layer2.1.bn1.weight torch.Size([128])\n",
      "cnn.layer2.1.bn1.bias torch.Size([128])\n",
      "cnn.layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "cnn.layer2.1.bn2.weight torch.Size([128])\n",
      "cnn.layer2.1.bn2.bias torch.Size([128])\n",
      "proj_layer.weight torch.Size([16, 128, 1, 1])\n",
      "linear1.weight torch.Size([512, 12544])\n",
      "linear1.bias torch.Size([512])\n",
      "linear2.weight torch.Size([4, 512])\n",
      "linear2.bias torch.Size([4])\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4407af8d704745eab4a78e11d87f4daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 0: tensor([0.7636, 0.6330, 0.6397, 0.2344]) 2.270752014297795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37282d2fd4c344cdad1f8a0d4e5c5f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.5953, 0.6398, 0.6284, 0.1781]) tensor(2.0416)\n",
      "[200, 400] loss:  tensor([0.5148, 0.6355, 0.6172, 0.1466]) tensor(1.9140)\n",
      "[400, 600] loss:  tensor([0.4828, 0.6350, 0.6103, 0.1360]) tensor(1.8641)\n",
      "[600, 800] loss:  tensor([0.4695, 0.6313, 0.6047, 0.1338]) tensor(1.8392)\n",
      "[800, 1000] loss:  tensor([0.4560, 0.6326, 0.5991, 0.1297]) tensor(1.8174)\n",
      "[1000, 1200] loss:  tensor([0.4477, 0.6293, 0.5951, 0.1281]) tensor(1.8002)\n",
      "[1200, 1400] loss:  tensor([0.4383, 0.6262, 0.5950, 0.1265]) tensor(1.7860)\n",
      "[1400, 1600] loss:  tensor([0.4358, 0.6321, 0.5838, 0.1255]) tensor(1.7771)\n",
      "[1600, 1800] loss:  tensor([0.4374, 0.6255, 0.5828, 0.1229]) tensor(1.7687)\n",
      "[1800, 2000] loss:  tensor([0.4258, 0.6270, 0.5788, 0.1228]) tensor(1.7544)\n",
      "[2000, 2200] loss:  tensor([0.4223, 0.6286, 0.5742, 0.1212]) tensor(1.7462)\n",
      "[2200, 2400] loss:  tensor([0.4162, 0.6238, 0.5681, 0.1213]) tensor(1.7294)\n",
      "[2400, 2600] loss:  tensor([0.4126, 0.6215, 0.5661, 0.1203]) tensor(1.7204)\n",
      "[2600, 2800] loss:  tensor([0.4192, 0.6215, 0.5671, 0.1203]) tensor(1.7281)\n",
      "[2800, 3000] loss:  tensor([0.4089, 0.6175, 0.5644, 0.1190]) tensor(1.7098)\n",
      "[3000, 3200] loss:  tensor([0.4050, 0.6199, 0.5609, 0.1185]) tensor(1.7044)\n",
      "[3200, 3400] loss:  tensor([0.4004, 0.6156, 0.5652, 0.1183]) tensor(1.6995)\n",
      "[3400, 3600] loss:  tensor([0.4084, 0.6153, 0.5640, 0.1178]) tensor(1.7054)\n",
      "[3600, 3800] loss:  tensor([0.4035, 0.6143, 0.5571, 0.1170]) tensor(1.6919)\n",
      "[3800, 4000] loss:  tensor([0.3981, 0.6147, 0.5532, 0.1179]) tensor(1.6839)\n",
      "[4000, 4200] loss:  tensor([0.4035, 0.6139, 0.5536, 0.1173]) tensor(1.6882)\n",
      "[4200, 4400] loss:  tensor([0.3977, 0.6077, 0.5566, 0.1165]) tensor(1.6785)\n",
      "[4400, 4600] loss:  tensor([0.3910, 0.6084, 0.5534, 0.1156]) tensor(1.6684)\n",
      "[4600, 4800] loss:  tensor([0.3916, 0.6114, 0.5507, 0.1150]) tensor(1.6687)\n",
      "[4800, 5000] loss:  tensor([0.3949, 0.6071, 0.5527, 0.1149]) tensor(1.6696)\n",
      "[5000, 5200] loss:  tensor([0.3947, 0.6078, 0.5487, 0.1146]) tensor(1.6658)\n",
      "[5200, 5400] loss:  tensor([0.3866, 0.6048, 0.5489, 0.1144]) tensor(1.6548)\n",
      "[5400, 5600] loss:  tensor([0.3921, 0.6025, 0.5458, 0.1132]) tensor(1.6536)\n",
      "[5600, 5800] loss:  tensor([0.3928, 0.6075, 0.5421, 0.1144]) tensor(1.6569)\n",
      "[5800, 6000] loss:  tensor([0.3849, 0.6062, 0.5424, 0.1131]) tensor(1.6466)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b764ed853e0463eb489ac7c50b9106c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 1: tensor([0.4195, 0.6087, 0.5526, 0.2309]) 1.811702918480644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57dfd9ed96134914baf82d63f57381a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3850, 0.6010, 0.5437, 0.1126]) tensor(1.6423)\n",
      "[200, 400] loss:  tensor([0.3866, 0.6002, 0.5440, 0.1131]) tensor(1.6438)\n",
      "[400, 600] loss:  tensor([0.3775, 0.6030, 0.5388, 0.1130]) tensor(1.6323)\n",
      "[600, 800] loss:  tensor([0.3840, 0.5988, 0.5410, 0.1127]) tensor(1.6364)\n",
      "[800, 1000] loss:  tensor([0.3812, 0.6003, 0.5376, 0.1117]) tensor(1.6308)\n",
      "[1000, 1200] loss:  tensor([0.3830, 0.5940, 0.5420, 0.1122]) tensor(1.6313)\n",
      "[1200, 1400] loss:  tensor([0.3773, 0.6004, 0.5339, 0.1112]) tensor(1.6227)\n",
      "[1400, 1600] loss:  tensor([0.3777, 0.5970, 0.5390, 0.1112]) tensor(1.6248)\n",
      "[1600, 1800] loss:  tensor([0.3753, 0.5954, 0.5376, 0.1107]) tensor(1.6189)\n",
      "[1800, 2000] loss:  tensor([0.3797, 0.5929, 0.5349, 0.1112]) tensor(1.6187)\n",
      "[2000, 2200] loss:  tensor([0.3777, 0.5925, 0.5380, 0.1116]) tensor(1.6197)\n",
      "[2200, 2400] loss:  tensor([0.3718, 0.5960, 0.5295, 0.1103]) tensor(1.6075)\n",
      "[2400, 2600] loss:  tensor([0.3739, 0.5967, 0.5301, 0.1109]) tensor(1.6116)\n",
      "[2600, 2800] loss:  tensor([0.3704, 0.5942, 0.5310, 0.1103]) tensor(1.6059)\n",
      "[2800, 3000] loss:  tensor([0.3715, 0.5918, 0.5334, 0.1102]) tensor(1.6070)\n",
      "[3000, 3200] loss:  tensor([0.3709, 0.5912, 0.5310, 0.1098]) tensor(1.6028)\n",
      "[3200, 3400] loss:  tensor([0.3717, 0.5942, 0.5278, 0.1114]) tensor(1.6051)\n",
      "[3400, 3600] loss:  tensor([0.3702, 0.5924, 0.5288, 0.1098]) tensor(1.6011)\n",
      "[3600, 3800] loss:  tensor([0.3745, 0.5888, 0.5269, 0.1114]) tensor(1.6017)\n",
      "[3800, 4000] loss:  tensor([0.3679, 0.5919, 0.5306, 0.1108]) tensor(1.6012)\n",
      "[4000, 4200] loss:  tensor([0.3628, 0.5916, 0.5291, 0.1090]) tensor(1.5926)\n",
      "[4200, 4400] loss:  tensor([0.3675, 0.5864, 0.5288, 0.1097]) tensor(1.5924)\n",
      "[4400, 4600] loss:  tensor([0.3715, 0.5863, 0.5270, 0.1088]) tensor(1.5936)\n",
      "[4600, 4800] loss:  tensor([0.3649, 0.5875, 0.5291, 0.1103]) tensor(1.5918)\n",
      "[4800, 5000] loss:  tensor([0.3649, 0.5859, 0.5229, 0.1095]) tensor(1.5832)\n",
      "[5000, 5200] loss:  tensor([0.3650, 0.5873, 0.5271, 0.1096]) tensor(1.5890)\n",
      "[5200, 5400] loss:  tensor([0.3647, 0.5785, 0.5250, 0.1078]) tensor(1.5760)\n",
      "[5400, 5600] loss:  tensor([0.3637, 0.5837, 0.5228, 0.1073]) tensor(1.5774)\n",
      "[5600, 5800] loss:  tensor([0.3648, 0.5860, 0.5259, 0.1093]) tensor(1.5860)\n",
      "[5800, 6000] loss:  tensor([0.3606, 0.5850, 0.5216, 0.1075]) tensor(1.5747)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2367d91db394b75b9eff5490740b319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 2: tensor([0.4877, 0.6083, 0.5486, 0.5075]) 2.1520391094807065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8122e1f541c74b418ebbddd10f30e44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3569, 0.5815, 0.5173, 0.1075]) tensor(1.5632)\n",
      "[200, 400] loss:  tensor([0.3636, 0.5806, 0.5212, 0.1075]) tensor(1.5729)\n",
      "[400, 600] loss:  tensor([0.3611, 0.5778, 0.5191, 0.1079]) tensor(1.5659)\n",
      "[600, 800] loss:  tensor([0.3611, 0.5778, 0.5184, 0.1077]) tensor(1.5651)\n",
      "[800, 1000] loss:  tensor([0.3601, 0.5769, 0.5180, 0.1089]) tensor(1.5639)\n",
      "[1000, 1200] loss:  tensor([0.3602, 0.5765, 0.5193, 0.1073]) tensor(1.5632)\n",
      "[1200, 1400] loss:  tensor([0.3605, 0.5797, 0.5212, 0.1077]) tensor(1.5691)\n",
      "[1400, 1600] loss:  tensor([0.3590, 0.5776, 0.5180, 0.1074]) tensor(1.5619)\n",
      "[1600, 1800] loss:  tensor([0.3642, 0.5786, 0.5194, 0.1082]) tensor(1.5704)\n",
      "[1800, 2000] loss:  tensor([0.3600, 0.5774, 0.5192, 0.1075]) tensor(1.5642)\n",
      "[2000, 2200] loss:  tensor([0.3562, 0.5806, 0.5186, 0.1075]) tensor(1.5630)\n",
      "[2200, 2400] loss:  tensor([0.3575, 0.5752, 0.5201, 0.1072]) tensor(1.5599)\n",
      "[2400, 2600] loss:  tensor([0.3575, 0.5794, 0.5162, 0.1076]) tensor(1.5607)\n",
      "[2600, 2800] loss:  tensor([0.3526, 0.5792, 0.5160, 0.1075]) tensor(1.5553)\n",
      "[2800, 3000] loss:  tensor([0.3590, 0.5752, 0.5184, 0.1075]) tensor(1.5602)\n",
      "[3000, 3200] loss:  tensor([0.3595, 0.5731, 0.5169, 0.1079]) tensor(1.5573)\n",
      "[3200, 3400] loss:  tensor([0.3566, 0.5772, 0.5128, 0.1071]) tensor(1.5538)\n",
      "[3400, 3600] loss:  tensor([0.3532, 0.5731, 0.5148, 0.1067]) tensor(1.5478)\n",
      "[3600, 3800] loss:  tensor([0.3586, 0.5760, 0.5144, 0.1075]) tensor(1.5565)\n",
      "[3800, 4000] loss:  tensor([0.3509, 0.5767, 0.5131, 0.1057]) tensor(1.5465)\n",
      "[4000, 4200] loss:  tensor([0.3551, 0.5731, 0.5121, 0.1079]) tensor(1.5483)\n",
      "[4200, 4400] loss:  tensor([0.3528, 0.5715, 0.5149, 0.1076]) tensor(1.5468)\n",
      "[4400, 4600] loss:  tensor([0.3542, 0.5728, 0.5115, 0.1071]) tensor(1.5456)\n",
      "[4600, 4800] loss:  tensor([0.3529, 0.5684, 0.5141, 0.1065]) tensor(1.5419)\n",
      "[4800, 5000] loss:  tensor([0.3492, 0.5711, 0.5122, 0.1067]) tensor(1.5392)\n",
      "[5000, 5200] loss:  tensor([0.3517, 0.5691, 0.5107, 0.1063]) tensor(1.5378)\n",
      "[5200, 5400] loss:  tensor([0.3498, 0.5664, 0.5117, 0.1056]) tensor(1.5334)\n",
      "[5400, 5600] loss:  tensor([0.3502, 0.5744, 0.5103, 0.1072]) tensor(1.5421)\n",
      "[5600, 5800] loss:  tensor([0.3508, 0.5696, 0.5130, 0.1064]) tensor(1.5398)\n",
      "[5800, 6000] loss:  tensor([0.3487, 0.5705, 0.5092, 0.1071]) tensor(1.5356)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba863af4b8d4336a0e4b5c7ecdb993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 3: tensor([0.5996, 0.6095, 0.5509, 0.5984]) 2.358358797528815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f6f6188ef64e99821e00ee2409daa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3499, 0.5658, 0.5133, 0.1057]) tensor(1.5347)\n",
      "[200, 400] loss:  tensor([0.3494, 0.5659, 0.5086, 0.1069]) tensor(1.5308)\n",
      "[400, 600] loss:  tensor([0.3466, 0.5689, 0.5102, 0.1050]) tensor(1.5306)\n",
      "[600, 800] loss:  tensor([0.3520, 0.5691, 0.5068, 0.1061]) tensor(1.5340)\n",
      "[800, 1000] loss:  tensor([0.3481, 0.5686, 0.5061, 0.1049]) tensor(1.5277)\n",
      "[1000, 1200] loss:  tensor([0.3474, 0.5681, 0.5047, 0.1053]) tensor(1.5255)\n",
      "[1200, 1400] loss:  tensor([0.3495, 0.5670, 0.5100, 0.1060]) tensor(1.5325)\n",
      "[1400, 1600] loss:  tensor([0.3460, 0.5627, 0.5085, 0.1059]) tensor(1.5231)\n",
      "[1600, 1800] loss:  tensor([0.3412, 0.5601, 0.5085, 0.1053]) tensor(1.5151)\n",
      "[1800, 2000] loss:  tensor([0.3463, 0.5639, 0.5062, 0.1058]) tensor(1.5223)\n",
      "[2000, 2200] loss:  tensor([0.3438, 0.5621, 0.5064, 0.1058]) tensor(1.5181)\n",
      "[2200, 2400] loss:  tensor([0.3482, 0.5655, 0.5054, 0.1056]) tensor(1.5247)\n",
      "[2400, 2600] loss:  tensor([0.3448, 0.5640, 0.5032, 0.1051]) tensor(1.5172)\n",
      "[2600, 2800] loss:  tensor([0.3427, 0.5651, 0.5031, 0.1052]) tensor(1.5161)\n",
      "[2800, 3000] loss:  tensor([0.3437, 0.5624, 0.5036, 0.1043]) tensor(1.5139)\n",
      "[3000, 3200] loss:  tensor([0.3509, 0.5631, 0.5043, 0.1057]) tensor(1.5241)\n",
      "[3200, 3400] loss:  tensor([0.3458, 0.5616, 0.5063, 0.1045]) tensor(1.5182)\n",
      "[3400, 3600] loss:  tensor([0.3419, 0.5650, 0.5037, 0.1052]) tensor(1.5158)\n",
      "[3600, 3800] loss:  tensor([0.3448, 0.5621, 0.5024, 0.1049]) tensor(1.5142)\n",
      "[3800, 4000] loss:  tensor([0.3443, 0.5565, 0.4999, 0.1045]) tensor(1.5052)\n",
      "[4000, 4200] loss:  tensor([0.3497, 0.5624, 0.5066, 0.1066]) tensor(1.5253)\n",
      "[4200, 4400] loss:  tensor([0.3445, 0.5590, 0.5050, 0.1054]) tensor(1.5139)\n",
      "[4400, 4600] loss:  tensor([0.3436, 0.5565, 0.5016, 0.1038]) tensor(1.5055)\n",
      "[4600, 4800] loss:  tensor([0.3458, 0.5588, 0.5045, 0.1049]) tensor(1.5141)\n",
      "[4800, 5000] loss:  tensor([0.3454, 0.5602, 0.4970, 0.1054]) tensor(1.5080)\n",
      "[5000, 5200] loss:  tensor([0.3468, 0.5555, 0.4979, 0.1052]) tensor(1.5054)\n",
      "[5200, 5400] loss:  tensor([0.3418, 0.5577, 0.4999, 0.1049]) tensor(1.5044)\n",
      "[5400, 5600] loss:  tensor([0.3438, 0.5580, 0.5047, 0.1046]) tensor(1.5112)\n",
      "[5600, 5800] loss:  tensor([0.3380, 0.5605, 0.5025, 0.1049]) tensor(1.5058)\n",
      "[5800, 6000] loss:  tensor([0.3396, 0.5610, 0.4973, 0.1043]) tensor(1.5023)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e661b0afb5a464ca1d0ede1fb2b81b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 4: tensor([0.4775, 0.6060, 0.5462, 0.5592]) 2.188898165403408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bdefd91ac341b198394206f26db5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3369, 0.5574, 0.4969, 0.1045]) tensor(1.4957)\n",
      "[200, 400] loss:  tensor([0.3353, 0.5606, 0.4971, 0.1052]) tensor(1.4982)\n",
      "[400, 600] loss:  tensor([0.3399, 0.5559, 0.4980, 0.1062]) tensor(1.5000)\n",
      "[600, 800] loss:  tensor([0.3420, 0.5570, 0.5014, 0.1045]) tensor(1.5050)\n",
      "[800, 1000] loss:  tensor([0.3414, 0.5540, 0.5033, 0.1045]) tensor(1.5032)\n",
      "[1000, 1200] loss:  tensor([0.3367, 0.5559, 0.4967, 0.1037]) tensor(1.4929)\n",
      "[1200, 1400] loss:  tensor([0.3420, 0.5531, 0.4979, 0.1056]) tensor(1.4986)\n",
      "[1400, 1600] loss:  tensor([0.3332, 0.5548, 0.4960, 0.1035]) tensor(1.4875)\n",
      "[1600, 1800] loss:  tensor([0.3358, 0.5534, 0.4987, 0.1052]) tensor(1.4931)\n",
      "[1800, 2000] loss:  tensor([0.3408, 0.5569, 0.4987, 0.1041]) tensor(1.5004)\n",
      "[2000, 2200] loss:  tensor([0.3371, 0.5548, 0.4991, 0.1032]) tensor(1.4943)\n",
      "[2200, 2400] loss:  tensor([0.3379, 0.5556, 0.4957, 0.1035]) tensor(1.4927)\n",
      "[2400, 2600] loss:  tensor([0.3398, 0.5518, 0.4917, 0.1038]) tensor(1.4871)\n",
      "[2600, 2800] loss:  tensor([0.3349, 0.5500, 0.4926, 0.1042]) tensor(1.4817)\n",
      "[2800, 3000] loss:  tensor([0.3389, 0.5509, 0.4949, 0.1047]) tensor(1.4895)\n",
      "[3000, 3200] loss:  tensor([0.3361, 0.5565, 0.4947, 0.1044]) tensor(1.4918)\n",
      "[3200, 3400] loss:  tensor([0.3384, 0.5528, 0.4925, 0.1042]) tensor(1.4879)\n",
      "[3400, 3600] loss:  tensor([0.3436, 0.5529, 0.4964, 0.1048]) tensor(1.4976)\n",
      "[3600, 3800] loss:  tensor([0.3341, 0.5525, 0.4990, 0.1034]) tensor(1.4890)\n",
      "[3800, 4000] loss:  tensor([0.3390, 0.5511, 0.4964, 0.1038]) tensor(1.4903)\n",
      "[4000, 4200] loss:  tensor([0.3344, 0.5510, 0.4943, 0.1044]) tensor(1.4842)\n",
      "[4200, 4400] loss:  tensor([0.3389, 0.5534, 0.4924, 0.1034]) tensor(1.4882)\n",
      "[4400, 4600] loss:  tensor([0.3363, 0.5549, 0.4884, 0.1031]) tensor(1.4827)\n",
      "[4600, 4800] loss:  tensor([0.3326, 0.5483, 0.4948, 0.1035]) tensor(1.4792)\n",
      "[4800, 5000] loss:  tensor([0.3348, 0.5501, 0.4934, 0.1044]) tensor(1.4827)\n",
      "[5000, 5200] loss:  tensor([0.3336, 0.5551, 0.4915, 0.1041]) tensor(1.4843)\n",
      "[5200, 5400] loss:  tensor([0.3359, 0.5570, 0.4907, 0.1040]) tensor(1.4875)\n",
      "[5400, 5600] loss:  tensor([0.3367, 0.5486, 0.4940, 0.1035]) tensor(1.4827)\n",
      "[5600, 5800] loss:  tensor([0.3373, 0.5513, 0.4907, 0.1033]) tensor(1.4826)\n",
      "[5800, 6000] loss:  tensor([0.3353, 0.5511, 0.4898, 0.1031]) tensor(1.4793)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edc79a8af074ceea1beff0b4df47c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 5: tensor([0.5046, 0.5968, 0.5500, 0.4642]) 2.1156620951829117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21396e91459545f096293876a26ddc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3324, 0.5473, 0.4899, 0.1033]) tensor(1.4730)\n",
      "[200, 400] loss:  tensor([0.3358, 0.5446, 0.4898, 0.1027]) tensor(1.4729)\n",
      "[400, 600] loss:  tensor([0.3350, 0.5498, 0.4870, 0.1039]) tensor(1.4757)\n",
      "[600, 800] loss:  tensor([0.3311, 0.5475, 0.4916, 0.1032]) tensor(1.4733)\n",
      "[800, 1000] loss:  tensor([0.3306, 0.5513, 0.4911, 0.1028]) tensor(1.4758)\n",
      "[1000, 1200] loss:  tensor([0.3329, 0.5499, 0.4936, 0.1036]) tensor(1.4799)\n",
      "[1200, 1400] loss:  tensor([0.3331, 0.5453, 0.4911, 0.1035]) tensor(1.4729)\n",
      "[1400, 1600] loss:  tensor([0.3317, 0.5494, 0.4925, 0.1036]) tensor(1.4772)\n",
      "[1600, 1800] loss:  tensor([0.3324, 0.5459, 0.4930, 0.1035]) tensor(1.4748)\n",
      "[1800, 2000] loss:  tensor([0.3285, 0.5456, 0.4911, 0.1038]) tensor(1.4689)\n",
      "[2000, 2200] loss:  tensor([0.3273, 0.5474, 0.4876, 0.1033]) tensor(1.4656)\n",
      "[2200, 2400] loss:  tensor([0.3345, 0.5444, 0.4878, 0.1020]) tensor(1.4686)\n",
      "[2400, 2600] loss:  tensor([0.3318, 0.5465, 0.4874, 0.1031]) tensor(1.4688)\n",
      "[2600, 2800] loss:  tensor([0.3254, 0.5473, 0.4878, 0.1037]) tensor(1.4642)\n",
      "[2800, 3000] loss:  tensor([0.3290, 0.5469, 0.4871, 0.1018]) tensor(1.4648)\n",
      "[3000, 3200] loss:  tensor([0.3324, 0.5491, 0.4874, 0.1034]) tensor(1.4723)\n",
      "[3200, 3400] loss:  tensor([0.3304, 0.5449, 0.4890, 0.1025]) tensor(1.4668)\n",
      "[3400, 3600] loss:  tensor([0.3316, 0.5437, 0.4887, 0.1022]) tensor(1.4663)\n",
      "[3600, 3800] loss:  tensor([0.3313, 0.5437, 0.4857, 0.1034]) tensor(1.4641)\n",
      "[3800, 4000] loss:  tensor([0.3296, 0.5435, 0.4893, 0.1025]) tensor(1.4649)\n",
      "[4000, 4200] loss:  tensor([0.3331, 0.5426, 0.4910, 0.1037]) tensor(1.4704)\n",
      "[4200, 4400] loss:  tensor([0.3267, 0.5439, 0.4851, 0.1038]) tensor(1.4594)\n",
      "[4400, 4600] loss:  tensor([0.3235, 0.5435, 0.4856, 0.1032]) tensor(1.4558)\n",
      "[4600, 4800] loss:  tensor([0.3287, 0.5469, 0.4873, 0.1030]) tensor(1.4660)\n",
      "[4800, 5000] loss:  tensor([0.3292, 0.5400, 0.4903, 0.1036]) tensor(1.4632)\n",
      "[5000, 5200] loss:  tensor([0.3285, 0.5402, 0.4891, 0.1025]) tensor(1.4604)\n",
      "[5200, 5400] loss:  tensor([0.3311, 0.5437, 0.4888, 0.1021]) tensor(1.4657)\n",
      "[5400, 5600] loss:  tensor([0.3293, 0.5405, 0.4882, 0.1026]) tensor(1.4606)\n",
      "[5600, 5800] loss:  tensor([0.3300, 0.5422, 0.4875, 0.1023]) tensor(1.4621)\n",
      "[5800, 6000] loss:  tensor([0.3295, 0.5453, 0.4843, 0.1031]) tensor(1.4621)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72cdbb50f8d64b06902f1eb92d3a8429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 6: tensor([0.5113, 0.5948, 0.5392, 0.4530]) 2.0983609605988476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc41b68c8c1046f684fd19fdae823e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3254, 0.5412, 0.4848, 0.1023]) tensor(1.4537)\n",
      "[200, 400] loss:  tensor([0.3267, 0.5376, 0.4862, 0.1020]) tensor(1.4525)\n",
      "[400, 600] loss:  tensor([0.3289, 0.5411, 0.4783, 0.1024]) tensor(1.4507)\n",
      "[600, 800] loss:  tensor([0.3272, 0.5439, 0.4840, 0.1025]) tensor(1.4575)\n",
      "[800, 1000] loss:  tensor([0.3244, 0.5426, 0.4852, 0.1025]) tensor(1.4547)\n",
      "[1000, 1200] loss:  tensor([0.3277, 0.5404, 0.4875, 0.1018]) tensor(1.4574)\n",
      "[1200, 1400] loss:  tensor([0.3214, 0.5435, 0.4869, 0.1015]) tensor(1.4533)\n",
      "[1400, 1600] loss:  tensor([0.3295, 0.5430, 0.4834, 0.1033]) tensor(1.4592)\n",
      "[1600, 1800] loss:  tensor([0.3226, 0.5374, 0.4848, 0.1025]) tensor(1.4473)\n",
      "[1800, 2000] loss:  tensor([0.3283, 0.5392, 0.4870, 0.1022]) tensor(1.4566)\n",
      "[2000, 2200] loss:  tensor([0.3275, 0.5370, 0.4842, 0.1028]) tensor(1.4516)\n",
      "[2200, 2400] loss:  tensor([0.3283, 0.5404, 0.4866, 0.1034]) tensor(1.4587)\n",
      "[2400, 2600] loss:  tensor([0.3241, 0.5402, 0.4844, 0.1022]) tensor(1.4509)\n",
      "[2600, 2800] loss:  tensor([0.3261, 0.5395, 0.4788, 0.1020]) tensor(1.4464)\n",
      "[2800, 3000] loss:  tensor([0.3258, 0.5387, 0.4812, 0.1018]) tensor(1.4475)\n",
      "[3000, 3200] loss:  tensor([0.3217, 0.5340, 0.4812, 0.1019]) tensor(1.4388)\n",
      "[3200, 3400] loss:  tensor([0.3252, 0.5427, 0.4811, 0.1033]) tensor(1.4523)\n",
      "[3400, 3600] loss:  tensor([0.3273, 0.5393, 0.4836, 0.1030]) tensor(1.4532)\n",
      "[3600, 3800] loss:  tensor([0.3254, 0.5417, 0.4814, 0.1023]) tensor(1.4508)\n",
      "[3800, 4000] loss:  tensor([0.3289, 0.5395, 0.4805, 0.1027]) tensor(1.4516)\n",
      "[4000, 4200] loss:  tensor([0.3254, 0.5376, 0.4792, 0.1015]) tensor(1.4437)\n",
      "[4200, 4400] loss:  tensor([0.3250, 0.5354, 0.4822, 0.1030]) tensor(1.4456)\n",
      "[4400, 4600] loss:  tensor([0.3235, 0.5358, 0.4814, 0.1013]) tensor(1.4419)\n",
      "[4600, 4800] loss:  tensor([0.3272, 0.5392, 0.4837, 0.1015]) tensor(1.4516)\n",
      "[4800, 5000] loss:  tensor([0.3280, 0.5356, 0.4868, 0.1021]) tensor(1.4525)\n",
      "[5000, 5200] loss:  tensor([0.3220, 0.5329, 0.4836, 0.1025]) tensor(1.4410)\n",
      "[5200, 5400] loss:  tensor([0.3240, 0.5334, 0.4808, 0.1015]) tensor(1.4397)\n",
      "[5400, 5600] loss:  tensor([0.3252, 0.5382, 0.4829, 0.1017]) tensor(1.4479)\n",
      "[5600, 5800] loss:  tensor([0.3256, 0.5334, 0.4820, 0.1023]) tensor(1.4434)\n",
      "[5800, 6000] loss:  tensor([0.3241, 0.5342, 0.4844, 0.1030]) tensor(1.4457)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0eed206c7564be08334075338bd0a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 7: tensor([0.5661, 0.5920, 0.5503, 0.5869]) 2.2952725174611626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed64fdfbe5d470f89174762212f4447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3204, 0.5355, 0.4810, 0.1031]) tensor(1.4399)\n",
      "[200, 400] loss:  tensor([0.3210, 0.5354, 0.4791, 0.1018]) tensor(1.4373)\n",
      "[400, 600] loss:  tensor([0.3224, 0.5356, 0.4799, 0.1027]) tensor(1.4406)\n",
      "[600, 800] loss:  tensor([0.3302, 0.5347, 0.4806, 0.1038]) tensor(1.4493)\n",
      "[800, 1000] loss:  tensor([0.3256, 0.5346, 0.4787, 0.1020]) tensor(1.4409)\n",
      "[1000, 1200] loss:  tensor([0.3219, 0.5320, 0.4786, 0.1014]) tensor(1.4340)\n",
      "[1200, 1400] loss:  tensor([0.3198, 0.5320, 0.4767, 0.1020]) tensor(1.4304)\n",
      "[1400, 1600] loss:  tensor([0.3216, 0.5328, 0.4829, 0.1020]) tensor(1.4393)\n",
      "[1600, 1800] loss:  tensor([0.3258, 0.5338, 0.4841, 0.1023]) tensor(1.4460)\n",
      "[1800, 2000] loss:  tensor([0.3183, 0.5345, 0.4771, 0.1012]) tensor(1.4310)\n",
      "[2000, 2200] loss:  tensor([0.3241, 0.5320, 0.4783, 0.1021]) tensor(1.4364)\n",
      "[2200, 2400] loss:  tensor([0.3212, 0.5326, 0.4784, 0.1017]) tensor(1.4338)\n",
      "[2400, 2600] loss:  tensor([0.3242, 0.5301, 0.4805, 0.1021]) tensor(1.4368)\n",
      "[2600, 2800] loss:  tensor([0.3213, 0.5326, 0.4795, 0.1015]) tensor(1.4349)\n",
      "[2800, 3000] loss:  tensor([0.3191, 0.5322, 0.4786, 0.1018]) tensor(1.4317)\n",
      "[3000, 3200] loss:  tensor([0.3195, 0.5328, 0.4792, 0.1018]) tensor(1.4333)\n",
      "[3200, 3400] loss:  tensor([0.3171, 0.5332, 0.4774, 0.1008]) tensor(1.4286)\n",
      "[3400, 3600] loss:  tensor([0.3257, 0.5364, 0.4797, 0.1016]) tensor(1.4434)\n",
      "[3600, 3800] loss:  tensor([0.3198, 0.5346, 0.4810, 0.1015]) tensor(1.4369)\n",
      "[3800, 4000] loss:  tensor([0.3242, 0.5330, 0.4766, 0.1018]) tensor(1.4357)\n",
      "[4000, 4200] loss:  tensor([0.3225, 0.5361, 0.4768, 0.1028]) tensor(1.4382)\n",
      "[4200, 4400] loss:  tensor([0.3202, 0.5338, 0.4818, 0.1015]) tensor(1.4373)\n",
      "[4400, 4600] loss:  tensor([0.3265, 0.5313, 0.4776, 0.1026]) tensor(1.4380)\n",
      "[4600, 4800] loss:  tensor([0.3232, 0.5328, 0.4803, 0.1033]) tensor(1.4395)\n",
      "[4800, 5000] loss:  tensor([0.3202, 0.5356, 0.4812, 0.1019]) tensor(1.4388)\n",
      "[5000, 5200] loss:  tensor([0.3184, 0.5307, 0.4762, 0.1012]) tensor(1.4264)\n",
      "[5200, 5400] loss:  tensor([0.3208, 0.5352, 0.4798, 0.1011]) tensor(1.4370)\n",
      "[5400, 5600] loss:  tensor([0.3181, 0.5327, 0.4796, 0.1020]) tensor(1.4324)\n",
      "[5600, 5800] loss:  tensor([0.3186, 0.5313, 0.4779, 0.1021]) tensor(1.4299)\n",
      "[5800, 6000] loss:  tensor([0.3233, 0.5315, 0.4807, 0.1013]) tensor(1.4369)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1d59506bff43caa7b2ff75a02a98f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 8: tensor([0.3826, 0.5466, 0.4878, 0.2296]) 1.6465722191336758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8db38df9c149679573f05e952ca618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3186, 0.5330, 0.4742, 0.1023]) tensor(1.4280)\n",
      "[200, 400] loss:  tensor([0.3226, 0.5283, 0.4735, 0.1019]) tensor(1.4263)\n",
      "[400, 600] loss:  tensor([0.3206, 0.5319, 0.4750, 0.1021]) tensor(1.4296)\n",
      "[600, 800] loss:  tensor([0.3183, 0.5302, 0.4742, 0.1012]) tensor(1.4239)\n",
      "[800, 1000] loss:  tensor([0.3184, 0.5269, 0.4712, 0.1011]) tensor(1.4176)\n",
      "[1000, 1200] loss:  tensor([0.3229, 0.5268, 0.4766, 0.1023]) tensor(1.4286)\n",
      "[1200, 1400] loss:  tensor([0.3154, 0.5295, 0.4763, 0.1015]) tensor(1.4227)\n",
      "[1400, 1600] loss:  tensor([0.3184, 0.5321, 0.4707, 0.1012]) tensor(1.4225)\n",
      "[1600, 1800] loss:  tensor([0.3152, 0.5288, 0.4747, 0.1012]) tensor(1.4199)\n",
      "[1800, 2000] loss:  tensor([0.3166, 0.5310, 0.4753, 0.1009]) tensor(1.4237)\n",
      "[2000, 2200] loss:  tensor([0.3167, 0.5284, 0.4782, 0.1019]) tensor(1.4252)\n",
      "[2200, 2400] loss:  tensor([0.3166, 0.5248, 0.4781, 0.1011]) tensor(1.4207)\n",
      "[2400, 2600] loss:  tensor([0.3194, 0.5307, 0.4764, 0.1015]) tensor(1.4278)\n",
      "[2600, 2800] loss:  tensor([0.3168, 0.5260, 0.4747, 0.1011]) tensor(1.4185)\n",
      "[2800, 3000] loss:  tensor([0.3157, 0.5294, 0.4785, 0.1015]) tensor(1.4251)\n",
      "[3000, 3200] loss:  tensor([0.3144, 0.5255, 0.4757, 0.1014]) tensor(1.4169)\n",
      "[3200, 3400] loss:  tensor([0.3156, 0.5322, 0.4775, 0.1014]) tensor(1.4267)\n",
      "[3400, 3600] loss:  tensor([0.3195, 0.5289, 0.4764, 0.1021]) tensor(1.4268)\n",
      "[3600, 3800] loss:  tensor([0.3159, 0.5304, 0.4752, 0.1015]) tensor(1.4231)\n",
      "[3800, 4000] loss:  tensor([0.3178, 0.5284, 0.4741, 0.1013]) tensor(1.4216)\n",
      "[4000, 4200] loss:  tensor([0.3235, 0.5264, 0.4796, 0.1015]) tensor(1.4310)\n",
      "[4200, 4400] loss:  tensor([0.3170, 0.5285, 0.4770, 0.1011]) tensor(1.4237)\n",
      "[4400, 4600] loss:  tensor([0.3155, 0.5274, 0.4764, 0.1023]) tensor(1.4215)\n",
      "[4600, 4800] loss:  tensor([0.3178, 0.5259, 0.4757, 0.1013]) tensor(1.4206)\n",
      "[4800, 5000] loss:  tensor([0.3172, 0.5254, 0.4725, 0.1015]) tensor(1.4166)\n",
      "[5000, 5200] loss:  tensor([0.3161, 0.5310, 0.4703, 0.1016]) tensor(1.4191)\n",
      "[5200, 5400] loss:  tensor([0.3196, 0.5288, 0.4730, 0.1021]) tensor(1.4235)\n",
      "[5400, 5600] loss:  tensor([0.3136, 0.5277, 0.4722, 0.1010]) tensor(1.4144)\n",
      "[5600, 5800] loss:  tensor([0.3173, 0.5266, 0.4734, 0.1010]) tensor(1.4182)\n",
      "[5800, 6000] loss:  tensor([0.3174, 0.5281, 0.4763, 0.1022]) tensor(1.4240)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e57b25a7fd84af882016dfc4064577d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 9: tensor([0.4333, 0.5832, 0.5394, 0.2515]) 1.807387177790654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33902dbd5789494cb379a2fb540a998b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3147, 0.5271, 0.4748, 0.0994]) tensor(1.4160)\n",
      "[200, 400] loss:  tensor([0.3165, 0.5269, 0.4701, 0.1012]) tensor(1.4148)\n",
      "[400, 600] loss:  tensor([0.3155, 0.5294, 0.4701, 0.1019]) tensor(1.4167)\n",
      "[600, 800] loss:  tensor([0.3158, 0.5281, 0.4725, 0.1015]) tensor(1.4179)\n",
      "[800, 1000] loss:  tensor([0.3142, 0.5283, 0.4723, 0.1010]) tensor(1.4157)\n",
      "[1000, 1200] loss:  tensor([0.3151, 0.5256, 0.4680, 0.1000]) tensor(1.4088)\n",
      "[1200, 1400] loss:  tensor([0.3150, 0.5255, 0.4690, 0.1007]) tensor(1.4102)\n",
      "[1400, 1600] loss:  tensor([0.3153, 0.5259, 0.4763, 0.1018]) tensor(1.4193)\n",
      "[1600, 1800] loss:  tensor([0.3151, 0.5229, 0.4716, 0.1004]) tensor(1.4101)\n",
      "[1800, 2000] loss:  tensor([0.3130, 0.5246, 0.4717, 0.1016]) tensor(1.4110)\n",
      "[2000, 2200] loss:  tensor([0.3179, 0.5245, 0.4685, 0.1016]) tensor(1.4126)\n",
      "[2200, 2400] loss:  tensor([0.3131, 0.5272, 0.4696, 0.1009]) tensor(1.4109)\n",
      "[2400, 2600] loss:  tensor([0.3177, 0.5267, 0.4687, 0.1011]) tensor(1.4142)\n",
      "[2600, 2800] loss:  tensor([0.3156, 0.5255, 0.4681, 0.1010]) tensor(1.4102)\n",
      "[2800, 3000] loss:  tensor([0.3141, 0.5236, 0.4724, 0.1007]) tensor(1.4108)\n",
      "[3000, 3200] loss:  tensor([0.3144, 0.5216, 0.4713, 0.1007]) tensor(1.4080)\n",
      "[3200, 3400] loss:  tensor([0.3161, 0.5255, 0.4716, 0.1005]) tensor(1.4137)\n",
      "[3400, 3600] loss:  tensor([0.3168, 0.5271, 0.4704, 0.1014]) tensor(1.4158)\n",
      "[3600, 3800] loss:  tensor([0.3159, 0.5202, 0.4717, 0.1003]) tensor(1.4081)\n",
      "[3800, 4000] loss:  tensor([0.3184, 0.5231, 0.4696, 0.1012]) tensor(1.4123)\n",
      "[4000, 4200] loss:  tensor([0.3153, 0.5274, 0.4711, 0.1008]) tensor(1.4147)\n",
      "[4200, 4400] loss:  tensor([0.3153, 0.5258, 0.4703, 0.0995]) tensor(1.4108)\n",
      "[4400, 4600] loss:  tensor([0.3125, 0.5202, 0.4692, 0.1013]) tensor(1.4031)\n",
      "[4600, 4800] loss:  tensor([0.3157, 0.5228, 0.4729, 0.1009]) tensor(1.4124)\n",
      "[4800, 5000] loss:  tensor([0.3136, 0.5218, 0.4658, 0.1004]) tensor(1.4016)\n",
      "[5000, 5200] loss:  tensor([0.3122, 0.5230, 0.4686, 0.1004]) tensor(1.4040)\n",
      "[5200, 5400] loss:  tensor([0.3150, 0.5233, 0.4689, 0.1004]) tensor(1.4076)\n",
      "[5400, 5600] loss:  tensor([0.3113, 0.5254, 0.4682, 0.0997]) tensor(1.4047)\n",
      "[5600, 5800] loss:  tensor([0.3114, 0.5220, 0.4676, 0.0997]) tensor(1.4006)\n",
      "[5800, 6000] loss:  tensor([0.3125, 0.5204, 0.4691, 0.1015]) tensor(1.4035)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605fa0478a1543cb88d9c7f797dd8497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 10: tensor([0.6304, 0.6046, 0.5287, 0.7560]) 2.5196724368109495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693a44ac2057496c98476e2a47090a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3163, 0.5250, 0.4689, 0.1009]) tensor(1.4110)\n",
      "[200, 400] loss:  tensor([0.3135, 0.5227, 0.4698, 0.1002]) tensor(1.4062)\n",
      "[400, 600] loss:  tensor([0.3121, 0.5198, 0.4655, 0.1008]) tensor(1.3982)\n",
      "[600, 800] loss:  tensor([0.3139, 0.5216, 0.4640, 0.1015]) tensor(1.4010)\n",
      "[800, 1000] loss:  tensor([0.3152, 0.5247, 0.4640, 0.0999]) tensor(1.4038)\n",
      "[1000, 1200] loss:  tensor([0.3087, 0.5230, 0.4703, 0.0994]) tensor(1.4014)\n",
      "[1200, 1400] loss:  tensor([0.3104, 0.5225, 0.4670, 0.0999]) tensor(1.3999)\n",
      "[1400, 1600] loss:  tensor([0.3087, 0.5235, 0.4652, 0.1001]) tensor(1.3975)\n",
      "[1600, 1800] loss:  tensor([0.3134, 0.5231, 0.4708, 0.1000]) tensor(1.4073)\n",
      "[1800, 2000] loss:  tensor([0.3105, 0.5236, 0.4692, 0.1025]) tensor(1.4057)\n",
      "[2000, 2200] loss:  tensor([0.3098, 0.5260, 0.4621, 0.1000]) tensor(1.3979)\n",
      "[2200, 2400] loss:  tensor([0.3121, 0.5186, 0.4718, 0.1004]) tensor(1.4029)\n",
      "[2400, 2600] loss:  tensor([0.3105, 0.5246, 0.4636, 0.1017]) tensor(1.4004)\n",
      "[2600, 2800] loss:  tensor([0.3130, 0.5189, 0.4675, 0.1004]) tensor(1.3997)\n",
      "[2800, 3000] loss:  tensor([0.3119, 0.5246, 0.4699, 0.1018]) tensor(1.4082)\n",
      "[3000, 3200] loss:  tensor([0.3111, 0.5203, 0.4694, 0.1014]) tensor(1.4021)\n",
      "[3200, 3400] loss:  tensor([0.3111, 0.5224, 0.4666, 0.1001]) tensor(1.4003)\n",
      "[3400, 3600] loss:  tensor([0.3135, 0.5186, 0.4702, 0.1001]) tensor(1.4023)\n",
      "[3600, 3800] loss:  tensor([0.3140, 0.5221, 0.4686, 0.1009]) tensor(1.4056)\n",
      "[3800, 4000] loss:  tensor([0.3094, 0.5187, 0.4664, 0.1003]) tensor(1.3948)\n",
      "[4000, 4200] loss:  tensor([0.3108, 0.5198, 0.4693, 0.1005]) tensor(1.4004)\n",
      "[4200, 4400] loss:  tensor([0.3085, 0.5228, 0.4682, 0.1003]) tensor(1.3998)\n",
      "[4400, 4600] loss:  tensor([0.3116, 0.5205, 0.4655, 0.1003]) tensor(1.3979)\n",
      "[4600, 4800] loss:  tensor([0.3130, 0.5189, 0.4684, 0.1003]) tensor(1.4005)\n",
      "[4800, 5000] loss:  tensor([0.3127, 0.5180, 0.4660, 0.1005]) tensor(1.3972)\n",
      "[5000, 5200] loss:  tensor([0.3113, 0.5209, 0.4676, 0.1007]) tensor(1.4004)\n",
      "[5200, 5400] loss:  tensor([0.3126, 0.5211, 0.4670, 0.1013]) tensor(1.4020)\n",
      "[5400, 5600] loss:  tensor([0.3117, 0.5208, 0.4660, 0.1005]) tensor(1.3990)\n",
      "[5600, 5800] loss:  tensor([0.3133, 0.5189, 0.4662, 0.1009]) tensor(1.3993)\n",
      "[5800, 6000] loss:  tensor([0.3125, 0.5217, 0.4681, 0.1010]) tensor(1.4033)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aaa70bfb23744ed9cb5a3f4704262a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 11: tensor([0.4056, 0.5520, 0.4983, 0.3084]) 1.7643272803260461\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd14e144a7a4b1cab7bf5b6f0c6f8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3093, 0.5203, 0.4651, 0.1007]) tensor(1.3954)\n",
      "[200, 400] loss:  tensor([0.3108, 0.5202, 0.4631, 0.1009]) tensor(1.3951)\n",
      "[400, 600] loss:  tensor([0.3105, 0.5191, 0.4672, 0.1009]) tensor(1.3977)\n",
      "[600, 800] loss:  tensor([0.3083, 0.5148, 0.4672, 0.1000]) tensor(1.3903)\n",
      "[800, 1000] loss:  tensor([0.3094, 0.5199, 0.4653, 0.1007]) tensor(1.3953)\n",
      "[1000, 1200] loss:  tensor([0.3095, 0.5200, 0.4619, 0.1007]) tensor(1.3921)\n",
      "[1200, 1400] loss:  tensor([0.3106, 0.5162, 0.4635, 0.1004]) tensor(1.3906)\n",
      "[1400, 1600] loss:  tensor([0.3087, 0.5172, 0.4629, 0.0999]) tensor(1.3887)\n",
      "[1600, 1800] loss:  tensor([0.3092, 0.5201, 0.4652, 0.0993]) tensor(1.3939)\n",
      "[1800, 2000] loss:  tensor([0.3096, 0.5200, 0.4621, 0.1017]) tensor(1.3933)\n",
      "[2000, 2200] loss:  tensor([0.3065, 0.5149, 0.4641, 0.1007]) tensor(1.3862)\n",
      "[2200, 2400] loss:  tensor([0.3117, 0.5186, 0.4670, 0.1014]) tensor(1.3987)\n",
      "[2400, 2600] loss:  tensor([0.3091, 0.5165, 0.4660, 0.1004]) tensor(1.3920)\n",
      "[2600, 2800] loss:  tensor([0.3080, 0.5193, 0.4669, 0.0995]) tensor(1.3938)\n",
      "[2800, 3000] loss:  tensor([0.3074, 0.5132, 0.4662, 0.0997]) tensor(1.3865)\n",
      "[3000, 3200] loss:  tensor([0.3102, 0.5171, 0.4650, 0.1002]) tensor(1.3925)\n",
      "[3200, 3400] loss:  tensor([0.3114, 0.5160, 0.4656, 0.0992]) tensor(1.3922)\n",
      "[3400, 3600] loss:  tensor([0.3081, 0.5216, 0.4652, 0.0997]) tensor(1.3945)\n",
      "[3600, 3800] loss:  tensor([0.3112, 0.5131, 0.4629, 0.1001]) tensor(1.3873)\n",
      "[3800, 4000] loss:  tensor([0.3092, 0.5163, 0.4668, 0.1003]) tensor(1.3926)\n",
      "[4000, 4200] loss:  tensor([0.3104, 0.5151, 0.4661, 0.1009]) tensor(1.3925)\n",
      "[4200, 4400] loss:  tensor([0.3064, 0.5206, 0.4651, 0.1003]) tensor(1.3924)\n",
      "[4400, 4600] loss:  tensor([0.3085, 0.5150, 0.4623, 0.0997]) tensor(1.3856)\n",
      "[4600, 4800] loss:  tensor([0.3084, 0.5165, 0.4649, 0.1001]) tensor(1.3899)\n",
      "[4800, 5000] loss:  tensor([0.3097, 0.5188, 0.4622, 0.1003]) tensor(1.3910)\n",
      "[5000, 5200] loss:  tensor([0.3128, 0.5148, 0.4651, 0.1007]) tensor(1.3934)\n",
      "[5200, 5400] loss:  tensor([0.3131, 0.5199, 0.4603, 0.0997]) tensor(1.3929)\n",
      "[5400, 5600] loss:  tensor([0.3066, 0.5189, 0.4607, 0.0998]) tensor(1.3860)\n",
      "[5600, 5800] loss:  tensor([0.3112, 0.5168, 0.4627, 0.1001]) tensor(1.3908)\n",
      "[5800, 6000] loss:  tensor([0.3101, 0.5157, 0.4650, 0.1005]) tensor(1.3913)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67405adfa3984a5d955474d13b59d839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 12: tensor([0.5441, 0.5888, 0.5254, 0.3955]) 2.0536979688674517\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6b26d063bd45fea84b8e03ecf155ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3059, 0.5148, 0.4650, 0.1011]) tensor(1.3869)\n",
      "[200, 400] loss:  tensor([0.3062, 0.5153, 0.4608, 0.1002]) tensor(1.3825)\n",
      "[400, 600] loss:  tensor([0.3121, 0.5163, 0.4620, 0.0996]) tensor(1.3900)\n",
      "[600, 800] loss:  tensor([0.3095, 0.5131, 0.4629, 0.1003]) tensor(1.3858)\n",
      "[800, 1000] loss:  tensor([0.3064, 0.5182, 0.4614, 0.0997]) tensor(1.3858)\n",
      "[1000, 1200] loss:  tensor([0.3063, 0.5171, 0.4625, 0.1000]) tensor(1.3860)\n",
      "[1200, 1400] loss:  tensor([0.3101, 0.5150, 0.4592, 0.1013]) tensor(1.3855)\n",
      "[1400, 1600] loss:  tensor([0.3073, 0.5172, 0.4599, 0.1015]) tensor(1.3858)\n",
      "[1600, 1800] loss:  tensor([0.3040, 0.5151, 0.4610, 0.0997]) tensor(1.3798)\n",
      "[1800, 2000] loss:  tensor([0.3081, 0.5169, 0.4626, 0.0995]) tensor(1.3871)\n",
      "[2000, 2200] loss:  tensor([0.3071, 0.5114, 0.4589, 0.0997]) tensor(1.3771)\n",
      "[2200, 2400] loss:  tensor([0.3084, 0.5160, 0.4630, 0.0992]) tensor(1.3866)\n",
      "[2400, 2600] loss:  tensor([0.3103, 0.5111, 0.4618, 0.0997]) tensor(1.3829)\n",
      "[2600, 2800] loss:  tensor([0.3098, 0.5164, 0.4647, 0.0997]) tensor(1.3905)\n",
      "[2800, 3000] loss:  tensor([0.3057, 0.5100, 0.4651, 0.1001]) tensor(1.3808)\n",
      "[3000, 3200] loss:  tensor([0.3065, 0.5138, 0.4592, 0.0992]) tensor(1.3787)\n",
      "[3200, 3400] loss:  tensor([0.3043, 0.5125, 0.4638, 0.0989]) tensor(1.3794)\n",
      "[3400, 3600] loss:  tensor([0.3092, 0.5149, 0.4646, 0.0999]) tensor(1.3885)\n",
      "[3600, 3800] loss:  tensor([0.3080, 0.5107, 0.4627, 0.1003]) tensor(1.3817)\n",
      "[3800, 4000] loss:  tensor([0.3091, 0.5186, 0.4600, 0.1005]) tensor(1.3882)\n",
      "[4000, 4200] loss:  tensor([0.3027, 0.5202, 0.4587, 0.1001]) tensor(1.3817)\n",
      "[4200, 4400] loss:  tensor([0.3063, 0.5177, 0.4633, 0.1007]) tensor(1.3880)\n",
      "[4400, 4600] loss:  tensor([0.3065, 0.5115, 0.4591, 0.0999]) tensor(1.3770)\n",
      "[4600, 4800] loss:  tensor([0.3100, 0.5138, 0.4639, 0.0990]) tensor(1.3868)\n",
      "[4800, 5000] loss:  tensor([0.3076, 0.5145, 0.4610, 0.1002]) tensor(1.3833)\n",
      "[5000, 5200] loss:  tensor([0.3047, 0.5135, 0.4572, 0.1003]) tensor(1.3758)\n",
      "[5200, 5400] loss:  tensor([0.3027, 0.5170, 0.4585, 0.0998]) tensor(1.3781)\n",
      "[5400, 5600] loss:  tensor([0.3054, 0.5165, 0.4587, 0.0983]) tensor(1.3789)\n",
      "[5600, 5800] loss:  tensor([0.3044, 0.5144, 0.4597, 0.1003]) tensor(1.3787)\n",
      "[5800, 6000] loss:  tensor([0.3088, 0.5124, 0.4607, 0.1000]) tensor(1.3819)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b07a323fbd74f11a63860a753a96c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 13: tensor([0.3557, 0.5352, 0.4810, 0.2737]) 1.6456472864726885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d828f9cc4b4b59894a73e992c1de53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3036, 0.5110, 0.4573, 0.1002]) tensor(1.3721)\n",
      "[200, 400] loss:  tensor([0.3041, 0.5189, 0.4585, 0.1003]) tensor(1.3818)\n",
      "[400, 600] loss:  tensor([0.3076, 0.5114, 0.4591, 0.1000]) tensor(1.3782)\n",
      "[600, 800] loss:  tensor([0.3044, 0.5126, 0.4587, 0.0991]) tensor(1.3748)\n",
      "[800, 1000] loss:  tensor([0.3019, 0.5128, 0.4610, 0.0995]) tensor(1.3753)\n",
      "[1000, 1200] loss:  tensor([0.3028, 0.5112, 0.4597, 0.0998]) tensor(1.3735)\n",
      "[1200, 1400] loss:  tensor([0.3052, 0.5081, 0.4605, 0.0996]) tensor(1.3734)\n",
      "[1400, 1600] loss:  tensor([0.3069, 0.5150, 0.4570, 0.1004]) tensor(1.3792)\n",
      "[1600, 1800] loss:  tensor([0.3033, 0.5125, 0.4589, 0.0996]) tensor(1.3743)\n",
      "[1800, 2000] loss:  tensor([0.3055, 0.5112, 0.4615, 0.0999]) tensor(1.3780)\n",
      "[2000, 2200] loss:  tensor([0.3033, 0.5137, 0.4586, 0.1000]) tensor(1.3756)\n",
      "[2200, 2400] loss:  tensor([0.3073, 0.5147, 0.4608, 0.0991]) tensor(1.3820)\n",
      "[2400, 2600] loss:  tensor([0.3073, 0.5105, 0.4594, 0.0989]) tensor(1.3762)\n",
      "[2600, 2800] loss:  tensor([0.3073, 0.5109, 0.4612, 0.1005]) tensor(1.3799)\n",
      "[2800, 3000] loss:  tensor([0.3071, 0.5142, 0.4550, 0.0988]) tensor(1.3751)\n",
      "[3000, 3200] loss:  tensor([0.3052, 0.5155, 0.4580, 0.1005]) tensor(1.3791)\n",
      "[3200, 3400] loss:  tensor([0.3055, 0.5109, 0.4583, 0.0994]) tensor(1.3742)\n",
      "[3400, 3600] loss:  tensor([0.3074, 0.5086, 0.4538, 0.0991]) tensor(1.3688)\n",
      "[3600, 3800] loss:  tensor([0.3049, 0.5145, 0.4600, 0.0990]) tensor(1.3785)\n",
      "[3800, 4000] loss:  tensor([0.3052, 0.5090, 0.4596, 0.1002]) tensor(1.3741)\n",
      "[4000, 4200] loss:  tensor([0.3079, 0.5147, 0.4580, 0.1000]) tensor(1.3806)\n",
      "[4200, 4400] loss:  tensor([0.3059, 0.5140, 0.4558, 0.1001]) tensor(1.3758)\n",
      "[4400, 4600] loss:  tensor([0.3049, 0.5140, 0.4597, 0.0994]) tensor(1.3780)\n",
      "[4600, 4800] loss:  tensor([0.3023, 0.5138, 0.4626, 0.1001]) tensor(1.3788)\n",
      "[4800, 5000] loss:  tensor([0.3026, 0.5052, 0.4543, 0.0997]) tensor(1.3618)\n",
      "[5000, 5200] loss:  tensor([0.3035, 0.5141, 0.4584, 0.0998]) tensor(1.3757)\n",
      "[5200, 5400] loss:  tensor([0.3035, 0.5095, 0.4567, 0.0988]) tensor(1.3685)\n",
      "[5400, 5600] loss:  tensor([0.3074, 0.5090, 0.4561, 0.1001]) tensor(1.3726)\n",
      "[5600, 5800] loss:  tensor([0.3023, 0.5105, 0.4607, 0.0997]) tensor(1.3731)\n",
      "[5800, 6000] loss:  tensor([0.3018, 0.5103, 0.4574, 0.0995]) tensor(1.3690)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddbcb911b164a16a4e2e458a180c4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 14: tensor([0.3489, 0.5267, 0.4702, 0.1402]) 1.4859478749060386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04b0f25edce468d94c4c55625016e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3038, 0.5066, 0.4582, 0.1004]) tensor(1.3689)\n",
      "[200, 400] loss:  tensor([0.3032, 0.5083, 0.4570, 0.0989]) tensor(1.3673)\n",
      "[400, 600] loss:  tensor([0.3035, 0.5080, 0.4553, 0.0990]) tensor(1.3658)\n",
      "[600, 800] loss:  tensor([0.3087, 0.5103, 0.4580, 0.1007]) tensor(1.3776)\n",
      "[800, 1000] loss:  tensor([0.2992, 0.5071, 0.4559, 0.0987]) tensor(1.3609)\n",
      "[1000, 1200] loss:  tensor([0.2993, 0.5108, 0.4599, 0.0985]) tensor(1.3685)\n",
      "[1200, 1400] loss:  tensor([0.3069, 0.5059, 0.4603, 0.0996]) tensor(1.3727)\n",
      "[1400, 1600] loss:  tensor([0.3021, 0.5046, 0.4581, 0.1001]) tensor(1.3648)\n",
      "[1600, 1800] loss:  tensor([0.3010, 0.5111, 0.4592, 0.0994]) tensor(1.3707)\n",
      "[1800, 2000] loss:  tensor([0.3050, 0.5052, 0.4588, 0.0998]) tensor(1.3689)\n",
      "[2000, 2200] loss:  tensor([0.3043, 0.5113, 0.4571, 0.0995]) tensor(1.3722)\n",
      "[2200, 2400] loss:  tensor([0.3096, 0.5097, 0.4585, 0.0998]) tensor(1.3775)\n",
      "[2400, 2600] loss:  tensor([0.3047, 0.5053, 0.4583, 0.0994]) tensor(1.3677)\n",
      "[2600, 2800] loss:  tensor([0.3045, 0.5075, 0.4607, 0.1007]) tensor(1.3734)\n",
      "[2800, 3000] loss:  tensor([0.3039, 0.5123, 0.4583, 0.1002]) tensor(1.3747)\n",
      "[3000, 3200] loss:  tensor([0.3040, 0.5079, 0.4551, 0.1007]) tensor(1.3677)\n",
      "[3200, 3400] loss:  tensor([0.3038, 0.5081, 0.4574, 0.1003]) tensor(1.3696)\n",
      "[3400, 3600] loss:  tensor([0.3033, 0.5072, 0.4557, 0.0983]) tensor(1.3645)\n",
      "[3600, 3800] loss:  tensor([0.3011, 0.5085, 0.4583, 0.0991]) tensor(1.3669)\n",
      "[3800, 4000] loss:  tensor([0.3076, 0.5086, 0.4621, 0.1003]) tensor(1.3786)\n",
      "[4000, 4200] loss:  tensor([0.3030, 0.5076, 0.4593, 0.0980]) tensor(1.3679)\n",
      "[4200, 4400] loss:  tensor([0.2992, 0.5086, 0.4567, 0.0985]) tensor(1.3629)\n",
      "[4400, 4600] loss:  tensor([0.3003, 0.5054, 0.4563, 0.0998]) tensor(1.3618)\n",
      "[4600, 4800] loss:  tensor([0.3021, 0.5112, 0.4543, 0.1008]) tensor(1.3683)\n",
      "[4800, 5000] loss:  tensor([0.3051, 0.5103, 0.4593, 0.1002]) tensor(1.3749)\n",
      "[5000, 5200] loss:  tensor([0.2991, 0.5092, 0.4549, 0.0985]) tensor(1.3617)\n",
      "[5200, 5400] loss:  tensor([0.3061, 0.5090, 0.4511, 0.0988]) tensor(1.3650)\n",
      "[5400, 5600] loss:  tensor([0.2962, 0.5079, 0.4594, 0.1004]) tensor(1.3640)\n",
      "[5600, 5800] loss:  tensor([0.2986, 0.5047, 0.4550, 0.0991]) tensor(1.3574)\n",
      "[5800, 6000] loss:  tensor([0.3045, 0.5098, 0.4541, 0.0994]) tensor(1.3679)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69d492d58f44022a3eba6fd94f21092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 15: tensor([0.6663, 0.5980, 0.6511, 0.3520]) 2.267470950263092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3737751a96fc40d7a2ed3807b3f1ed87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.2987, 0.5059, 0.4527, 0.0987]) tensor(1.3559)\n",
      "[200, 400] loss:  tensor([0.3010, 0.5046, 0.4552, 0.0988]) tensor(1.3596)\n",
      "[400, 600] loss:  tensor([0.3052, 0.5052, 0.4552, 0.0988]) tensor(1.3644)\n",
      "[600, 800] loss:  tensor([0.3045, 0.5096, 0.4542, 0.0993]) tensor(1.3676)\n",
      "[800, 1000] loss:  tensor([0.3031, 0.5050, 0.4544, 0.0988]) tensor(1.3612)\n",
      "[1000, 1200] loss:  tensor([0.3031, 0.5070, 0.4545, 0.0992]) tensor(1.3638)\n",
      "[1200, 1400] loss:  tensor([0.2990, 0.5067, 0.4559, 0.0997]) tensor(1.3613)\n",
      "[1400, 1600] loss:  tensor([0.3044, 0.5077, 0.4547, 0.0985]) tensor(1.3654)\n",
      "[1600, 1800] loss:  tensor([0.2999, 0.5042, 0.4592, 0.0987]) tensor(1.3620)\n",
      "[1800, 2000] loss:  tensor([0.3008, 0.5063, 0.4569, 0.1004]) tensor(1.3643)\n",
      "[2000, 2200] loss:  tensor([0.3015, 0.5025, 0.4554, 0.0991]) tensor(1.3586)\n",
      "[2200, 2400] loss:  tensor([0.3059, 0.5052, 0.4535, 0.0993]) tensor(1.3639)\n",
      "[2400, 2600] loss:  tensor([0.3015, 0.5063, 0.4513, 0.0993]) tensor(1.3585)\n",
      "[2600, 2800] loss:  tensor([0.3050, 0.5109, 0.4524, 0.0999]) tensor(1.3682)\n",
      "[2800, 3000] loss:  tensor([0.3057, 0.5061, 0.4574, 0.0997]) tensor(1.3690)\n",
      "[3000, 3200] loss:  tensor([0.2998, 0.5057, 0.4565, 0.0994]) tensor(1.3614)\n",
      "[3200, 3400] loss:  tensor([0.3032, 0.5061, 0.4527, 0.0991]) tensor(1.3611)\n",
      "[3400, 3600] loss:  tensor([0.2982, 0.5041, 0.4529, 0.0986]) tensor(1.3538)\n",
      "[3600, 3800] loss:  tensor([0.3015, 0.5001, 0.4522, 0.0997]) tensor(1.3535)\n",
      "[3800, 4000] loss:  tensor([0.2966, 0.4996, 0.4566, 0.0995]) tensor(1.3523)\n",
      "[4000, 4200] loss:  tensor([0.3011, 0.5097, 0.4569, 0.1002]) tensor(1.3679)\n",
      "[4200, 4400] loss:  tensor([0.3013, 0.5052, 0.4524, 0.0986]) tensor(1.3575)\n",
      "[4400, 4600] loss:  tensor([0.2998, 0.5027, 0.4553, 0.0993]) tensor(1.3572)\n",
      "[4600, 4800] loss:  tensor([0.3006, 0.5031, 0.4572, 0.0989]) tensor(1.3598)\n",
      "[4800, 5000] loss:  tensor([0.3014, 0.5041, 0.4513, 0.0994]) tensor(1.3563)\n",
      "[5000, 5200] loss:  tensor([0.3000, 0.5068, 0.4505, 0.0994]) tensor(1.3568)\n",
      "[5200, 5400] loss:  tensor([0.3032, 0.5058, 0.4551, 0.0990]) tensor(1.3631)\n",
      "[5400, 5600] loss:  tensor([0.3012, 0.5053, 0.4554, 0.0980]) tensor(1.3599)\n",
      "[5600, 5800] loss:  tensor([0.3015, 0.5004, 0.4532, 0.0985]) tensor(1.3536)\n",
      "[5800, 6000] loss:  tensor([0.3014, 0.5078, 0.4541, 0.0989]) tensor(1.3622)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f2282f76c94727bbc31f00737186de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 16: tensor([0.5558, 0.5902, 0.5463, 0.6332]) 2.325467898474693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad26ce89c2044110a97d3d0dec39568b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.2997, 0.5059, 0.4558, 0.0991]) tensor(1.3606)\n",
      "[200, 400] loss:  tensor([0.2986, 0.5061, 0.4510, 0.0993]) tensor(1.3551)\n",
      "[400, 600] loss:  tensor([0.3007, 0.5017, 0.4551, 0.0988]) tensor(1.3564)\n",
      "[600, 800] loss:  tensor([0.2997, 0.5044, 0.4533, 0.0993]) tensor(1.3567)\n",
      "[800, 1000] loss:  tensor([0.3006, 0.5067, 0.4489, 0.0995]) tensor(1.3556)\n",
      "[1000, 1200] loss:  tensor([0.2984, 0.5008, 0.4511, 0.0985]) tensor(1.3487)\n",
      "[1200, 1400] loss:  tensor([0.3004, 0.5043, 0.4511, 0.0981]) tensor(1.3539)\n",
      "[1400, 1600] loss:  tensor([0.3018, 0.5055, 0.4478, 0.1002]) tensor(1.3553)\n",
      "[1600, 1800] loss:  tensor([0.3003, 0.5032, 0.4513, 0.0988]) tensor(1.3537)\n",
      "[1800, 2000] loss:  tensor([0.2980, 0.5063, 0.4525, 0.0987]) tensor(1.3555)\n",
      "[2000, 2200] loss:  tensor([0.3038, 0.5048, 0.4515, 0.0984]) tensor(1.3585)\n",
      "[2200, 2400] loss:  tensor([0.3011, 0.5064, 0.4538, 0.0994]) tensor(1.3606)\n",
      "[2400, 2600] loss:  tensor([0.3014, 0.5032, 0.4539, 0.0990]) tensor(1.3575)\n",
      "[2600, 2800] loss:  tensor([0.2993, 0.5050, 0.4540, 0.0995]) tensor(1.3578)\n",
      "[2800, 3000] loss:  tensor([0.2994, 0.4974, 0.4512, 0.0974]) tensor(1.3455)\n",
      "[3000, 3200] loss:  tensor([0.2980, 0.5048, 0.4529, 0.0985]) tensor(1.3542)\n",
      "[3200, 3400] loss:  tensor([0.2998, 0.5040, 0.4499, 0.0990]) tensor(1.3527)\n",
      "[3400, 3600] loss:  tensor([0.2973, 0.5056, 0.4508, 0.0986]) tensor(1.3523)\n",
      "[3600, 3800] loss:  tensor([0.3015, 0.5085, 0.4503, 0.0984]) tensor(1.3587)\n",
      "[3800, 4000] loss:  tensor([0.3031, 0.5053, 0.4542, 0.0986]) tensor(1.3613)\n",
      "[4000, 4200] loss:  tensor([0.3001, 0.5061, 0.4528, 0.0998]) tensor(1.3587)\n",
      "[4200, 4400] loss:  tensor([0.2998, 0.5043, 0.4547, 0.0983]) tensor(1.3570)\n",
      "[4400, 4600] loss:  tensor([0.2999, 0.5047, 0.4535, 0.0982]) tensor(1.3563)\n",
      "[4600, 4800] loss:  tensor([0.2965, 0.5031, 0.4554, 0.0989]) tensor(1.3539)\n",
      "[4800, 5000] loss:  tensor([0.3033, 0.5041, 0.4504, 0.0990]) tensor(1.3567)\n",
      "[5000, 5200] loss:  tensor([0.2988, 0.5039, 0.4508, 0.0991]) tensor(1.3526)\n",
      "[5200, 5400] loss:  tensor([0.3008, 0.5011, 0.4501, 0.0997]) tensor(1.3518)\n",
      "[5400, 5600] loss:  tensor([0.3020, 0.5023, 0.4513, 0.0994]) tensor(1.3551)\n",
      "[5600, 5800] loss:  tensor([0.2985, 0.5066, 0.4514, 0.0993]) tensor(1.3557)\n",
      "[5800, 6000] loss:  tensor([0.3000, 0.5035, 0.4550, 0.0993]) tensor(1.3578)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581152d992b74149b1ea8a31eefd8113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 17: tensor([0.6325, 0.6203, 0.5477, 0.8216]) 2.6221610929278376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220d34ffd28f4939b124d1903d48a460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.2955, 0.5003, 0.4489, 0.0980]) tensor(1.3428)\n",
      "[200, 400] loss:  tensor([0.2988, 0.5009, 0.4484, 0.0989]) tensor(1.3470)\n",
      "[400, 600] loss:  tensor([0.2992, 0.5044, 0.4493, 0.0984]) tensor(1.3512)\n",
      "[600, 800] loss:  tensor([0.3062, 0.5020, 0.4489, 0.0995]) tensor(1.3566)\n",
      "[800, 1000] loss:  tensor([0.3002, 0.5013, 0.4499, 0.0987]) tensor(1.3501)\n",
      "[1000, 1200] loss:  tensor([0.2998, 0.5045, 0.4508, 0.0982]) tensor(1.3532)\n",
      "[1200, 1400] loss:  tensor([0.2996, 0.5017, 0.4546, 0.0981]) tensor(1.3540)\n",
      "[1400, 1600] loss:  tensor([0.2960, 0.5037, 0.4482, 0.0982]) tensor(1.3460)\n",
      "[1600, 1800] loss:  tensor([0.3019, 0.5006, 0.4520, 0.1006]) tensor(1.3551)\n",
      "[1800, 2000] loss:  tensor([0.3009, 0.5040, 0.4487, 0.0995]) tensor(1.3532)\n",
      "[2000, 2200] loss:  tensor([0.2989, 0.5008, 0.4505, 0.0989]) tensor(1.3491)\n",
      "[2200, 2400] loss:  tensor([0.2995, 0.5037, 0.4521, 0.0988]) tensor(1.3540)\n",
      "[2400, 2600] loss:  tensor([0.3006, 0.5047, 0.4481, 0.0985]) tensor(1.3519)\n",
      "[2600, 2800] loss:  tensor([0.2999, 0.5043, 0.4506, 0.0993]) tensor(1.3541)\n",
      "[2800, 3000] loss:  tensor([0.2954, 0.5024, 0.4495, 0.0986]) tensor(1.3460)\n",
      "[3000, 3200] loss:  tensor([0.2973, 0.5010, 0.4488, 0.0979]) tensor(1.3450)\n",
      "[3200, 3400] loss:  tensor([0.2997, 0.5016, 0.4506, 0.0989]) tensor(1.3509)\n",
      "[3400, 3600] loss:  tensor([0.2986, 0.4991, 0.4500, 0.0995]) tensor(1.3472)\n",
      "[3600, 3800] loss:  tensor([0.2976, 0.5024, 0.4521, 0.0984]) tensor(1.3506)\n",
      "[3800, 4000] loss:  tensor([0.3007, 0.5001, 0.4526, 0.0996]) tensor(1.3530)\n",
      "[4000, 4200] loss:  tensor([0.3018, 0.5023, 0.4512, 0.0989]) tensor(1.3543)\n",
      "[4200, 4400] loss:  tensor([0.2991, 0.4989, 0.4521, 0.0992]) tensor(1.3493)\n",
      "[4400, 4600] loss:  tensor([0.2980, 0.5033, 0.4507, 0.0991]) tensor(1.3511)\n",
      "[4600, 4800] loss:  tensor([0.2999, 0.5030, 0.4491, 0.0984]) tensor(1.3505)\n",
      "[4800, 5000] loss:  tensor([0.3020, 0.4986, 0.4520, 0.0990]) tensor(1.3517)\n",
      "[5000, 5200] loss:  tensor([0.2922, 0.5014, 0.4463, 0.0984]) tensor(1.3382)\n",
      "[5200, 5400] loss:  tensor([0.2966, 0.5030, 0.4534, 0.0991]) tensor(1.3522)\n",
      "[5400, 5600] loss:  tensor([0.2971, 0.5025, 0.4506, 0.0995]) tensor(1.3498)\n",
      "[5600, 5800] loss:  tensor([0.2978, 0.5010, 0.4535, 0.0988]) tensor(1.3511)\n",
      "[5800, 6000] loss:  tensor([0.2977, 0.5038, 0.4463, 0.0986]) tensor(1.3464)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e7af85e6af43ff950570bc3d73a2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 18: tensor([0.6363, 0.6190, 0.5943, 0.2533]) 2.102947207388499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba691a1f207e46b684f9d274c95b1569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.2957, 0.4979, 0.4478, 0.0988]) tensor(1.3403)\n",
      "[200, 400] loss:  tensor([0.2964, 0.5006, 0.4531, 0.0981]) tensor(1.3483)\n",
      "[400, 600] loss:  tensor([0.2946, 0.5006, 0.4473, 0.0988]) tensor(1.3413)\n",
      "[600, 800] loss:  tensor([0.2930, 0.4974, 0.4469, 0.0983]) tensor(1.3357)\n",
      "[800, 1000] loss:  tensor([0.2982, 0.5011, 0.4485, 0.0984]) tensor(1.3462)\n",
      "[1000, 1200] loss:  tensor([0.2999, 0.4991, 0.4523, 0.0994]) tensor(1.3507)\n",
      "[1200, 1400] loss:  tensor([0.2977, 0.5020, 0.4494, 0.0991]) tensor(1.3482)\n",
      "[1400, 1600] loss:  tensor([0.2964, 0.5019, 0.4455, 0.0984]) tensor(1.3422)\n",
      "[1600, 1800] loss:  tensor([0.2954, 0.5007, 0.4497, 0.0980]) tensor(1.3439)\n",
      "[1800, 2000] loss:  tensor([0.2970, 0.4972, 0.4470, 0.0982]) tensor(1.3394)\n",
      "[2000, 2200] loss:  tensor([0.3005, 0.5021, 0.4483, 0.0988]) tensor(1.3497)\n",
      "[2200, 2400] loss:  tensor([0.2966, 0.4996, 0.4489, 0.0978]) tensor(1.3429)\n",
      "[2400, 2600] loss:  tensor([0.2960, 0.5002, 0.4479, 0.0980]) tensor(1.3421)\n",
      "[2600, 2800] loss:  tensor([0.2956, 0.4970, 0.4491, 0.0987]) tensor(1.3404)\n",
      "[2800, 3000] loss:  tensor([0.2995, 0.4995, 0.4498, 0.0987]) tensor(1.3474)\n",
      "[3000, 3200] loss:  tensor([0.3004, 0.5002, 0.4510, 0.0990]) tensor(1.3506)\n",
      "[3200, 3400] loss:  tensor([0.2965, 0.4989, 0.4487, 0.0981]) tensor(1.3423)\n",
      "[3400, 3600] loss:  tensor([0.3019, 0.4995, 0.4490, 0.0997]) tensor(1.3502)\n",
      "[3600, 3800] loss:  tensor([0.2967, 0.4986, 0.4499, 0.0990]) tensor(1.3442)\n",
      "[3800, 4000] loss:  tensor([0.2960, 0.4979, 0.4513, 0.0976]) tensor(1.3428)\n",
      "[4000, 4200] loss:  tensor([0.3005, 0.5016, 0.4455, 0.0989]) tensor(1.3465)\n",
      "[4200, 4400] loss:  tensor([0.2977, 0.4997, 0.4491, 0.0988]) tensor(1.3453)\n",
      "[4400, 4600] loss:  tensor([0.2993, 0.4962, 0.4468, 0.0983]) tensor(1.3407)\n",
      "[4600, 4800] loss:  tensor([0.2950, 0.4990, 0.4475, 0.0989]) tensor(1.3403)\n",
      "[4800, 5000] loss:  tensor([0.2945, 0.5002, 0.4467, 0.0987]) tensor(1.3402)\n",
      "[5000, 5200] loss:  tensor([0.3019, 0.4993, 0.4500, 0.0990]) tensor(1.3501)\n",
      "[5200, 5400] loss:  tensor([0.2954, 0.4964, 0.4460, 0.0984]) tensor(1.3362)\n",
      "[5400, 5600] loss:  tensor([0.2971, 0.5026, 0.4480, 0.0986]) tensor(1.3463)\n",
      "[5600, 5800] loss:  tensor([0.2971, 0.4979, 0.4492, 0.0987]) tensor(1.3429)\n",
      "[5800, 6000] loss:  tensor([0.2947, 0.5003, 0.4484, 0.0983]) tensor(1.3417)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f3c7c9703e4f5da3c643d742a95b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 19: tensor([0.3870, 0.5302, 0.4730, 0.3558]) 1.7459207533356302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9991eca4b0444fb79bf82156df2790ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.2927, 0.4968, 0.4431, 0.0986]) tensor(1.3313)\n",
      "[200, 400] loss:  tensor([0.2961, 0.4976, 0.4460, 0.0989]) tensor(1.3386)\n",
      "[400, 600] loss:  tensor([0.2923, 0.4971, 0.4458, 0.0978]) tensor(1.3330)\n",
      "[600, 800] loss:  tensor([0.2948, 0.4982, 0.4458, 0.0992]) tensor(1.3380)\n",
      "[800, 1000] loss:  tensor([0.2978, 0.4959, 0.4475, 0.0986]) tensor(1.3398)\n",
      "[1000, 1200] loss:  tensor([0.2969, 0.4990, 0.4456, 0.0992]) tensor(1.3408)\n",
      "[1200, 1400] loss:  tensor([0.2946, 0.4993, 0.4462, 0.0985]) tensor(1.3387)\n",
      "[1400, 1600] loss:  tensor([0.2951, 0.4965, 0.4491, 0.0977]) tensor(1.3384)\n",
      "[1600, 1800] loss:  tensor([0.2960, 0.4970, 0.4454, 0.0989]) tensor(1.3373)\n",
      "[1800, 2000] loss:  tensor([0.2977, 0.4975, 0.4503, 0.0976]) tensor(1.3431)\n",
      "[2000, 2200] loss:  tensor([0.2969, 0.4994, 0.4470, 0.0990]) tensor(1.3422)\n",
      "[2200, 2400] loss:  tensor([0.2936, 0.4956, 0.4433, 0.0986]) tensor(1.3312)\n",
      "[2400, 2600] loss:  tensor([0.2976, 0.5040, 0.4442, 0.0989]) tensor(1.3447)\n",
      "[2600, 2800] loss:  tensor([0.2919, 0.4950, 0.4480, 0.0996]) tensor(1.3345)\n",
      "[2800, 3000] loss:  tensor([0.2969, 0.5008, 0.4478, 0.0979]) tensor(1.3433)\n",
      "[3000, 3200] loss:  tensor([0.2954, 0.4950, 0.4462, 0.0976]) tensor(1.3341)\n",
      "[3200, 3400] loss:  tensor([0.2939, 0.5020, 0.4432, 0.0987]) tensor(1.3379)\n",
      "[3400, 3600] loss:  tensor([0.2950, 0.4996, 0.4418, 0.0988]) tensor(1.3353)\n",
      "[3600, 3800] loss:  tensor([0.2951, 0.4952, 0.4475, 0.0973]) tensor(1.3350)\n",
      "[3800, 4000] loss:  tensor([0.3001, 0.4978, 0.4434, 0.0983]) tensor(1.3396)\n",
      "[4000, 4200] loss:  tensor([0.2989, 0.4958, 0.4471, 0.0978]) tensor(1.3396)\n",
      "[4200, 4400] loss:  tensor([0.2997, 0.4981, 0.4467, 0.0991]) tensor(1.3436)\n",
      "[4400, 4600] loss:  tensor([0.2980, 0.4988, 0.4455, 0.0988]) tensor(1.3412)\n",
      "[4600, 4800] loss:  tensor([0.2959, 0.4952, 0.4471, 0.0977]) tensor(1.3360)\n",
      "[4800, 5000] loss:  tensor([0.2980, 0.4954, 0.4454, 0.0986]) tensor(1.3372)\n",
      "[5000, 5200] loss:  tensor([0.2932, 0.4974, 0.4456, 0.0983]) tensor(1.3344)\n",
      "[5200, 5400] loss:  tensor([0.2979, 0.4970, 0.4449, 0.0989]) tensor(1.3388)\n",
      "[5400, 5600] loss:  tensor([0.2934, 0.4973, 0.4455, 0.0981]) tensor(1.3344)\n",
      "[5600, 5800] loss:  tensor([0.2947, 0.4980, 0.4463, 0.0981]) tensor(1.3371)\n",
      "[5800, 6000] loss:  tensor([0.2939, 0.4937, 0.4456, 0.0986]) tensor(1.3318)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7befd9a66d4239ae2a29a37f2e3587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 20: tensor([0.3814, 0.5458, 0.4992, 0.2088]) 1.6351506465719745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57341342cfbc49a2a5534bd46b597f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.2967, 0.4943, 0.4464, 0.0991]) tensor(1.3365)\n",
      "[200, 400] loss:  tensor([0.2936, 0.4918, 0.4462, 0.0979]) tensor(1.3294)\n",
      "[400, 600] loss:  tensor([0.2954, 0.4889, 0.4441, 0.0987]) tensor(1.3271)\n",
      "[600, 800] loss:  tensor([0.2929, 0.4962, 0.4400, 0.0982]) tensor(1.3273)\n",
      "[800, 1000] loss:  tensor([0.2931, 0.4965, 0.4457, 0.0973]) tensor(1.3325)\n",
      "[1000, 1200] loss:  tensor([0.2983, 0.4990, 0.4463, 0.0994]) tensor(1.3430)\n",
      "[1200, 1400] loss:  tensor([0.2940, 0.4979, 0.4454, 0.0992]) tensor(1.3365)\n",
      "[1400, 1600] loss:  tensor([0.2927, 0.4979, 0.4446, 0.0974]) tensor(1.3325)\n",
      "[1600, 1800] loss:  tensor([0.2953, 0.4955, 0.4451, 0.0981]) tensor(1.3341)\n",
      "[1800, 2000] loss:  tensor([0.2967, 0.4977, 0.4437, 0.0965]) tensor(1.3346)\n",
      "[2000, 2200] loss:  tensor([0.2939, 0.4953, 0.4456, 0.0986]) tensor(1.3333)\n",
      "[2200, 2400] loss:  tensor([0.2929, 0.4954, 0.4393, 0.0990]) tensor(1.3265)\n",
      "[2400, 2600] loss:  tensor([0.2930, 0.4937, 0.4459, 0.0983]) tensor(1.3309)\n",
      "[2600, 2800] loss:  tensor([0.2895, 0.4944, 0.4445, 0.0990]) tensor(1.3274)\n",
      "[2800, 3000] loss:  tensor([0.2952, 0.4972, 0.4408, 0.0988]) tensor(1.3320)\n",
      "[3000, 3200] loss:  tensor([0.2934, 0.4956, 0.4477, 0.0987]) tensor(1.3355)\n",
      "[3200, 3400] loss:  tensor([0.2951, 0.4966, 0.4471, 0.0980]) tensor(1.3368)\n",
      "[3400, 3600] loss:  tensor([0.2907, 0.4945, 0.4459, 0.0986]) tensor(1.3297)\n",
      "[3600, 3800] loss:  tensor([0.2926, 0.4940, 0.4465, 0.0985]) tensor(1.3316)\n",
      "[3800, 4000] loss:  tensor([0.2955, 0.5007, 0.4432, 0.0989]) tensor(1.3382)\n",
      "[4000, 4200] loss:  tensor([0.2923, 0.4925, 0.4416, 0.0988]) tensor(1.3252)\n",
      "[4200, 4400] loss:  tensor([0.2943, 0.5018, 0.4459, 0.0990]) tensor(1.3410)\n",
      "[4400, 4600] loss:  tensor([0.2931, 0.4972, 0.4442, 0.0981]) tensor(1.3326)\n",
      "[4600, 4800] loss:  tensor([0.2930, 0.4987, 0.4423, 0.0980]) tensor(1.3320)\n",
      "[4800, 5000] loss:  tensor([0.2949, 0.4917, 0.4474, 0.0986]) tensor(1.3326)\n",
      "[5000, 5200] loss:  tensor([0.2942, 0.4931, 0.4446, 0.0977]) tensor(1.3296)\n",
      "[5200, 5400] loss:  tensor([0.2934, 0.4944, 0.4448, 0.0982]) tensor(1.3308)\n",
      "[5400, 5600] loss:  tensor([0.2958, 0.4970, 0.4453, 0.0991]) tensor(1.3373)\n",
      "[5600, 5800] loss:  tensor([0.2956, 0.4939, 0.4466, 0.0979]) tensor(1.3340)\n",
      "[5800, 6000] loss:  tensor([0.2964, 0.4945, 0.4462, 0.0981]) tensor(1.3352)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff7b3c6077e492793f82ab4bd47def4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 21: tensor([0.3641, 0.5249, 0.4662, 0.2204]) 1.5755831480205462\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2226f58c8e4d6b8366b346be70d478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.2886, 0.4948, 0.4413, 0.0980]) tensor(1.3228)\n",
      "[200, 400] loss:  tensor([0.2925, 0.4953, 0.4435, 0.0968]) tensor(1.3281)\n",
      "[400, 600] loss:  tensor([0.2959, 0.4914, 0.4455, 0.0983]) tensor(1.3312)\n",
      "[600, 800] loss:  tensor([0.2928, 0.4937, 0.4446, 0.0983]) tensor(1.3294)\n",
      "[800, 1000] loss:  tensor([0.2948, 0.4964, 0.4408, 0.0980]) tensor(1.3300)\n",
      "[1000, 1200] loss:  tensor([0.2940, 0.4935, 0.4458, 0.0994]) tensor(1.3327)\n",
      "[1200, 1400] loss:  tensor([0.2929, 0.4928, 0.4426, 0.0979]) tensor(1.3262)\n",
      "[1400, 1600] loss:  tensor([0.2930, 0.4920, 0.4422, 0.0986]) tensor(1.3259)\n",
      "[1600, 1800] loss:  tensor([0.2950, 0.4922, 0.4442, 0.0979]) tensor(1.3293)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-7508c13e76fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mT_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mT_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0ml1_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mT_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruoshi/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruoshi/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruoshi/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruoshi/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruoshi/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0m_start_new_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_active_limbo_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_set = objaverse_sfm(dataset_root, 4, train=True, transform = ToTensor())\n",
    "train_dataloader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=64, drop_last=False)\n",
    "\n",
    "test_set = objaverse_sfm(dataset_root, 4, train=False, transform = ToTensor())\n",
    "test_dataloader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=64, drop_last=False)\n",
    "\n",
    "model = sfm(resnet=True).to(device)\n",
    "\n",
    "print('\\n================== total trainable parameters: %d ==================\\n' % sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)\n",
    "\n",
    "# model = torch.nn.DataParallel(model, device_ids=[6, 7])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.1)\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    print('validation')\n",
    "    model.eval()\n",
    "    test_loss = torch.zeros(4).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(test_dataloader, 0), total=len(test_dataloader)):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            image_target, image_cond, T_gt = \\\n",
    "                batch['image_target'].to(device), batch['image_cond'].to(device), batch['T'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            T_pred = model(image_cond, image_target)\n",
    "            loss = (T_pred - T_gt).abs()\n",
    "            test_loss += loss.sum(dim=0)\n",
    "    \n",
    "    print('validation loss for epoch %d:' % epoch, test_loss.cpu() / len(test_set), test_loss.cpu().sum().item() / len(test_set))\n",
    "    \n",
    "    running_loss = torch.zeros(4).to(device)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(train_dataloader, 0), total=len(train_dataloader)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        image_target, image_cond, T_gt = \\\n",
    "            batch['image_target'].to(device), batch['image_cond'].to(device), batch['T'].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        T_pred = model(image_cond, image_target)\n",
    "        loss = ((T_pred - T_gt)**2).mean(dim=0)\n",
    "        l1_loss = ((T_pred - T_gt).abs()).mean(dim=0)\n",
    "        running_loss += l1_loss.detach()\n",
    "        loss = loss.sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'[{i-199}, {i+1:d}] loss: ', running_loss.detach().cpu() / 200, \\\n",
    "                  running_loss.detach().cpu().sum() / 200)\n",
    "            running_loss = torch.zeros(4).to(device)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72ca8da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing resnet weights\n",
      "\n",
      "================== total trainable parameters: 8677380 ==================\n",
      "\n",
      "cnn.conv1.weight torch.Size([64, 6, 7, 7])\n",
      "cnn.bn1.weight torch.Size([64])\n",
      "cnn.bn1.bias torch.Size([64])\n",
      "cnn.layer4.0.conv1.weight torch.Size([512, 256, 3, 3])\n",
      "cnn.layer4.0.bn1.weight torch.Size([512])\n",
      "cnn.layer4.0.bn1.bias torch.Size([512])\n",
      "cnn.layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "cnn.layer4.0.bn2.weight torch.Size([512])\n",
      "cnn.layer4.0.bn2.bias torch.Size([512])\n",
      "cnn.layer4.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "cnn.layer4.0.downsample.1.weight torch.Size([512])\n",
      "cnn.layer4.0.downsample.1.bias torch.Size([512])\n",
      "cnn.layer4.1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "cnn.layer4.1.bn1.weight torch.Size([512])\n",
      "cnn.layer4.1.bn1.bias torch.Size([512])\n",
      "cnn.layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "cnn.layer4.1.bn2.weight torch.Size([512])\n",
      "cnn.layer4.1.bn2.bias torch.Size([512])\n",
      "linear1.weight torch.Size([512, 512])\n",
      "linear1.bias torch.Size([512])\n",
      "linear2.weight torch.Size([4, 512])\n",
      "linear2.bias torch.Size([4])\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d604486dc20d4402ac07844ba49ba179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 0: tensor([0.7673, 0.6362, 0.6355, 0.2494]) 2.288342618547983\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec8c6e0e2aa44b59d8b74358e967a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.6100, 0.6377, 0.6343, 0.1830]) tensor(2.0650)\n",
      "[200, 400] loss:  tensor([0.5451, 0.6400, 0.6271, 0.1669]) tensor(1.9791)\n",
      "[400, 600] loss:  tensor([0.5230, 0.6376, 0.6221, 0.1579]) tensor(1.9406)\n",
      "[600, 800] loss:  tensor([0.5085, 0.6405, 0.6128, 0.1560]) tensor(1.9178)\n",
      "[800, 1000] loss:  tensor([0.4991, 0.6318, 0.6167, 0.1528]) tensor(1.9004)\n",
      "[1000, 1200] loss:  tensor([0.4901, 0.6396, 0.6111, 0.1493]) tensor(1.8900)\n",
      "[1200, 1400] loss:  tensor([0.4919, 0.6355, 0.6108, 0.1493]) tensor(1.8875)\n",
      "[1400, 1600] loss:  tensor([0.4757, 0.6398, 0.6017, 0.1456]) tensor(1.8629)\n",
      "[1600, 1800] loss:  tensor([0.4697, 0.6348, 0.6084, 0.1428]) tensor(1.8557)\n",
      "[1800, 2000] loss:  tensor([0.4670, 0.6384, 0.6060, 0.1430]) tensor(1.8545)\n",
      "[2000, 2200] loss:  tensor([0.4684, 0.6418, 0.5965, 0.1406]) tensor(1.8472)\n",
      "[2200, 2400] loss:  tensor([0.4615, 0.6384, 0.6001, 0.1400]) tensor(1.8401)\n",
      "[2400, 2600] loss:  tensor([0.4582, 0.6339, 0.5986, 0.1406]) tensor(1.8313)\n",
      "[2600, 2800] loss:  tensor([0.4508, 0.6320, 0.6012, 0.1387]) tensor(1.8227)\n",
      "[2800, 3000] loss:  tensor([0.4589, 0.6355, 0.5930, 0.1394]) tensor(1.8268)\n",
      "[3000, 3200] loss:  tensor([0.4544, 0.6300, 0.5997, 0.1363]) tensor(1.8202)\n",
      "[3200, 3400] loss:  tensor([0.4490, 0.6322, 0.5989, 0.1371]) tensor(1.8172)\n",
      "[3400, 3600] loss:  tensor([0.4526, 0.6368, 0.5929, 0.1358]) tensor(1.8180)\n",
      "[3600, 3800] loss:  tensor([0.4484, 0.6344, 0.5921, 0.1344]) tensor(1.8093)\n",
      "[3800, 4000] loss:  tensor([0.4462, 0.6341, 0.5894, 0.1338]) tensor(1.8036)\n",
      "[4000, 4200] loss:  tensor([0.4444, 0.6316, 0.5925, 0.1337]) tensor(1.8021)\n",
      "[4200, 4400] loss:  tensor([0.4509, 0.6339, 0.5908, 0.1325]) tensor(1.8081)\n",
      "[4400, 4600] loss:  tensor([0.4387, 0.6391, 0.5831, 0.1342]) tensor(1.7951)\n",
      "[4600, 4800] loss:  tensor([0.4386, 0.6348, 0.5847, 0.1337]) tensor(1.7918)\n",
      "[4800, 5000] loss:  tensor([0.4331, 0.6341, 0.5913, 0.1328]) tensor(1.7913)\n",
      "[5000, 5200] loss:  tensor([0.4363, 0.6286, 0.5903, 0.1322]) tensor(1.7874)\n",
      "[5200, 5400] loss:  tensor([0.4373, 0.6249, 0.5904, 0.1326]) tensor(1.7851)\n",
      "[5400, 5600] loss:  tensor([0.4359, 0.6298, 0.5837, 0.1316]) tensor(1.7810)\n",
      "[5600, 5800] loss:  tensor([0.4357, 0.6304, 0.5824, 0.1301]) tensor(1.7785)\n",
      "[5800, 6000] loss:  tensor([0.4356, 0.6317, 0.5824, 0.1313]) tensor(1.7810)\n",
      "[6000, 6200] loss:  tensor([0.4335, 0.6284, 0.5813, 0.1310]) tensor(1.7742)\n",
      "[6200, 6400] loss:  tensor([0.4325, 0.6313, 0.5787, 0.1295]) tensor(1.7720)\n",
      "[6400, 6600] loss:  tensor([0.4207, 0.6306, 0.5817, 0.1299]) tensor(1.7629)\n",
      "[6600, 6800] loss:  tensor([0.4256, 0.6298, 0.5794, 0.1311]) tensor(1.7659)\n",
      "[6800, 7000] loss:  tensor([0.4233, 0.6275, 0.5809, 0.1282]) tensor(1.7599)\n",
      "[7000, 7200] loss:  tensor([0.4221, 0.6248, 0.5800, 0.1280]) tensor(1.7548)\n",
      "[7200, 7400] loss:  tensor([0.4254, 0.6306, 0.5761, 0.1299]) tensor(1.7621)\n",
      "[7400, 7600] loss:  tensor([0.4269, 0.6277, 0.5780, 0.1309]) tensor(1.7635)\n",
      "[7600, 7800] loss:  tensor([0.4213, 0.6255, 0.5795, 0.1291]) tensor(1.7554)\n",
      "[7800, 8000] loss:  tensor([0.4199, 0.6259, 0.5774, 0.1283]) tensor(1.7514)\n",
      "[8000, 8200] loss:  tensor([0.4212, 0.6252, 0.5756, 0.1275]) tensor(1.7495)\n",
      "[8200, 8400] loss:  tensor([0.4243, 0.6263, 0.5759, 0.1283]) tensor(1.7547)\n",
      "[8400, 8600] loss:  tensor([0.4199, 0.6287, 0.5720, 0.1286]) tensor(1.7492)\n",
      "[8600, 8800] loss:  tensor([0.4220, 0.6258, 0.5733, 0.1280]) tensor(1.7491)\n",
      "[8800, 9000] loss:  tensor([0.4164, 0.6263, 0.5681, 0.1284]) tensor(1.7392)\n",
      "[9000, 9200] loss:  tensor([0.4183, 0.6324, 0.5714, 0.1259]) tensor(1.7480)\n",
      "[9200, 9400] loss:  tensor([0.4185, 0.6252, 0.5730, 0.1289]) tensor(1.7456)\n",
      "[9400, 9600] loss:  tensor([0.4213, 0.6269, 0.5749, 0.1265]) tensor(1.7495)\n",
      "[9600, 9800] loss:  tensor([0.4159, 0.6210, 0.5752, 0.1287]) tensor(1.7409)\n",
      "[9800, 10000] loss:  tensor([0.4055, 0.6254, 0.5699, 0.1266]) tensor(1.7274)\n",
      "[10000, 10200] loss:  tensor([0.4103, 0.6235, 0.5692, 0.1272]) tensor(1.7301)\n",
      "[10200, 10400] loss:  tensor([0.4115, 0.6241, 0.5636, 0.1266]) tensor(1.7259)\n",
      "[10400, 10600] loss:  tensor([0.4130, 0.6208, 0.5666, 0.1262]) tensor(1.7267)\n",
      "[10600, 10800] loss:  tensor([0.4112, 0.6174, 0.5697, 0.1273]) tensor(1.7256)\n",
      "[10800, 11000] loss:  tensor([0.4153, 0.6218, 0.5738, 0.1256]) tensor(1.7365)\n",
      "[11000, 11200] loss:  tensor([0.4104, 0.6206, 0.5682, 0.1250]) tensor(1.7243)\n",
      "[11200, 11400] loss:  tensor([0.4131, 0.6213, 0.5629, 0.1280]) tensor(1.7253)\n",
      "[11400, 11600] loss:  tensor([0.4173, 0.6209, 0.5649, 0.1245]) tensor(1.7276)\n",
      "[11600, 11800] loss:  tensor([0.4125, 0.6180, 0.5645, 0.1258]) tensor(1.7208)\n",
      "[11800, 12000] loss:  tensor([0.4049, 0.6200, 0.5655, 0.1253]) tensor(1.7157)\n",
      "[12000, 12200] loss:  tensor([0.4093, 0.6187, 0.5698, 0.1268]) tensor(1.7245)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e3d429859b47e2856564e43c9e6132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 1: tensor([0.4159, 0.6201, 0.5756, 0.1390]) 1.750625308310887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362bf3aaccc84420be23b419d4ebd402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.4070, 0.6233, 0.5595, 0.1251]) tensor(1.7149)\n",
      "[200, 400] loss:  tensor([0.4047, 0.6182, 0.5646, 0.1238]) tensor(1.7113)\n",
      "[400, 600] loss:  tensor([0.4099, 0.6173, 0.5659, 0.1230]) tensor(1.7162)\n",
      "[600, 800] loss:  tensor([0.4038, 0.6190, 0.5599, 0.1262]) tensor(1.7089)\n",
      "[800, 1000] loss:  tensor([0.4029, 0.6196, 0.5558, 0.1244]) tensor(1.7027)\n",
      "[1000, 1200] loss:  tensor([0.3992, 0.6150, 0.5660, 0.1243]) tensor(1.7046)\n",
      "[1200, 1400] loss:  tensor([0.4004, 0.6131, 0.5665, 0.1238]) tensor(1.7039)\n",
      "[1400, 1600] loss:  tensor([0.4006, 0.6150, 0.5596, 0.1245]) tensor(1.6998)\n",
      "[1600, 1800] loss:  tensor([0.4000, 0.6148, 0.5629, 0.1234]) tensor(1.7011)\n",
      "[1800, 2000] loss:  tensor([0.4035, 0.6136, 0.5624, 0.1241]) tensor(1.7036)\n",
      "[2000, 2200] loss:  tensor([0.4081, 0.6118, 0.5648, 0.1229]) tensor(1.7076)\n",
      "[2200, 2400] loss:  tensor([0.4048, 0.6183, 0.5536, 0.1231]) tensor(1.6999)\n",
      "[2400, 2600] loss:  tensor([0.4013, 0.6170, 0.5534, 0.1225]) tensor(1.6942)\n",
      "[2600, 2800] loss:  tensor([0.4023, 0.6187, 0.5558, 0.1227]) tensor(1.6995)\n",
      "[2800, 3000] loss:  tensor([0.3984, 0.6135, 0.5575, 0.1248]) tensor(1.6941)\n",
      "[3000, 3200] loss:  tensor([0.3986, 0.6118, 0.5570, 0.1216]) tensor(1.6890)\n",
      "[3200, 3400] loss:  tensor([0.4022, 0.6121, 0.5619, 0.1225]) tensor(1.6987)\n",
      "[3400, 3600] loss:  tensor([0.4007, 0.6184, 0.5545, 0.1250]) tensor(1.6986)\n",
      "[3600, 3800] loss:  tensor([0.3955, 0.6070, 0.5604, 0.1232]) tensor(1.6861)\n",
      "[3800, 4000] loss:  tensor([0.4056, 0.6149, 0.5567, 0.1239]) tensor(1.7012)\n",
      "[4000, 4200] loss:  tensor([0.3993, 0.6104, 0.5552, 0.1230]) tensor(1.6879)\n",
      "[4200, 4400] loss:  tensor([0.4002, 0.6140, 0.5559, 0.1228]) tensor(1.6929)\n",
      "[4400, 4600] loss:  tensor([0.3985, 0.6088, 0.5568, 0.1221]) tensor(1.6863)\n",
      "[4600, 4800] loss:  tensor([0.3977, 0.6168, 0.5555, 0.1225]) tensor(1.6925)\n",
      "[4800, 5000] loss:  tensor([0.3986, 0.6122, 0.5549, 0.1223]) tensor(1.6879)\n",
      "[5000, 5200] loss:  tensor([0.3956, 0.6110, 0.5541, 0.1228]) tensor(1.6835)\n",
      "[5200, 5400] loss:  tensor([0.3961, 0.6119, 0.5543, 0.1220]) tensor(1.6843)\n",
      "[5400, 5600] loss:  tensor([0.3990, 0.6101, 0.5537, 0.1222]) tensor(1.6850)\n",
      "[5600, 5800] loss:  tensor([0.3969, 0.6130, 0.5522, 0.1226]) tensor(1.6848)\n",
      "[5800, 6000] loss:  tensor([0.3948, 0.6090, 0.5564, 0.1234]) tensor(1.6836)\n",
      "[6000, 6200] loss:  tensor([0.4035, 0.6041, 0.5580, 0.1234]) tensor(1.6890)\n",
      "[6200, 6400] loss:  tensor([0.3924, 0.6118, 0.5549, 0.1218]) tensor(1.6810)\n",
      "[6400, 6600] loss:  tensor([0.3931, 0.6127, 0.5536, 0.1212]) tensor(1.6806)\n",
      "[6600, 6800] loss:  tensor([0.3884, 0.6093, 0.5517, 0.1221]) tensor(1.6715)\n",
      "[6800, 7000] loss:  tensor([0.3932, 0.6097, 0.5480, 0.1230]) tensor(1.6739)\n",
      "[7000, 7200] loss:  tensor([0.3886, 0.6091, 0.5555, 0.1218]) tensor(1.6749)\n",
      "[7200, 7400] loss:  tensor([0.3880, 0.6053, 0.5545, 0.1215]) tensor(1.6692)\n",
      "[7400, 7600] loss:  tensor([0.3921, 0.6086, 0.5491, 0.1226]) tensor(1.6724)\n",
      "[7600, 7800] loss:  tensor([0.3934, 0.6096, 0.5525, 0.1219]) tensor(1.6773)\n",
      "[7800, 8000] loss:  tensor([0.3884, 0.6086, 0.5506, 0.1191]) tensor(1.6668)\n",
      "[8000, 8200] loss:  tensor([0.3893, 0.6069, 0.5468, 0.1211]) tensor(1.6642)\n",
      "[8200, 8400] loss:  tensor([0.3916, 0.6099, 0.5491, 0.1210]) tensor(1.6715)\n",
      "[8400, 8600] loss:  tensor([0.3753, 0.6049, 0.5460, 0.1202]) tensor(1.6464)\n",
      "[8600, 8800] loss:  tensor([0.3918, 0.6094, 0.5450, 0.1222]) tensor(1.6684)\n",
      "[8800, 9000] loss:  tensor([0.3861, 0.6083, 0.5464, 0.1187]) tensor(1.6594)\n",
      "[9000, 9200] loss:  tensor([0.3851, 0.6118, 0.5458, 0.1225]) tensor(1.6651)\n",
      "[9200, 9400] loss:  tensor([0.3890, 0.6090, 0.5448, 0.1199]) tensor(1.6627)\n",
      "[9400, 9600] loss:  tensor([0.3886, 0.6069, 0.5502, 0.1214]) tensor(1.6672)\n",
      "[9600, 9800] loss:  tensor([0.3876, 0.6077, 0.5492, 0.1208]) tensor(1.6653)\n",
      "[9800, 10000] loss:  tensor([0.3889, 0.6045, 0.5530, 0.1201]) tensor(1.6665)\n",
      "[10000, 10200] loss:  tensor([0.3848, 0.6108, 0.5470, 0.1218]) tensor(1.6645)\n",
      "[10200, 10400] loss:  tensor([0.3910, 0.6103, 0.5476, 0.1199]) tensor(1.6689)\n",
      "[10400, 10600] loss:  tensor([0.3929, 0.6054, 0.5430, 0.1206]) tensor(1.6619)\n",
      "[10600, 10800] loss:  tensor([0.3889, 0.6079, 0.5424, 0.1217]) tensor(1.6609)\n",
      "[10800, 11000] loss:  tensor([0.3864, 0.6044, 0.5463, 0.1195]) tensor(1.6567)\n",
      "[11000, 11200] loss:  tensor([0.3872, 0.6028, 0.5457, 0.1213]) tensor(1.6570)\n",
      "[11200, 11400] loss:  tensor([0.3857, 0.6061, 0.5466, 0.1188]) tensor(1.6572)\n",
      "[11400, 11600] loss:  tensor([0.3876, 0.6044, 0.5454, 0.1206]) tensor(1.6581)\n",
      "[11600, 11800] loss:  tensor([0.3859, 0.6081, 0.5513, 0.1203]) tensor(1.6656)\n",
      "[11800, 12000] loss:  tensor([0.3864, 0.6113, 0.5375, 0.1211]) tensor(1.6564)\n",
      "[12000, 12200] loss:  tensor([0.3865, 0.6049, 0.5408, 0.1203]) tensor(1.6526)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75e07bfdf3f4e06b995f9a66bca3740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 2: tensor([0.5251, 0.6194, 0.5622, 0.2801]) 1.9868236246398145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f49e62d1834660a51fd58291b9a19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3833, 0.6070, 0.5440, 0.1202]) tensor(1.6545)\n",
      "[200, 400] loss:  tensor([0.3810, 0.6020, 0.5487, 0.1188]) tensor(1.6505)\n",
      "[400, 600] loss:  tensor([0.3823, 0.6070, 0.5445, 0.1201]) tensor(1.6539)\n",
      "[600, 800] loss:  tensor([0.3839, 0.6063, 0.5442, 0.1208]) tensor(1.6551)\n",
      "[800, 1000] loss:  tensor([0.3831, 0.6061, 0.5433, 0.1198]) tensor(1.6522)\n",
      "[1000, 1200] loss:  tensor([0.3898, 0.5992, 0.5402, 0.1214]) tensor(1.6506)\n",
      "[1200, 1400] loss:  tensor([0.3827, 0.6049, 0.5435, 0.1199]) tensor(1.6511)\n",
      "[1400, 1600] loss:  tensor([0.3829, 0.6077, 0.5393, 0.1194]) tensor(1.6493)\n",
      "[1600, 1800] loss:  tensor([0.3911, 0.6005, 0.5452, 0.1200]) tensor(1.6568)\n",
      "[1800, 2000] loss:  tensor([0.3818, 0.6014, 0.5469, 0.1205]) tensor(1.6507)\n",
      "[2000, 2200] loss:  tensor([0.3815, 0.6060, 0.5394, 0.1203]) tensor(1.6473)\n",
      "[2200, 2400] loss:  tensor([0.3854, 0.6012, 0.5423, 0.1193]) tensor(1.6482)\n",
      "[2400, 2600] loss:  tensor([0.3844, 0.5997, 0.5503, 0.1196]) tensor(1.6540)\n",
      "[2600, 2800] loss:  tensor([0.3776, 0.6008, 0.5407, 0.1176]) tensor(1.6366)\n",
      "[2800, 3000] loss:  tensor([0.3752, 0.6002, 0.5455, 0.1226]) tensor(1.6435)\n",
      "[3000, 3200] loss:  tensor([0.3834, 0.5960, 0.5455, 0.1187]) tensor(1.6435)\n",
      "[3200, 3400] loss:  tensor([0.3817, 0.6035, 0.5384, 0.1191]) tensor(1.6426)\n",
      "[3400, 3600] loss:  tensor([0.3814, 0.6003, 0.5420, 0.1188]) tensor(1.6425)\n",
      "[3600, 3800] loss:  tensor([0.3774, 0.6062, 0.5357, 0.1188]) tensor(1.6381)\n",
      "[3800, 4000] loss:  tensor([0.3821, 0.6011, 0.5402, 0.1200]) tensor(1.6434)\n",
      "[4000, 4200] loss:  tensor([0.3818, 0.6033, 0.5351, 0.1185]) tensor(1.6386)\n",
      "[4200, 4400] loss:  tensor([0.3759, 0.6047, 0.5442, 0.1188]) tensor(1.6436)\n",
      "[4400, 4600] loss:  tensor([0.3772, 0.5988, 0.5401, 0.1189]) tensor(1.6350)\n",
      "[4600, 4800] loss:  tensor([0.3833, 0.5987, 0.5349, 0.1190]) tensor(1.6360)\n",
      "[4800, 5000] loss:  tensor([0.3800, 0.6005, 0.5449, 0.1194]) tensor(1.6448)\n",
      "[5000, 5200] loss:  tensor([0.3838, 0.5949, 0.5468, 0.1197]) tensor(1.6451)\n",
      "[5200, 5400] loss:  tensor([0.3825, 0.5988, 0.5433, 0.1185]) tensor(1.6431)\n",
      "[5400, 5600] loss:  tensor([0.3746, 0.5979, 0.5414, 0.1166]) tensor(1.6305)\n",
      "[5600, 5800] loss:  tensor([0.3768, 0.6039, 0.5377, 0.1184]) tensor(1.6369)\n",
      "[5800, 6000] loss:  tensor([0.3813, 0.5960, 0.5380, 0.1186]) tensor(1.6339)\n",
      "[6000, 6200] loss:  tensor([0.3767, 0.5988, 0.5319, 0.1184]) tensor(1.6258)\n",
      "[6200, 6400] loss:  tensor([0.3777, 0.6022, 0.5451, 0.1197]) tensor(1.6448)\n",
      "[6400, 6600] loss:  tensor([0.3822, 0.5974, 0.5370, 0.1182]) tensor(1.6348)\n",
      "[6600, 6800] loss:  tensor([0.3808, 0.5999, 0.5330, 0.1187]) tensor(1.6325)\n",
      "[6800, 7000] loss:  tensor([0.3813, 0.5967, 0.5350, 0.1187]) tensor(1.6316)\n",
      "[7000, 7200] loss:  tensor([0.3817, 0.5994, 0.5355, 0.1170]) tensor(1.6336)\n",
      "[7200, 7400] loss:  tensor([0.3787, 0.5975, 0.5406, 0.1197]) tensor(1.6365)\n",
      "[7400, 7600] loss:  tensor([0.3802, 0.5940, 0.5395, 0.1200]) tensor(1.6338)\n",
      "[7600, 7800] loss:  tensor([0.3743, 0.5925, 0.5388, 0.1176]) tensor(1.6232)\n",
      "[7800, 8000] loss:  tensor([0.3719, 0.5979, 0.5403, 0.1166]) tensor(1.6267)\n",
      "[8000, 8200] loss:  tensor([0.3766, 0.5980, 0.5354, 0.1181]) tensor(1.6281)\n",
      "[8200, 8400] loss:  tensor([0.3799, 0.6014, 0.5368, 0.1196]) tensor(1.6377)\n",
      "[8400, 8600] loss:  tensor([0.3747, 0.6018, 0.5345, 0.1182]) tensor(1.6292)\n",
      "[8600, 8800] loss:  tensor([0.3791, 0.5944, 0.5378, 0.1174]) tensor(1.6288)\n",
      "[8800, 9000] loss:  tensor([0.3698, 0.5977, 0.5325, 0.1170]) tensor(1.6170)\n",
      "[9000, 9200] loss:  tensor([0.3709, 0.5958, 0.5402, 0.1173]) tensor(1.6242)\n",
      "[9200, 9400] loss:  tensor([0.3744, 0.6009, 0.5347, 0.1170]) tensor(1.6269)\n",
      "[9400, 9600] loss:  tensor([0.3729, 0.5967, 0.5359, 0.1175]) tensor(1.6230)\n",
      "[9600, 9800] loss:  tensor([0.3755, 0.5892, 0.5331, 0.1183]) tensor(1.6161)\n",
      "[9800, 10000] loss:  tensor([0.3647, 0.5918, 0.5409, 0.1197]) tensor(1.6172)\n",
      "[10000, 10200] loss:  tensor([0.3779, 0.5949, 0.5436, 0.1185]) tensor(1.6350)\n",
      "[10200, 10400] loss:  tensor([0.3801, 0.5935, 0.5353, 0.1177]) tensor(1.6266)\n",
      "[10400, 10600] loss:  tensor([0.3715, 0.6028, 0.5329, 0.1171]) tensor(1.6243)\n",
      "[10600, 10800] loss:  tensor([0.3740, 0.5957, 0.5365, 0.1154]) tensor(1.6215)\n",
      "[10800, 11000] loss:  tensor([0.3703, 0.5953, 0.5354, 0.1173]) tensor(1.6184)\n",
      "[11000, 11200] loss:  tensor([0.3804, 0.5945, 0.5337, 0.1168]) tensor(1.6254)\n",
      "[11200, 11400] loss:  tensor([0.3773, 0.5870, 0.5372, 0.1188]) tensor(1.6202)\n",
      "[11400, 11600] loss:  tensor([0.3758, 0.5991, 0.5305, 0.1169]) tensor(1.6223)\n",
      "[11600, 11800] loss:  tensor([0.3705, 0.5941, 0.5359, 0.1193]) tensor(1.6197)\n",
      "[11800, 12000] loss:  tensor([0.3698, 0.5953, 0.5318, 0.1166]) tensor(1.6134)\n",
      "[12000, 12200] loss:  tensor([0.3697, 0.5904, 0.5368, 0.1174]) tensor(1.6143)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959d685833d6462584e19e668cae41d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 3: tensor([0.3763, 0.5941, 0.5367, 0.1226]) 1.6298139319327862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb495424f654be2b46c4a969d8df2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3709, 0.5922, 0.5312, 0.1170]) tensor(1.6113)\n",
      "[200, 400] loss:  tensor([0.3727, 0.5873, 0.5388, 0.1176]) tensor(1.6164)\n",
      "[400, 600] loss:  tensor([0.3732, 0.5942, 0.5296, 0.1159]) tensor(1.6129)\n",
      "[600, 800] loss:  tensor([0.3709, 0.5895, 0.5368, 0.1166]) tensor(1.6138)\n",
      "[800, 1000] loss:  tensor([0.3626, 0.5907, 0.5330, 0.1169]) tensor(1.6033)\n",
      "[1000, 1200] loss:  tensor([0.3734, 0.5914, 0.5398, 0.1164]) tensor(1.6210)\n",
      "[1200, 1400] loss:  tensor([0.3726, 0.5928, 0.5326, 0.1145]) tensor(1.6125)\n",
      "[1400, 1600] loss:  tensor([0.3751, 0.5916, 0.5360, 0.1177]) tensor(1.6205)\n",
      "[1600, 1800] loss:  tensor([0.3726, 0.5944, 0.5351, 0.1157]) tensor(1.6178)\n",
      "[1800, 2000] loss:  tensor([0.3749, 0.5964, 0.5312, 0.1173]) tensor(1.6197)\n",
      "[2000, 2200] loss:  tensor([0.3679, 0.5941, 0.5310, 0.1157]) tensor(1.6086)\n",
      "[2200, 2400] loss:  tensor([0.3648, 0.5951, 0.5317, 0.1180]) tensor(1.6096)\n",
      "[2400, 2600] loss:  tensor([0.3719, 0.5925, 0.5315, 0.1177]) tensor(1.6136)\n",
      "[2600, 2800] loss:  tensor([0.3706, 0.5939, 0.5328, 0.1164]) tensor(1.6136)\n",
      "[2800, 3000] loss:  tensor([0.3687, 0.5895, 0.5343, 0.1154]) tensor(1.6079)\n",
      "[3000, 3200] loss:  tensor([0.3721, 0.5957, 0.5246, 0.1155]) tensor(1.6079)\n",
      "[3200, 3400] loss:  tensor([0.3699, 0.5897, 0.5321, 0.1177]) tensor(1.6094)\n",
      "[3400, 3600] loss:  tensor([0.3679, 0.5892, 0.5319, 0.1167]) tensor(1.6057)\n",
      "[3600, 3800] loss:  tensor([0.3715, 0.5906, 0.5331, 0.1176]) tensor(1.6128)\n",
      "[3800, 4000] loss:  tensor([0.3683, 0.5899, 0.5336, 0.1177]) tensor(1.6095)\n",
      "[4000, 4200] loss:  tensor([0.3630, 0.5934, 0.5276, 0.1135]) tensor(1.5974)\n",
      "[4200, 4400] loss:  tensor([0.3681, 0.5919, 0.5358, 0.1183]) tensor(1.6142)\n",
      "[4400, 4600] loss:  tensor([0.3668, 0.5914, 0.5309, 0.1169]) tensor(1.6060)\n",
      "[4600, 4800] loss:  tensor([0.3665, 0.5888, 0.5333, 0.1168]) tensor(1.6055)\n",
      "[4800, 5000] loss:  tensor([0.3628, 0.5852, 0.5273, 0.1174]) tensor(1.5927)\n",
      "[5000, 5200] loss:  tensor([0.3690, 0.5940, 0.5316, 0.1165]) tensor(1.6110)\n",
      "[5200, 5400] loss:  tensor([0.3679, 0.5897, 0.5286, 0.1178]) tensor(1.6039)\n",
      "[5400, 5600] loss:  tensor([0.3642, 0.5840, 0.5324, 0.1159]) tensor(1.5965)\n",
      "[5600, 5800] loss:  tensor([0.3646, 0.5828, 0.5341, 0.1153]) tensor(1.5967)\n",
      "[5800, 6000] loss:  tensor([0.3624, 0.5884, 0.5273, 0.1175]) tensor(1.5956)\n",
      "[6000, 6200] loss:  tensor([0.3689, 0.5854, 0.5321, 0.1174]) tensor(1.6037)\n",
      "[6200, 6400] loss:  tensor([0.3654, 0.5852, 0.5278, 0.1155]) tensor(1.5939)\n",
      "[6400, 6600] loss:  tensor([0.3708, 0.5852, 0.5276, 0.1145]) tensor(1.5981)\n",
      "[6600, 6800] loss:  tensor([0.3656, 0.5843, 0.5344, 0.1150]) tensor(1.5994)\n",
      "[6800, 7000] loss:  tensor([0.3677, 0.5843, 0.5321, 0.1178]) tensor(1.6018)\n",
      "[7000, 7200] loss:  tensor([0.3635, 0.5897, 0.5329, 0.1171]) tensor(1.6032)\n",
      "[7200, 7400] loss:  tensor([0.3639, 0.5864, 0.5256, 0.1158]) tensor(1.5916)\n",
      "[7400, 7600] loss:  tensor([0.3600, 0.5906, 0.5256, 0.1164]) tensor(1.5926)\n",
      "[7600, 7800] loss:  tensor([0.3615, 0.5862, 0.5339, 0.1160]) tensor(1.5977)\n",
      "[7800, 8000] loss:  tensor([0.3627, 0.5894, 0.5286, 0.1176]) tensor(1.5983)\n",
      "[8000, 8200] loss:  tensor([0.3669, 0.5871, 0.5273, 0.1155]) tensor(1.5969)\n",
      "[8200, 8400] loss:  tensor([0.3620, 0.5787, 0.5287, 0.1147]) tensor(1.5842)\n",
      "[8400, 8600] loss:  tensor([0.3567, 0.5923, 0.5258, 0.1160]) tensor(1.5909)\n",
      "[8600, 8800] loss:  tensor([0.3669, 0.5887, 0.5244, 0.1161]) tensor(1.5960)\n",
      "[8800, 9000] loss:  tensor([0.3686, 0.5893, 0.5316, 0.1181]) tensor(1.6076)\n",
      "[9000, 9200] loss:  tensor([0.3620, 0.5838, 0.5303, 0.1167]) tensor(1.5928)\n",
      "[9200, 9400] loss:  tensor([0.3591, 0.5842, 0.5294, 0.1140]) tensor(1.5867)\n",
      "[9400, 9600] loss:  tensor([0.3665, 0.5850, 0.5284, 0.1162]) tensor(1.5961)\n",
      "[9600, 9800] loss:  tensor([0.3709, 0.5874, 0.5287, 0.1168]) tensor(1.6038)\n",
      "[9800, 10000] loss:  tensor([0.3699, 0.5833, 0.5308, 0.1156]) tensor(1.5996)\n",
      "[10000, 10200] loss:  tensor([0.3583, 0.5885, 0.5322, 0.1161]) tensor(1.5951)\n",
      "[10200, 10400] loss:  tensor([0.3607, 0.5804, 0.5286, 0.1153]) tensor(1.5851)\n",
      "[10400, 10600] loss:  tensor([0.3631, 0.5814, 0.5295, 0.1150]) tensor(1.5890)\n",
      "[10600, 10800] loss:  tensor([0.3714, 0.5830, 0.5337, 0.1167]) tensor(1.6048)\n",
      "[10800, 11000] loss:  tensor([0.3693, 0.5871, 0.5291, 0.1160]) tensor(1.6015)\n",
      "[11000, 11200] loss:  tensor([0.3661, 0.5874, 0.5233, 0.1165]) tensor(1.5934)\n",
      "[11200, 11400] loss:  tensor([0.3555, 0.5888, 0.5319, 0.1169]) tensor(1.5930)\n",
      "[11400, 11600] loss:  tensor([0.3613, 0.5820, 0.5307, 0.1161]) tensor(1.5901)\n",
      "[11600, 11800] loss:  tensor([0.3617, 0.5843, 0.5292, 0.1149]) tensor(1.5902)\n",
      "[11800, 12000] loss:  tensor([0.3579, 0.5861, 0.5282, 0.1145]) tensor(1.5866)\n",
      "[12000, 12200] loss:  tensor([0.3627, 0.5870, 0.5313, 0.1158]) tensor(1.5968)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f8f0b7c6e244299aada9f5b453e57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 4: tensor([0.3520, 0.5799, 0.5292, 0.1344]) 1.5955352668504135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246d7d8ed0534a60bb10d1cb3a01aeb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3684, 0.5801, 0.5256, 0.1154]) tensor(1.5895)\n",
      "[200, 400] loss:  tensor([0.3584, 0.5842, 0.5269, 0.1146]) tensor(1.5841)\n",
      "[400, 600] loss:  tensor([0.3586, 0.5864, 0.5207, 0.1136]) tensor(1.5793)\n",
      "[600, 800] loss:  tensor([0.3573, 0.5871, 0.5270, 0.1139]) tensor(1.5854)\n",
      "[800, 1000] loss:  tensor([0.3630, 0.5841, 0.5296, 0.1159]) tensor(1.5926)\n",
      "[1000, 1200] loss:  tensor([0.3643, 0.5840, 0.5277, 0.1154]) tensor(1.5914)\n",
      "[1200, 1400] loss:  tensor([0.3616, 0.5818, 0.5255, 0.1148]) tensor(1.5837)\n",
      "[1400, 1600] loss:  tensor([0.3672, 0.5824, 0.5260, 0.1151]) tensor(1.5907)\n",
      "[1600, 1800] loss:  tensor([0.3601, 0.5794, 0.5280, 0.1146]) tensor(1.5820)\n",
      "[1800, 2000] loss:  tensor([0.3587, 0.5805, 0.5284, 0.1160]) tensor(1.5837)\n",
      "[2000, 2200] loss:  tensor([0.3570, 0.5807, 0.5233, 0.1140]) tensor(1.5750)\n",
      "[2200, 2400] loss:  tensor([0.3598, 0.5853, 0.5284, 0.1152]) tensor(1.5887)\n",
      "[2400, 2600] loss:  tensor([0.3583, 0.5845, 0.5284, 0.1143]) tensor(1.5855)\n",
      "[2600, 2800] loss:  tensor([0.3577, 0.5838, 0.5240, 0.1150]) tensor(1.5804)\n",
      "[2800, 3000] loss:  tensor([0.3613, 0.5797, 0.5346, 0.1137]) tensor(1.5893)\n",
      "[3000, 3200] loss:  tensor([0.3604, 0.5784, 0.5320, 0.1161]) tensor(1.5868)\n",
      "[3200, 3400] loss:  tensor([0.3666, 0.5844, 0.5260, 0.1160]) tensor(1.5929)\n",
      "[3400, 3600] loss:  tensor([0.3588, 0.5794, 0.5235, 0.1154]) tensor(1.5770)\n",
      "[3600, 3800] loss:  tensor([0.3574, 0.5791, 0.5253, 0.1153]) tensor(1.5771)\n",
      "[3800, 4000] loss:  tensor([0.3612, 0.5811, 0.5222, 0.1149]) tensor(1.5794)\n",
      "[4000, 4200] loss:  tensor([0.3605, 0.5795, 0.5227, 0.1139]) tensor(1.5766)\n",
      "[4200, 4400] loss:  tensor([0.3626, 0.5800, 0.5275, 0.1152]) tensor(1.5852)\n",
      "[4400, 4600] loss:  tensor([0.3588, 0.5794, 0.5276, 0.1135]) tensor(1.5794)\n",
      "[4600, 4800] loss:  tensor([0.3619, 0.5778, 0.5238, 0.1135]) tensor(1.5770)\n",
      "[4800, 5000] loss:  tensor([0.3627, 0.5814, 0.5202, 0.1159]) tensor(1.5803)\n",
      "[5000, 5200] loss:  tensor([0.3561, 0.5782, 0.5209, 0.1145]) tensor(1.5698)\n",
      "[5200, 5400] loss:  tensor([0.3640, 0.5820, 0.5253, 0.1148]) tensor(1.5862)\n",
      "[5400, 5600] loss:  tensor([0.3595, 0.5786, 0.5217, 0.1142]) tensor(1.5741)\n",
      "[5600, 5800] loss:  tensor([0.3626, 0.5744, 0.5265, 0.1138]) tensor(1.5773)\n",
      "[5800, 6000] loss:  tensor([0.3671, 0.5836, 0.5209, 0.1157]) tensor(1.5873)\n",
      "[6000, 6200] loss:  tensor([0.3577, 0.5819, 0.5225, 0.1136]) tensor(1.5757)\n",
      "[6200, 6400] loss:  tensor([0.3569, 0.5811, 0.5179, 0.1148]) tensor(1.5708)\n",
      "[6400, 6600] loss:  tensor([0.3606, 0.5755, 0.5199, 0.1146]) tensor(1.5705)\n",
      "[6600, 6800] loss:  tensor([0.3505, 0.5811, 0.5252, 0.1142]) tensor(1.5710)\n",
      "[6800, 7000] loss:  tensor([0.3517, 0.5779, 0.5262, 0.1159]) tensor(1.5717)\n",
      "[7000, 7200] loss:  tensor([0.3557, 0.5783, 0.5227, 0.1145]) tensor(1.5713)\n",
      "[7200, 7400] loss:  tensor([0.3628, 0.5805, 0.5223, 0.1156]) tensor(1.5812)\n",
      "[7400, 7600] loss:  tensor([0.3618, 0.5767, 0.5279, 0.1147]) tensor(1.5811)\n",
      "[7600, 7800] loss:  tensor([0.3633, 0.5818, 0.5196, 0.1149]) tensor(1.5796)\n",
      "[7800, 8000] loss:  tensor([0.3572, 0.5801, 0.5225, 0.1165]) tensor(1.5763)\n",
      "[8000, 8200] loss:  tensor([0.3658, 0.5806, 0.5266, 0.1147]) tensor(1.5878)\n",
      "[8200, 8400] loss:  tensor([0.3595, 0.5725, 0.5273, 0.1156]) tensor(1.5748)\n",
      "[8400, 8600] loss:  tensor([0.3552, 0.5764, 0.5241, 0.1146]) tensor(1.5704)\n",
      "[8600, 8800] loss:  tensor([0.3568, 0.5787, 0.5269, 0.1133]) tensor(1.5757)\n",
      "[8800, 9000] loss:  tensor([0.3569, 0.5854, 0.5242, 0.1169]) tensor(1.5834)\n",
      "[9000, 9200] loss:  tensor([0.3626, 0.5799, 0.5252, 0.1150]) tensor(1.5826)\n",
      "[9200, 9400] loss:  tensor([0.3618, 0.5801, 0.5180, 0.1159]) tensor(1.5758)\n",
      "[9400, 9600] loss:  tensor([0.3578, 0.5758, 0.5268, 0.1135]) tensor(1.5740)\n",
      "[9600, 9800] loss:  tensor([0.3547, 0.5819, 0.5203, 0.1135]) tensor(1.5704)\n",
      "[9800, 10000] loss:  tensor([0.3619, 0.5774, 0.5261, 0.1158]) tensor(1.5811)\n",
      "[10000, 10200] loss:  tensor([0.3550, 0.5715, 0.5214, 0.1151]) tensor(1.5630)\n",
      "[10200, 10400] loss:  tensor([0.3581, 0.5787, 0.5225, 0.1138]) tensor(1.5731)\n",
      "[10400, 10600] loss:  tensor([0.3607, 0.5843, 0.5263, 0.1134]) tensor(1.5847)\n",
      "[10600, 10800] loss:  tensor([0.3614, 0.5764, 0.5215, 0.1149]) tensor(1.5741)\n",
      "[10800, 11000] loss:  tensor([0.3589, 0.5757, 0.5250, 0.1145]) tensor(1.5740)\n",
      "[11000, 11200] loss:  tensor([0.3650, 0.5794, 0.5264, 0.1141]) tensor(1.5850)\n",
      "[11200, 11400] loss:  tensor([0.3528, 0.5765, 0.5203, 0.1121]) tensor(1.5616)\n",
      "[11400, 11600] loss:  tensor([0.3600, 0.5791, 0.5224, 0.1142]) tensor(1.5758)\n",
      "[11600, 11800] loss:  tensor([0.3537, 0.5746, 0.5224, 0.1144]) tensor(1.5651)\n",
      "[11800, 12000] loss:  tensor([0.3629, 0.5755, 0.5210, 0.1137]) tensor(1.5732)\n",
      "[12000, 12200] loss:  tensor([0.3598, 0.5686, 0.5221, 0.1138]) tensor(1.5644)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f75d50d98c84155b543b9905d02461c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 5: tensor([0.3571, 0.5809, 0.5256, 0.1335]) 1.5971961082357178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e192afa6b074409f865881a4b8a57b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3526, 0.5757, 0.5245, 0.1146]) tensor(1.5675)\n",
      "[200, 400] loss:  tensor([0.3523, 0.5730, 0.5214, 0.1155]) tensor(1.5623)\n",
      "[400, 600] loss:  tensor([0.3659, 0.5796, 0.5228, 0.1160]) tensor(1.5843)\n",
      "[600, 800] loss:  tensor([0.3518, 0.5753, 0.5141, 0.1137]) tensor(1.5549)\n",
      "[800, 1000] loss:  tensor([0.3541, 0.5725, 0.5221, 0.1140]) tensor(1.5627)\n",
      "[1000, 1200] loss:  tensor([0.3574, 0.5775, 0.5198, 0.1140]) tensor(1.5688)\n",
      "[1200, 1400] loss:  tensor([0.3537, 0.5765, 0.5228, 0.1158]) tensor(1.5688)\n",
      "[1400, 1600] loss:  tensor([0.3513, 0.5749, 0.5143, 0.1134]) tensor(1.5540)\n",
      "[1600, 1800] loss:  tensor([0.3579, 0.5778, 0.5166, 0.1134]) tensor(1.5657)\n",
      "[1800, 2000] loss:  tensor([0.3559, 0.5720, 0.5114, 0.1140]) tensor(1.5533)\n",
      "[2000, 2200] loss:  tensor([0.3513, 0.5711, 0.5233, 0.1151]) tensor(1.5609)\n",
      "[2200, 2400] loss:  tensor([0.3546, 0.5721, 0.5246, 0.1150]) tensor(1.5663)\n",
      "[2400, 2600] loss:  tensor([0.3545, 0.5744, 0.5218, 0.1136]) tensor(1.5643)\n",
      "[2600, 2800] loss:  tensor([0.3509, 0.5722, 0.5241, 0.1134]) tensor(1.5607)\n",
      "[2800, 3000] loss:  tensor([0.3535, 0.5694, 0.5178, 0.1124]) tensor(1.5530)\n",
      "[3000, 3200] loss:  tensor([0.3567, 0.5742, 0.5182, 0.1148]) tensor(1.5639)\n",
      "[3200, 3400] loss:  tensor([0.3523, 0.5748, 0.5191, 0.1151]) tensor(1.5614)\n",
      "[3400, 3600] loss:  tensor([0.3558, 0.5703, 0.5159, 0.1159]) tensor(1.5580)\n",
      "[3600, 3800] loss:  tensor([0.3565, 0.5793, 0.5176, 0.1150]) tensor(1.5683)\n",
      "[3800, 4000] loss:  tensor([0.3500, 0.5686, 0.5221, 0.1136]) tensor(1.5542)\n",
      "[4000, 4200] loss:  tensor([0.3570, 0.5685, 0.5264, 0.1150]) tensor(1.5670)\n",
      "[4200, 4400] loss:  tensor([0.3515, 0.5718, 0.5236, 0.1161]) tensor(1.5630)\n",
      "[4400, 4600] loss:  tensor([0.3488, 0.5727, 0.5233, 0.1148]) tensor(1.5596)\n",
      "[4600, 4800] loss:  tensor([0.3535, 0.5776, 0.5209, 0.1152]) tensor(1.5674)\n",
      "[4800, 5000] loss:  tensor([0.3599, 0.5711, 0.5214, 0.1125]) tensor(1.5650)\n",
      "[5000, 5200] loss:  tensor([0.3510, 0.5692, 0.5187, 0.1127]) tensor(1.5516)\n",
      "[5200, 5400] loss:  tensor([0.3590, 0.5737, 0.5233, 0.1150]) tensor(1.5710)\n",
      "[5400, 5600] loss:  tensor([0.3468, 0.5702, 0.5236, 0.1130]) tensor(1.5535)\n",
      "[5600, 5800] loss:  tensor([0.3582, 0.5743, 0.5186, 0.1147]) tensor(1.5658)\n",
      "[5800, 6000] loss:  tensor([0.3590, 0.5738, 0.5221, 0.1133]) tensor(1.5682)\n",
      "[6000, 6200] loss:  tensor([0.3432, 0.5674, 0.5128, 0.1137]) tensor(1.5372)\n",
      "[6200, 6400] loss:  tensor([0.3472, 0.5755, 0.5192, 0.1146]) tensor(1.5565)\n",
      "[6400, 6600] loss:  tensor([0.3537, 0.5693, 0.5156, 0.1140]) tensor(1.5526)\n",
      "[6600, 6800] loss:  tensor([0.3495, 0.5715, 0.5173, 0.1146]) tensor(1.5529)\n",
      "[6800, 7000] loss:  tensor([0.3550, 0.5753, 0.5206, 0.1138]) tensor(1.5648)\n",
      "[7000, 7200] loss:  tensor([0.3474, 0.5726, 0.5152, 0.1138]) tensor(1.5489)\n",
      "[7200, 7400] loss:  tensor([0.3537, 0.5679, 0.5178, 0.1133]) tensor(1.5527)\n",
      "[7400, 7600] loss:  tensor([0.3481, 0.5650, 0.5187, 0.1128]) tensor(1.5446)\n",
      "[7600, 7800] loss:  tensor([0.3481, 0.5674, 0.5188, 0.1141]) tensor(1.5484)\n",
      "[7800, 8000] loss:  tensor([0.3516, 0.5715, 0.5191, 0.1131]) tensor(1.5553)\n",
      "[8000, 8200] loss:  tensor([0.3558, 0.5703, 0.5213, 0.1139]) tensor(1.5615)\n",
      "[8200, 8400] loss:  tensor([0.3595, 0.5716, 0.5183, 0.1132]) tensor(1.5627)\n",
      "[8400, 8600] loss:  tensor([0.3539, 0.5733, 0.5184, 0.1147]) tensor(1.5603)\n",
      "[8600, 8800] loss:  tensor([0.3496, 0.5681, 0.5209, 0.1135]) tensor(1.5522)\n",
      "[8800, 9000] loss:  tensor([0.3535, 0.5740, 0.5166, 0.1131]) tensor(1.5572)\n",
      "[9000, 9200] loss:  tensor([0.3506, 0.5704, 0.5128, 0.1132]) tensor(1.5470)\n",
      "[9200, 9400] loss:  tensor([0.3465, 0.5699, 0.5196, 0.1128]) tensor(1.5487)\n",
      "[9400, 9600] loss:  tensor([0.3552, 0.5685, 0.5194, 0.1135]) tensor(1.5566)\n",
      "[9600, 9800] loss:  tensor([0.3569, 0.5720, 0.5260, 0.1143]) tensor(1.5692)\n",
      "[9800, 10000] loss:  tensor([0.3530, 0.5729, 0.5167, 0.1147]) tensor(1.5574)\n",
      "[10000, 10200] loss:  tensor([0.3483, 0.5654, 0.5154, 0.1124]) tensor(1.5414)\n",
      "[10200, 10400] loss:  tensor([0.3503, 0.5719, 0.5137, 0.1133]) tensor(1.5492)\n",
      "[10400, 10600] loss:  tensor([0.3503, 0.5707, 0.5182, 0.1135]) tensor(1.5527)\n",
      "[10600, 10800] loss:  tensor([0.3561, 0.5701, 0.5174, 0.1138]) tensor(1.5573)\n",
      "[10800, 11000] loss:  tensor([0.3489, 0.5684, 0.5184, 0.1111]) tensor(1.5468)\n",
      "[11000, 11200] loss:  tensor([0.3517, 0.5702, 0.5165, 0.1133]) tensor(1.5518)\n",
      "[11200, 11400] loss:  tensor([0.3541, 0.5716, 0.5190, 0.1126]) tensor(1.5573)\n",
      "[11400, 11600] loss:  tensor([0.3503, 0.5704, 0.5216, 0.1147]) tensor(1.5570)\n",
      "[11600, 11800] loss:  tensor([0.3525, 0.5693, 0.5190, 0.1146]) tensor(1.5554)\n",
      "[11800, 12000] loss:  tensor([0.3546, 0.5734, 0.5196, 0.1141]) tensor(1.5617)\n",
      "[12000, 12200] loss:  tensor([0.3460, 0.5718, 0.5123, 0.1122]) tensor(1.5423)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e846a80e9c4905804fa47f7e4b7cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 6: tensor([0.3576, 0.5653, 0.5176, 0.1228]) 1.5633326840860686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a86ea8c4dc46fe91671ba3a669ea53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3403, 0.5655, 0.5157, 0.1135]) tensor(1.5351)\n",
      "[200, 400] loss:  tensor([0.3442, 0.5688, 0.5159, 0.1128]) tensor(1.5417)\n",
      "[400, 600] loss:  tensor([0.3511, 0.5642, 0.5198, 0.1151]) tensor(1.5502)\n",
      "[600, 800] loss:  tensor([0.3522, 0.5676, 0.5153, 0.1136]) tensor(1.5487)\n",
      "[800, 1000] loss:  tensor([0.3472, 0.5748, 0.5148, 0.1127]) tensor(1.5496)\n",
      "[1000, 1200] loss:  tensor([0.3510, 0.5677, 0.5162, 0.1132]) tensor(1.5481)\n",
      "[1200, 1400] loss:  tensor([0.3514, 0.5740, 0.5179, 0.1140]) tensor(1.5573)\n",
      "[1400, 1600] loss:  tensor([0.3488, 0.5628, 0.5164, 0.1119]) tensor(1.5400)\n",
      "[1600, 1800] loss:  tensor([0.3455, 0.5654, 0.5144, 0.1150]) tensor(1.5403)\n",
      "[1800, 2000] loss:  tensor([0.3476, 0.5665, 0.5149, 0.1128]) tensor(1.5419)\n",
      "[2000, 2200] loss:  tensor([0.3526, 0.5626, 0.5201, 0.1140]) tensor(1.5493)\n",
      "[2200, 2400] loss:  tensor([0.3532, 0.5715, 0.5128, 0.1141]) tensor(1.5516)\n",
      "[2400, 2600] loss:  tensor([0.3515, 0.5660, 0.5178, 0.1138]) tensor(1.5490)\n",
      "[2600, 2800] loss:  tensor([0.3494, 0.5684, 0.5168, 0.1136]) tensor(1.5481)\n",
      "[2800, 3000] loss:  tensor([0.3479, 0.5642, 0.5145, 0.1139]) tensor(1.5405)\n",
      "[3000, 3200] loss:  tensor([0.3495, 0.5661, 0.5102, 0.1127]) tensor(1.5384)\n",
      "[3200, 3400] loss:  tensor([0.3515, 0.5644, 0.5149, 0.1133]) tensor(1.5442)\n",
      "[3400, 3600] loss:  tensor([0.3528, 0.5666, 0.5151, 0.1135]) tensor(1.5480)\n",
      "[3600, 3800] loss:  tensor([0.3503, 0.5596, 0.5166, 0.1121]) tensor(1.5385)\n",
      "[3800, 4000] loss:  tensor([0.3499, 0.5661, 0.5132, 0.1148]) tensor(1.5440)\n",
      "[4000, 4200] loss:  tensor([0.3520, 0.5689, 0.5135, 0.1135]) tensor(1.5479)\n",
      "[4200, 4400] loss:  tensor([0.3500, 0.5692, 0.5126, 0.1148]) tensor(1.5466)\n",
      "[4400, 4600] loss:  tensor([0.3478, 0.5643, 0.5144, 0.1141]) tensor(1.5406)\n",
      "[4600, 4800] loss:  tensor([0.3471, 0.5687, 0.5122, 0.1125]) tensor(1.5404)\n",
      "[4800, 5000] loss:  tensor([0.3437, 0.5689, 0.5101, 0.1134]) tensor(1.5360)\n",
      "[5000, 5200] loss:  tensor([0.3553, 0.5728, 0.5107, 0.1159]) tensor(1.5547)\n",
      "[5200, 5400] loss:  tensor([0.3467, 0.5632, 0.5182, 0.1134]) tensor(1.5414)\n",
      "[5400, 5600] loss:  tensor([0.3433, 0.5664, 0.5191, 0.1149]) tensor(1.5437)\n",
      "[5600, 5800] loss:  tensor([0.3513, 0.5676, 0.5159, 0.1135]) tensor(1.5482)\n",
      "[5800, 6000] loss:  tensor([0.3529, 0.5628, 0.5155, 0.1135]) tensor(1.5447)\n",
      "[6000, 6200] loss:  tensor([0.3444, 0.5644, 0.5146, 0.1131]) tensor(1.5364)\n",
      "[6200, 6400] loss:  tensor([0.3463, 0.5698, 0.5163, 0.1138]) tensor(1.5463)\n",
      "[6400, 6600] loss:  tensor([0.3483, 0.5620, 0.5097, 0.1138]) tensor(1.5337)\n",
      "[6600, 6800] loss:  tensor([0.3446, 0.5651, 0.5125, 0.1151]) tensor(1.5373)\n",
      "[6800, 7000] loss:  tensor([0.3487, 0.5637, 0.5099, 0.1118]) tensor(1.5341)\n",
      "[7000, 7200] loss:  tensor([0.3465, 0.5669, 0.5119, 0.1151]) tensor(1.5404)\n",
      "[7200, 7400] loss:  tensor([0.3488, 0.5606, 0.5117, 0.1131]) tensor(1.5342)\n",
      "[7400, 7600] loss:  tensor([0.3471, 0.5667, 0.5121, 0.1139]) tensor(1.5398)\n",
      "[7600, 7800] loss:  tensor([0.3449, 0.5702, 0.5140, 0.1138]) tensor(1.5429)\n",
      "[7800, 8000] loss:  tensor([0.3521, 0.5601, 0.5193, 0.1132]) tensor(1.5447)\n",
      "[8000, 8200] loss:  tensor([0.3501, 0.5658, 0.5093, 0.1126]) tensor(1.5378)\n",
      "[8200, 8400] loss:  tensor([0.3565, 0.5611, 0.5161, 0.1139]) tensor(1.5475)\n",
      "[8400, 8600] loss:  tensor([0.3490, 0.5707, 0.5077, 0.1141]) tensor(1.5416)\n",
      "[8600, 8800] loss:  tensor([0.3458, 0.5671, 0.5140, 0.1135]) tensor(1.5404)\n",
      "[8800, 9000] loss:  tensor([0.3458, 0.5698, 0.5104, 0.1134]) tensor(1.5393)\n",
      "[9000, 9200] loss:  tensor([0.3514, 0.5631, 0.5165, 0.1125]) tensor(1.5436)\n",
      "[9200, 9400] loss:  tensor([0.3508, 0.5639, 0.5174, 0.1122]) tensor(1.5443)\n",
      "[9400, 9600] loss:  tensor([0.3522, 0.5623, 0.5100, 0.1130]) tensor(1.5375)\n",
      "[9600, 9800] loss:  tensor([0.3419, 0.5609, 0.5133, 0.1135]) tensor(1.5297)\n",
      "[9800, 10000] loss:  tensor([0.3521, 0.5610, 0.5080, 0.1123]) tensor(1.5334)\n",
      "[10000, 10200] loss:  tensor([0.3518, 0.5623, 0.5132, 0.1134]) tensor(1.5407)\n",
      "[10200, 10400] loss:  tensor([0.3536, 0.5595, 0.5185, 0.1150]) tensor(1.5466)\n",
      "[10400, 10600] loss:  tensor([0.3476, 0.5668, 0.5173, 0.1127]) tensor(1.5444)\n",
      "[10600, 10800] loss:  tensor([0.3467, 0.5687, 0.5094, 0.1138]) tensor(1.5386)\n",
      "[10800, 11000] loss:  tensor([0.3450, 0.5657, 0.5090, 0.1124]) tensor(1.5321)\n",
      "[11000, 11200] loss:  tensor([0.3501, 0.5594, 0.5153, 0.1107]) tensor(1.5355)\n",
      "[11200, 11400] loss:  tensor([0.3447, 0.5664, 0.5071, 0.1139]) tensor(1.5320)\n",
      "[11400, 11600] loss:  tensor([0.3441, 0.5632, 0.5149, 0.1129]) tensor(1.5351)\n",
      "[11600, 11800] loss:  tensor([0.3510, 0.5638, 0.5110, 0.1134]) tensor(1.5391)\n",
      "[11800, 12000] loss:  tensor([0.3471, 0.5616, 0.5165, 0.1129]) tensor(1.5380)\n",
      "[12000, 12200] loss:  tensor([0.3476, 0.5639, 0.5118, 0.1125]) tensor(1.5359)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a265cb4622e4460a3fd5c2ca2620e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 7: tensor([0.3512, 0.5703, 0.5146, 0.1193]) 1.5554264673640692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a82eacad624bc4ac2be270abb4f0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3472, 0.5666, 0.5144, 0.1138]) tensor(1.5420)\n",
      "[200, 400] loss:  tensor([0.3461, 0.5617, 0.5148, 0.1117]) tensor(1.5344)\n",
      "[400, 600] loss:  tensor([0.3472, 0.5563, 0.5137, 0.1141]) tensor(1.5313)\n",
      "[600, 800] loss:  tensor([0.3494, 0.5608, 0.5160, 0.1134]) tensor(1.5396)\n",
      "[800, 1000] loss:  tensor([0.3506, 0.5606, 0.5060, 0.1136]) tensor(1.5308)\n",
      "[1000, 1200] loss:  tensor([0.3459, 0.5620, 0.5103, 0.1144]) tensor(1.5327)\n",
      "[1200, 1400] loss:  tensor([0.3412, 0.5632, 0.5104, 0.1113]) tensor(1.5261)\n",
      "[1400, 1600] loss:  tensor([0.3409, 0.5632, 0.5073, 0.1155]) tensor(1.5269)\n",
      "[1600, 1800] loss:  tensor([0.3454, 0.5696, 0.5112, 0.1137]) tensor(1.5399)\n",
      "[1800, 2000] loss:  tensor([0.3457, 0.5638, 0.5064, 0.1127]) tensor(1.5287)\n",
      "[2000, 2200] loss:  tensor([0.3391, 0.5578, 0.5110, 0.1150]) tensor(1.5229)\n",
      "[2200, 2400] loss:  tensor([0.3490, 0.5591, 0.5082, 0.1116]) tensor(1.5279)\n",
      "[2400, 2600] loss:  tensor([0.3453, 0.5621, 0.5095, 0.1146]) tensor(1.5315)\n",
      "[2600, 2800] loss:  tensor([0.3412, 0.5626, 0.5074, 0.1135]) tensor(1.5246)\n",
      "[2800, 3000] loss:  tensor([0.3416, 0.5617, 0.5093, 0.1137]) tensor(1.5262)\n",
      "[3000, 3200] loss:  tensor([0.3505, 0.5593, 0.5063, 0.1136]) tensor(1.5297)\n",
      "[3200, 3400] loss:  tensor([0.3428, 0.5607, 0.5065, 0.1136]) tensor(1.5236)\n",
      "[3400, 3600] loss:  tensor([0.3470, 0.5603, 0.5073, 0.1139]) tensor(1.5285)\n",
      "[3600, 3800] loss:  tensor([0.3415, 0.5602, 0.5064, 0.1127]) tensor(1.5208)\n",
      "[3800, 4000] loss:  tensor([0.3429, 0.5580, 0.5107, 0.1126]) tensor(1.5243)\n",
      "[4000, 4200] loss:  tensor([0.3479, 0.5614, 0.5168, 0.1137]) tensor(1.5399)\n",
      "[4200, 4400] loss:  tensor([0.3435, 0.5605, 0.5128, 0.1121]) tensor(1.5289)\n",
      "[4400, 4600] loss:  tensor([0.3453, 0.5618, 0.5156, 0.1126]) tensor(1.5354)\n",
      "[4600, 4800] loss:  tensor([0.3432, 0.5643, 0.5064, 0.1153]) tensor(1.5292)\n",
      "[4800, 5000] loss:  tensor([0.3414, 0.5562, 0.5112, 0.1126]) tensor(1.5215)\n",
      "[5000, 5200] loss:  tensor([0.3420, 0.5631, 0.5111, 0.1128]) tensor(1.5290)\n",
      "[5200, 5400] loss:  tensor([0.3433, 0.5601, 0.5082, 0.1132]) tensor(1.5249)\n",
      "[5400, 5600] loss:  tensor([0.3453, 0.5551, 0.5128, 0.1146]) tensor(1.5278)\n",
      "[5600, 5800] loss:  tensor([0.3464, 0.5589, 0.5129, 0.1135]) tensor(1.5317)\n",
      "[5800, 6000] loss:  tensor([0.3495, 0.5617, 0.5112, 0.1135]) tensor(1.5359)\n",
      "[6000, 6200] loss:  tensor([0.3420, 0.5623, 0.5113, 0.1135]) tensor(1.5291)\n",
      "[6200, 6400] loss:  tensor([0.3433, 0.5572, 0.5162, 0.1128]) tensor(1.5296)\n",
      "[6400, 6600] loss:  tensor([0.3372, 0.5651, 0.5111, 0.1137]) tensor(1.5271)\n",
      "[6600, 6800] loss:  tensor([0.3439, 0.5610, 0.5048, 0.1136]) tensor(1.5232)\n",
      "[6800, 7000] loss:  tensor([0.3417, 0.5541, 0.5106, 0.1134]) tensor(1.5198)\n",
      "[7000, 7200] loss:  tensor([0.3467, 0.5614, 0.5086, 0.1129]) tensor(1.5297)\n",
      "[7200, 7400] loss:  tensor([0.3414, 0.5627, 0.5166, 0.1131]) tensor(1.5338)\n",
      "[7400, 7600] loss:  tensor([0.3422, 0.5576, 0.5072, 0.1119]) tensor(1.5190)\n",
      "[7600, 7800] loss:  tensor([0.3454, 0.5586, 0.5084, 0.1124]) tensor(1.5249)\n",
      "[7800, 8000] loss:  tensor([0.3451, 0.5640, 0.5078, 0.1131]) tensor(1.5300)\n",
      "[8000, 8200] loss:  tensor([0.3379, 0.5562, 0.5090, 0.1122]) tensor(1.5153)\n",
      "[8200, 8400] loss:  tensor([0.3403, 0.5623, 0.5101, 0.1127]) tensor(1.5255)\n",
      "[8400, 8600] loss:  tensor([0.3443, 0.5680, 0.5114, 0.1138]) tensor(1.5375)\n",
      "[8600, 8800] loss:  tensor([0.3405, 0.5566, 0.5157, 0.1125]) tensor(1.5253)\n",
      "[8800, 9000] loss:  tensor([0.3451, 0.5565, 0.5111, 0.1124]) tensor(1.5250)\n",
      "[9000, 9200] loss:  tensor([0.3469, 0.5615, 0.5113, 0.1124]) tensor(1.5321)\n",
      "[9200, 9400] loss:  tensor([0.3439, 0.5638, 0.5123, 0.1129]) tensor(1.5329)\n",
      "[9400, 9600] loss:  tensor([0.3372, 0.5592, 0.5114, 0.1142]) tensor(1.5220)\n",
      "[9600, 9800] loss:  tensor([0.3457, 0.5609, 0.5078, 0.1106]) tensor(1.5251)\n",
      "[9800, 10000] loss:  tensor([0.3383, 0.5573, 0.5093, 0.1128]) tensor(1.5177)\n",
      "[10000, 10200] loss:  tensor([0.3491, 0.5540, 0.5095, 0.1127]) tensor(1.5253)\n",
      "[10200, 10400] loss:  tensor([0.3456, 0.5547, 0.5091, 0.1143]) tensor(1.5237)\n",
      "[10400, 10600] loss:  tensor([0.3452, 0.5583, 0.5116, 0.1128]) tensor(1.5279)\n",
      "[10600, 10800] loss:  tensor([0.3472, 0.5612, 0.5095, 0.1113]) tensor(1.5292)\n",
      "[10800, 11000] loss:  tensor([0.3392, 0.5579, 0.5074, 0.1122]) tensor(1.5167)\n",
      "[11000, 11200] loss:  tensor([0.3415, 0.5604, 0.5108, 0.1117]) tensor(1.5244)\n",
      "[11200, 11400] loss:  tensor([0.3470, 0.5606, 0.5118, 0.1122]) tensor(1.5316)\n",
      "[11400, 11600] loss:  tensor([0.3469, 0.5619, 0.5099, 0.1123]) tensor(1.5310)\n",
      "[11600, 11800] loss:  tensor([0.3490, 0.5618, 0.5111, 0.1127]) tensor(1.5346)\n",
      "[11800, 12000] loss:  tensor([0.3372, 0.5581, 0.5113, 0.1116]) tensor(1.5182)\n",
      "[12000, 12200] loss:  tensor([0.3449, 0.5589, 0.5067, 0.1112]) tensor(1.5217)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f751b61156c447c8f0e8e572b294a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 8: tensor([0.3781, 0.5734, 0.5256, 0.1365]) 1.6135856458281133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486a2ba32d454db09167737e933477aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3442, 0.5624, 0.5131, 0.1133]) tensor(1.5330)\n",
      "[200, 400] loss:  tensor([0.3486, 0.5572, 0.5069, 0.1137]) tensor(1.5265)\n",
      "[400, 600] loss:  tensor([0.3429, 0.5552, 0.5117, 0.1146]) tensor(1.5245)\n",
      "[600, 800] loss:  tensor([0.3420, 0.5562, 0.5100, 0.1131]) tensor(1.5213)\n",
      "[800, 1000] loss:  tensor([0.3472, 0.5619, 0.5125, 0.1125]) tensor(1.5341)\n",
      "[1000, 1200] loss:  tensor([0.3434, 0.5563, 0.5069, 0.1120]) tensor(1.5186)\n",
      "[1200, 1400] loss:  tensor([0.3479, 0.5618, 0.5042, 0.1122]) tensor(1.5262)\n",
      "[1400, 1600] loss:  tensor([0.3445, 0.5554, 0.5058, 0.1129]) tensor(1.5186)\n",
      "[1600, 1800] loss:  tensor([0.3366, 0.5541, 0.5121, 0.1116]) tensor(1.5144)\n",
      "[1800, 2000] loss:  tensor([0.3370, 0.5537, 0.5024, 0.1113]) tensor(1.5044)\n",
      "[2000, 2200] loss:  tensor([0.3400, 0.5557, 0.5050, 0.1115]) tensor(1.5122)\n",
      "[2200, 2400] loss:  tensor([0.3431, 0.5553, 0.5058, 0.1128]) tensor(1.5170)\n",
      "[2400, 2600] loss:  tensor([0.3402, 0.5592, 0.5132, 0.1126]) tensor(1.5252)\n",
      "[2600, 2800] loss:  tensor([0.3394, 0.5566, 0.5091, 0.1130]) tensor(1.5180)\n",
      "[2800, 3000] loss:  tensor([0.3405, 0.5544, 0.5105, 0.1125]) tensor(1.5178)\n",
      "[3000, 3200] loss:  tensor([0.3427, 0.5500, 0.5101, 0.1128]) tensor(1.5156)\n",
      "[3200, 3400] loss:  tensor([0.3452, 0.5569, 0.5105, 0.1119]) tensor(1.5244)\n",
      "[3400, 3600] loss:  tensor([0.3433, 0.5610, 0.5058, 0.1134]) tensor(1.5235)\n",
      "[3600, 3800] loss:  tensor([0.3485, 0.5576, 0.5072, 0.1118]) tensor(1.5251)\n",
      "[3800, 4000] loss:  tensor([0.3424, 0.5614, 0.5095, 0.1131]) tensor(1.5264)\n",
      "[4000, 4200] loss:  tensor([0.3368, 0.5578, 0.5078, 0.1116]) tensor(1.5139)\n",
      "[4200, 4400] loss:  tensor([0.3421, 0.5612, 0.5099, 0.1117]) tensor(1.5249)\n",
      "[4400, 4600] loss:  tensor([0.3439, 0.5617, 0.5113, 0.1134]) tensor(1.5304)\n",
      "[4600, 4800] loss:  tensor([0.3394, 0.5609, 0.5054, 0.1134]) tensor(1.5191)\n",
      "[4800, 5000] loss:  tensor([0.3443, 0.5591, 0.5084, 0.1121]) tensor(1.5239)\n",
      "[5000, 5200] loss:  tensor([0.3484, 0.5607, 0.5074, 0.1130]) tensor(1.5294)\n",
      "[5200, 5400] loss:  tensor([0.3439, 0.5547, 0.5051, 0.1135]) tensor(1.5172)\n",
      "[5400, 5600] loss:  tensor([0.3463, 0.5568, 0.5011, 0.1139]) tensor(1.5182)\n",
      "[5600, 5800] loss:  tensor([0.3440, 0.5559, 0.5055, 0.1132]) tensor(1.5186)\n",
      "[5800, 6000] loss:  tensor([0.3443, 0.5552, 0.5081, 0.1122]) tensor(1.5198)\n",
      "[6000, 6200] loss:  tensor([0.3458, 0.5615, 0.5113, 0.1132]) tensor(1.5317)\n",
      "[6200, 6400] loss:  tensor([0.3403, 0.5560, 0.5098, 0.1124]) tensor(1.5186)\n",
      "[6400, 6600] loss:  tensor([0.3476, 0.5603, 0.5071, 0.1120]) tensor(1.5270)\n",
      "[6600, 6800] loss:  tensor([0.3410, 0.5541, 0.5124, 0.1140]) tensor(1.5214)\n",
      "[6800, 7000] loss:  tensor([0.3404, 0.5532, 0.5104, 0.1131]) tensor(1.5171)\n",
      "[7000, 7200] loss:  tensor([0.3376, 0.5572, 0.5024, 0.1131]) tensor(1.5104)\n",
      "[7200, 7400] loss:  tensor([0.3424, 0.5535, 0.5078, 0.1112]) tensor(1.5148)\n",
      "[7400, 7600] loss:  tensor([0.3434, 0.5584, 0.5064, 0.1118]) tensor(1.5201)\n",
      "[7600, 7800] loss:  tensor([0.3420, 0.5610, 0.5072, 0.1118]) tensor(1.5220)\n",
      "[7800, 8000] loss:  tensor([0.3462, 0.5603, 0.5078, 0.1131]) tensor(1.5275)\n",
      "[8000, 8200] loss:  tensor([0.3389, 0.5583, 0.5085, 0.1109]) tensor(1.5166)\n",
      "[8200, 8400] loss:  tensor([0.3369, 0.5582, 0.5022, 0.1128]) tensor(1.5102)\n",
      "[8400, 8600] loss:  tensor([0.3386, 0.5612, 0.5061, 0.1115]) tensor(1.5174)\n",
      "[8600, 8800] loss:  tensor([0.3443, 0.5578, 0.5024, 0.1124]) tensor(1.5169)\n",
      "[8800, 9000] loss:  tensor([0.3411, 0.5599, 0.5024, 0.1131]) tensor(1.5165)\n",
      "[9000, 9200] loss:  tensor([0.3395, 0.5592, 0.5038, 0.1126]) tensor(1.5151)\n",
      "[9200, 9400] loss:  tensor([0.3370, 0.5557, 0.5116, 0.1108]) tensor(1.5151)\n",
      "[9400, 9600] loss:  tensor([0.3436, 0.5576, 0.5059, 0.1112]) tensor(1.5183)\n",
      "[9600, 9800] loss:  tensor([0.3448, 0.5553, 0.5117, 0.1138]) tensor(1.5255)\n",
      "[9800, 10000] loss:  tensor([0.3431, 0.5575, 0.5116, 0.1137]) tensor(1.5260)\n",
      "[10000, 10200] loss:  tensor([0.3477, 0.5602, 0.5023, 0.1120]) tensor(1.5222)\n",
      "[10200, 10400] loss:  tensor([0.3414, 0.5562, 0.5061, 0.1122]) tensor(1.5159)\n",
      "[10400, 10600] loss:  tensor([0.3431, 0.5505, 0.5083, 0.1120]) tensor(1.5139)\n",
      "[10600, 10800] loss:  tensor([0.3396, 0.5589, 0.5078, 0.1122]) tensor(1.5186)\n",
      "[10800, 11000] loss:  tensor([0.3390, 0.5584, 0.5093, 0.1124]) tensor(1.5191)\n",
      "[11000, 11200] loss:  tensor([0.3368, 0.5528, 0.5091, 0.1125]) tensor(1.5113)\n",
      "[11200, 11400] loss:  tensor([0.3520, 0.5514, 0.5118, 0.1124]) tensor(1.5276)\n",
      "[11400, 11600] loss:  tensor([0.3444, 0.5579, 0.5058, 0.1112]) tensor(1.5194)\n",
      "[11600, 11800] loss:  tensor([0.3449, 0.5585, 0.5110, 0.1122]) tensor(1.5266)\n",
      "[11800, 12000] loss:  tensor([0.3398, 0.5560, 0.5039, 0.1129]) tensor(1.5126)\n",
      "[12000, 12200] loss:  tensor([0.3476, 0.5641, 0.5062, 0.1133]) tensor(1.5312)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22acc8b64a5045d9bfbf876b3717159b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 9: tensor([0.3406, 0.5570, 0.5057, 0.1132]) 1.5164625779096719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac736a62c45467da7573c83de86f21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3373, 0.5529, 0.5091, 0.1134]) tensor(1.5127)\n",
      "[200, 400] loss:  tensor([0.3427, 0.5564, 0.5048, 0.1126]) tensor(1.5166)\n",
      "[400, 600] loss:  tensor([0.3413, 0.5555, 0.5014, 0.1129]) tensor(1.5111)\n",
      "[600, 800] loss:  tensor([0.3355, 0.5551, 0.5050, 0.1119]) tensor(1.5075)\n",
      "[800, 1000] loss:  tensor([0.3376, 0.5585, 0.5009, 0.1123]) tensor(1.5092)\n",
      "[1000, 1200] loss:  tensor([0.3355, 0.5566, 0.5075, 0.1118]) tensor(1.5114)\n",
      "[1200, 1400] loss:  tensor([0.3433, 0.5553, 0.5108, 0.1135]) tensor(1.5230)\n",
      "[1400, 1600] loss:  tensor([0.3436, 0.5589, 0.5107, 0.1124]) tensor(1.5255)\n",
      "[1600, 1800] loss:  tensor([0.3405, 0.5548, 0.5068, 0.1123]) tensor(1.5144)\n",
      "[1800, 2000] loss:  tensor([0.3429, 0.5548, 0.5086, 0.1129]) tensor(1.5191)\n",
      "[2000, 2200] loss:  tensor([0.3471, 0.5538, 0.5061, 0.1127]) tensor(1.5197)\n",
      "[2200, 2400] loss:  tensor([0.3348, 0.5500, 0.5080, 0.1104]) tensor(1.5033)\n",
      "[2400, 2600] loss:  tensor([0.3474, 0.5537, 0.4978, 0.1125]) tensor(1.5114)\n",
      "[2600, 2800] loss:  tensor([0.3420, 0.5548, 0.5033, 0.1128]) tensor(1.5129)\n",
      "[2800, 3000] loss:  tensor([0.3411, 0.5553, 0.4961, 0.1124]) tensor(1.5049)\n",
      "[3000, 3200] loss:  tensor([0.3436, 0.5516, 0.5055, 0.1136]) tensor(1.5143)\n",
      "[3200, 3400] loss:  tensor([0.3422, 0.5556, 0.5062, 0.1117]) tensor(1.5157)\n",
      "[3400, 3600] loss:  tensor([0.3361, 0.5514, 0.5083, 0.1113]) tensor(1.5070)\n",
      "[3600, 3800] loss:  tensor([0.3366, 0.5537, 0.5015, 0.1123]) tensor(1.5041)\n",
      "[3800, 4000] loss:  tensor([0.3378, 0.5544, 0.5100, 0.1134]) tensor(1.5155)\n",
      "[4000, 4200] loss:  tensor([0.3425, 0.5495, 0.5059, 0.1125]) tensor(1.5104)\n",
      "[4200, 4400] loss:  tensor([0.3484, 0.5521, 0.5066, 0.1121]) tensor(1.5193)\n",
      "[4400, 4600] loss:  tensor([0.3426, 0.5585, 0.5065, 0.1113]) tensor(1.5189)\n",
      "[4600, 4800] loss:  tensor([0.3356, 0.5512, 0.5062, 0.1095]) tensor(1.5026)\n",
      "[4800, 5000] loss:  tensor([0.3413, 0.5528, 0.5039, 0.1129]) tensor(1.5110)\n",
      "[5000, 5200] loss:  tensor([0.3362, 0.5502, 0.5090, 0.1125]) tensor(1.5080)\n",
      "[5200, 5400] loss:  tensor([0.3398, 0.5510, 0.5035, 0.1113]) tensor(1.5056)\n",
      "[5400, 5600] loss:  tensor([0.3428, 0.5531, 0.5060, 0.1115]) tensor(1.5134)\n",
      "[5600, 5800] loss:  tensor([0.3397, 0.5541, 0.5031, 0.1129]) tensor(1.5099)\n",
      "[5800, 6000] loss:  tensor([0.3470, 0.5612, 0.5058, 0.1140]) tensor(1.5279)\n",
      "[6000, 6200] loss:  tensor([0.3344, 0.5528, 0.5125, 0.1139]) tensor(1.5135)\n",
      "[6200, 6400] loss:  tensor([0.3338, 0.5531, 0.5042, 0.1118]) tensor(1.5029)\n",
      "[6400, 6600] loss:  tensor([0.3446, 0.5535, 0.5082, 0.1114]) tensor(1.5178)\n",
      "[6600, 6800] loss:  tensor([0.3424, 0.5580, 0.5079, 0.1145]) tensor(1.5228)\n",
      "[6800, 7000] loss:  tensor([0.3417, 0.5562, 0.5021, 0.1138]) tensor(1.5138)\n",
      "[7000, 7200] loss:  tensor([0.3440, 0.5423, 0.5117, 0.1119]) tensor(1.5098)\n",
      "[7200, 7400] loss:  tensor([0.3418, 0.5551, 0.5079, 0.1133]) tensor(1.5181)\n",
      "[7400, 7600] loss:  tensor([0.3450, 0.5566, 0.5083, 0.1121]) tensor(1.5219)\n",
      "[7600, 7800] loss:  tensor([0.3490, 0.5546, 0.5085, 0.1123]) tensor(1.5244)\n",
      "[7800, 8000] loss:  tensor([0.3447, 0.5507, 0.5037, 0.1115]) tensor(1.5106)\n",
      "[8000, 8200] loss:  tensor([0.3394, 0.5570, 0.5061, 0.1131]) tensor(1.5156)\n",
      "[8200, 8400] loss:  tensor([0.3466, 0.5596, 0.4997, 0.1113]) tensor(1.5172)\n",
      "[8400, 8600] loss:  tensor([0.3389, 0.5550, 0.5068, 0.1114]) tensor(1.5121)\n",
      "[8600, 8800] loss:  tensor([0.3378, 0.5489, 0.5083, 0.1129]) tensor(1.5080)\n",
      "[8800, 9000] loss:  tensor([0.3407, 0.5576, 0.5080, 0.1109]) tensor(1.5172)\n",
      "[9000, 9200] loss:  tensor([0.3396, 0.5563, 0.5114, 0.1116]) tensor(1.5187)\n",
      "[9200, 9400] loss:  tensor([0.3367, 0.5532, 0.5037, 0.1120]) tensor(1.5055)\n",
      "[9400, 9600] loss:  tensor([0.3504, 0.5587, 0.5047, 0.1142]) tensor(1.5280)\n",
      "[9600, 9800] loss:  tensor([0.3424, 0.5584, 0.5058, 0.1125]) tensor(1.5190)\n",
      "[9800, 10000] loss:  tensor([0.3378, 0.5561, 0.5097, 0.1115]) tensor(1.5152)\n",
      "[10000, 10200] loss:  tensor([0.3410, 0.5549, 0.5052, 0.1134]) tensor(1.5145)\n",
      "[10200, 10400] loss:  tensor([0.3468, 0.5530, 0.5037, 0.1120]) tensor(1.5156)\n",
      "[10400, 10600] loss:  tensor([0.3377, 0.5553, 0.5036, 0.1126]) tensor(1.5092)\n",
      "[10600, 10800] loss:  tensor([0.3487, 0.5530, 0.4993, 0.1121]) tensor(1.5131)\n",
      "[10800, 11000] loss:  tensor([0.3408, 0.5531, 0.5073, 0.1111]) tensor(1.5123)\n",
      "[11000, 11200] loss:  tensor([0.3374, 0.5548, 0.5072, 0.1119]) tensor(1.5113)\n",
      "[11200, 11400] loss:  tensor([0.3418, 0.5590, 0.5038, 0.1134]) tensor(1.5179)\n",
      "[11400, 11600] loss:  tensor([0.3469, 0.5587, 0.5002, 0.1127]) tensor(1.5186)\n",
      "[11600, 11800] loss:  tensor([0.3418, 0.5528, 0.5112, 0.1134]) tensor(1.5192)\n",
      "[11800, 12000] loss:  tensor([0.3401, 0.5471, 0.5087, 0.1125]) tensor(1.5083)\n",
      "[12000, 12200] loss:  tensor([0.3439, 0.5550, 0.4991, 0.1117]) tensor(1.5096)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eeea1b7166b464db06163b23e463ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 10: tensor([0.3420, 0.5483, 0.5015, 0.1125]) 1.5042420886447632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e35fc27e34407790cf145b05ef4117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3349, 0.5512, 0.5068, 0.1116]) tensor(1.5044)\n",
      "[200, 400] loss:  tensor([0.3409, 0.5545, 0.5052, 0.1137]) tensor(1.5143)\n",
      "[400, 600] loss:  tensor([0.3396, 0.5493, 0.5035, 0.1100]) tensor(1.5024)\n",
      "[600, 800] loss:  tensor([0.3408, 0.5524, 0.5068, 0.1121]) tensor(1.5122)\n",
      "[800, 1000] loss:  tensor([0.3352, 0.5489, 0.5001, 0.1119]) tensor(1.4960)\n",
      "[1000, 1200] loss:  tensor([0.3386, 0.5520, 0.5041, 0.1127]) tensor(1.5074)\n",
      "[1200, 1400] loss:  tensor([0.3403, 0.5540, 0.5062, 0.1132]) tensor(1.5136)\n",
      "[1400, 1600] loss:  tensor([0.3451, 0.5556, 0.5070, 0.1126]) tensor(1.5203)\n",
      "[1600, 1800] loss:  tensor([0.3408, 0.5475, 0.5059, 0.1121]) tensor(1.5062)\n",
      "[1800, 2000] loss:  tensor([0.3455, 0.5515, 0.5057, 0.1109]) tensor(1.5136)\n",
      "[2000, 2200] loss:  tensor([0.3416, 0.5502, 0.5059, 0.1118]) tensor(1.5095)\n",
      "[2200, 2400] loss:  tensor([0.3401, 0.5524, 0.5047, 0.1128]) tensor(1.5100)\n",
      "[2400, 2600] loss:  tensor([0.3427, 0.5527, 0.5084, 0.1133]) tensor(1.5172)\n",
      "[2600, 2800] loss:  tensor([0.3416, 0.5545, 0.5027, 0.1136]) tensor(1.5124)\n",
      "[2800, 3000] loss:  tensor([0.3390, 0.5538, 0.5005, 0.1112]) tensor(1.5045)\n",
      "[3000, 3200] loss:  tensor([0.3416, 0.5533, 0.5008, 0.1125]) tensor(1.5083)\n",
      "[3200, 3400] loss:  tensor([0.3421, 0.5500, 0.5087, 0.1106]) tensor(1.5114)\n",
      "[3400, 3600] loss:  tensor([0.3321, 0.5534, 0.5023, 0.1139]) tensor(1.5017)\n",
      "[3600, 3800] loss:  tensor([0.3399, 0.5512, 0.5072, 0.1109]) tensor(1.5092)\n",
      "[3800, 4000] loss:  tensor([0.3368, 0.5550, 0.4994, 0.1131]) tensor(1.5043)\n",
      "[4000, 4200] loss:  tensor([0.3404, 0.5448, 0.5055, 0.1129]) tensor(1.5036)\n",
      "[4200, 4400] loss:  tensor([0.3501, 0.5517, 0.5043, 0.1110]) tensor(1.5173)\n",
      "[4400, 4600] loss:  tensor([0.3349, 0.5566, 0.4992, 0.1119]) tensor(1.5026)\n",
      "[4600, 4800] loss:  tensor([0.3422, 0.5491, 0.5060, 0.1119]) tensor(1.5092)\n",
      "[4800, 5000] loss:  tensor([0.3400, 0.5541, 0.5068, 0.1123]) tensor(1.5132)\n",
      "[5000, 5200] loss:  tensor([0.3359, 0.5546, 0.4985, 0.1109]) tensor(1.4999)\n",
      "[5200, 5400] loss:  tensor([0.3391, 0.5506, 0.4998, 0.1129]) tensor(1.5024)\n",
      "[5400, 5600] loss:  tensor([0.3404, 0.5508, 0.5083, 0.1133]) tensor(1.5128)\n",
      "[5600, 5800] loss:  tensor([0.3437, 0.5541, 0.5031, 0.1111]) tensor(1.5120)\n",
      "[5800, 6000] loss:  tensor([0.3430, 0.5526, 0.5002, 0.1118]) tensor(1.5076)\n",
      "[6000, 6200] loss:  tensor([0.3419, 0.5511, 0.4977, 0.1122]) tensor(1.5029)\n",
      "[6200, 6400] loss:  tensor([0.3415, 0.5520, 0.5024, 0.1118]) tensor(1.5077)\n",
      "[6400, 6600] loss:  tensor([0.3402, 0.5439, 0.5032, 0.1118]) tensor(1.4991)\n",
      "[6600, 6800] loss:  tensor([0.3382, 0.5503, 0.4998, 0.1123]) tensor(1.5005)\n",
      "[6800, 7000] loss:  tensor([0.3368, 0.5547, 0.5013, 0.1122]) tensor(1.5050)\n",
      "[7000, 7200] loss:  tensor([0.3408, 0.5541, 0.4982, 0.1104]) tensor(1.5035)\n",
      "[7200, 7400] loss:  tensor([0.3399, 0.5576, 0.5046, 0.1131]) tensor(1.5152)\n",
      "[7400, 7600] loss:  tensor([0.3443, 0.5568, 0.5014, 0.1128]) tensor(1.5154)\n",
      "[7600, 7800] loss:  tensor([0.3427, 0.5508, 0.5030, 0.1116]) tensor(1.5081)\n",
      "[7800, 8000] loss:  tensor([0.3405, 0.5540, 0.5066, 0.1136]) tensor(1.5147)\n",
      "[8000, 8200] loss:  tensor([0.3347, 0.5530, 0.5043, 0.1117]) tensor(1.5037)\n",
      "[8200, 8400] loss:  tensor([0.3359, 0.5512, 0.4987, 0.1112]) tensor(1.4970)\n",
      "[8400, 8600] loss:  tensor([0.3410, 0.5535, 0.5111, 0.1128]) tensor(1.5184)\n",
      "[8600, 8800] loss:  tensor([0.3382, 0.5504, 0.5066, 0.1096]) tensor(1.5049)\n",
      "[8800, 9000] loss:  tensor([0.3472, 0.5536, 0.5099, 0.1123]) tensor(1.5230)\n",
      "[9000, 9200] loss:  tensor([0.3422, 0.5470, 0.5052, 0.1130]) tensor(1.5074)\n",
      "[9200, 9400] loss:  tensor([0.3412, 0.5544, 0.5046, 0.1137]) tensor(1.5139)\n",
      "[9400, 9600] loss:  tensor([0.3384, 0.5533, 0.5048, 0.1106]) tensor(1.5071)\n",
      "[9600, 9800] loss:  tensor([0.3452, 0.5521, 0.5007, 0.1104]) tensor(1.5084)\n",
      "[9800, 10000] loss:  tensor([0.3389, 0.5530, 0.5037, 0.1131]) tensor(1.5087)\n",
      "[10000, 10200] loss:  tensor([0.3425, 0.5563, 0.5031, 0.1122]) tensor(1.5141)\n",
      "[10200, 10400] loss:  tensor([0.3394, 0.5479, 0.5049, 0.1120]) tensor(1.5043)\n",
      "[10400, 10600] loss:  tensor([0.3436, 0.5481, 0.5031, 0.1144]) tensor(1.5092)\n",
      "[10600, 10800] loss:  tensor([0.3341, 0.5501, 0.5084, 0.1109]) tensor(1.5035)\n",
      "[10800, 11000] loss:  tensor([0.3351, 0.5565, 0.5020, 0.1117]) tensor(1.5053)\n",
      "[11000, 11200] loss:  tensor([0.3401, 0.5506, 0.5057, 0.1104]) tensor(1.5069)\n",
      "[11200, 11400] loss:  tensor([0.3414, 0.5506, 0.5036, 0.1117]) tensor(1.5074)\n",
      "[11400, 11600] loss:  tensor([0.3407, 0.5519, 0.5064, 0.1111]) tensor(1.5101)\n",
      "[11600, 11800] loss:  tensor([0.3353, 0.5491, 0.5057, 0.1101]) tensor(1.5002)\n",
      "[11800, 12000] loss:  tensor([0.3429, 0.5473, 0.5083, 0.1131]) tensor(1.5115)\n",
      "[12000, 12200] loss:  tensor([0.3407, 0.5551, 0.5024, 0.1122]) tensor(1.5103)\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2b617fe2734e5c94f6b7e5ee21aab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss for epoch 11: tensor([0.3486, 0.5551, 0.5076, 0.1156]) 1.5269081996993235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d2336dbc5e430189da8732c0b9638b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 200] loss:  tensor([0.3336, 0.5526, 0.5030, 0.1112]) tensor(1.5004)\n",
      "[200, 400] loss:  tensor([0.3440, 0.5522, 0.4977, 0.1113]) tensor(1.5052)\n",
      "[400, 600] loss:  tensor([0.3454, 0.5556, 0.4965, 0.1113]) tensor(1.5088)\n",
      "[600, 800] loss:  tensor([0.3363, 0.5506, 0.5017, 0.1121]) tensor(1.5006)\n",
      "[800, 1000] loss:  tensor([0.3387, 0.5501, 0.4984, 0.1122]) tensor(1.4993)\n",
      "[1000, 1200] loss:  tensor([0.3416, 0.5506, 0.5075, 0.1118]) tensor(1.5115)\n",
      "[1200, 1400] loss:  tensor([0.3360, 0.5488, 0.5056, 0.1109]) tensor(1.5014)\n",
      "[1400, 1600] loss:  tensor([0.3367, 0.5548, 0.4989, 0.1109]) tensor(1.5013)\n",
      "[1600, 1800] loss:  tensor([0.3416, 0.5500, 0.5018, 0.1124]) tensor(1.5058)\n",
      "[1800, 2000] loss:  tensor([0.3416, 0.5486, 0.5017, 0.1120]) tensor(1.5040)\n",
      "[2000, 2200] loss:  tensor([0.3388, 0.5486, 0.5058, 0.1128]) tensor(1.5061)\n",
      "[2200, 2400] loss:  tensor([0.3376, 0.5537, 0.5034, 0.1109]) tensor(1.5057)\n",
      "[2400, 2600] loss:  tensor([0.3377, 0.5512, 0.5017, 0.1116]) tensor(1.5022)\n",
      "[2600, 2800] loss:  tensor([0.3360, 0.5521, 0.5032, 0.1104]) tensor(1.5018)\n",
      "[2800, 3000] loss:  tensor([0.3394, 0.5509, 0.4996, 0.1120]) tensor(1.5019)\n",
      "[3000, 3200] loss:  tensor([0.3385, 0.5528, 0.4992, 0.1118]) tensor(1.5023)\n",
      "[3200, 3400] loss:  tensor([0.3461, 0.5548, 0.5012, 0.1113]) tensor(1.5134)\n",
      "[3400, 3600] loss:  tensor([0.3390, 0.5518, 0.5075, 0.1116]) tensor(1.5099)\n",
      "[3600, 3800] loss:  tensor([0.3412, 0.5463, 0.5016, 0.1113]) tensor(1.5004)\n",
      "[3800, 4000] loss:  tensor([0.3341, 0.5506, 0.5071, 0.1137]) tensor(1.5056)\n",
      "[4000, 4200] loss:  tensor([0.3415, 0.5551, 0.5038, 0.1121]) tensor(1.5125)\n",
      "[4200, 4400] loss:  tensor([0.3421, 0.5539, 0.5008, 0.1118]) tensor(1.5087)\n",
      "[4400, 4600] loss:  tensor([0.3371, 0.5546, 0.5037, 0.1102]) tensor(1.5055)\n",
      "[4600, 4800] loss:  tensor([0.3384, 0.5459, 0.5036, 0.1111]) tensor(1.4991)\n",
      "[4800, 5000] loss:  tensor([0.3381, 0.5513, 0.5043, 0.1121]) tensor(1.5058)\n",
      "[5000, 5200] loss:  tensor([0.3378, 0.5511, 0.5078, 0.1116]) tensor(1.5083)\n",
      "[5200, 5400] loss:  tensor([0.3339, 0.5487, 0.5005, 0.1116]) tensor(1.4948)\n",
      "[5400, 5600] loss:  tensor([0.3401, 0.5511, 0.5030, 0.1116]) tensor(1.5057)\n",
      "[5600, 5800] loss:  tensor([0.3465, 0.5507, 0.5023, 0.1122]) tensor(1.5118)\n",
      "[5800, 6000] loss:  tensor([0.3390, 0.5503, 0.5044, 0.1120]) tensor(1.5057)\n",
      "[6000, 6200] loss:  tensor([0.3352, 0.5494, 0.5041, 0.1110]) tensor(1.4996)\n",
      "[6200, 6400] loss:  tensor([0.3385, 0.5576, 0.5031, 0.1121]) tensor(1.5113)\n",
      "[6400, 6600] loss:  tensor([0.3358, 0.5449, 0.5016, 0.1110]) tensor(1.4933)\n",
      "[6600, 6800] loss:  tensor([0.3428, 0.5470, 0.5007, 0.1115]) tensor(1.5020)\n",
      "[6800, 7000] loss:  tensor([0.3387, 0.5518, 0.4981, 0.1106]) tensor(1.4993)\n",
      "[7000, 7200] loss:  tensor([0.3356, 0.5519, 0.5044, 0.1128]) tensor(1.5047)\n",
      "[7200, 7400] loss:  tensor([0.3386, 0.5486, 0.5030, 0.1122]) tensor(1.5024)\n",
      "[7400, 7600] loss:  tensor([0.3384, 0.5494, 0.5052, 0.1121]) tensor(1.5050)\n",
      "[7600, 7800] loss:  tensor([0.3423, 0.5513, 0.5029, 0.1109]) tensor(1.5074)\n",
      "[7800, 8000] loss:  tensor([0.3300, 0.5534, 0.5026, 0.1113]) tensor(1.4973)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fe199c553fb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mT_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mT_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0ml1_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mT_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruoshi/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruoshi/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruoshi/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruoshi/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruoshi/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0m_start_new_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_active_limbo_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-573:\n",
      "Process Process-559:\n",
      "Process Process-555:\n",
      "Process Process-576:\n",
      "Process Process-575:\n",
      "Process Process-564:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "Process Process-570:\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "Process Process-565:\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/rliu/ruoshi/anaconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "train_set = objaverse_sfm(dataset_root, 4, train=True, transform = ToTensor())\n",
    "train_dataloader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=32, drop_last=False)\n",
    "\n",
    "test_set = objaverse_sfm(dataset_root, 4, train=False, transform = ToTensor())\n",
    "test_dataloader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=16, drop_last=False)\n",
    "\n",
    "model = sfm(resnet=True).to(device)\n",
    "model.cnn.layer1.requires_grad_(False)\n",
    "model.cnn.layer2.requires_grad_(False)\n",
    "model.cnn.layer3.requires_grad_(False)\n",
    "\n",
    "print('\\n================== total trainable parameters: %d ==================\\n' % sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)\n",
    "\n",
    "model = torch.nn.DataParallel(model, device_ids=[6, 7])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.3)\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    print('validation')\n",
    "    model.eval()\n",
    "    test_loss = torch.zeros(4).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(test_dataloader, 0), total=len(test_dataloader)):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            image_target, image_cond, T_gt = \\\n",
    "                batch['image_target'].to(device), batch['image_cond'].to(device), batch['T'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            T_pred = model(image_cond, image_target)\n",
    "            loss = (T_pred - T_gt).abs()\n",
    "            test_loss += loss.sum(dim=0)\n",
    "    \n",
    "    print('validation loss for epoch %d:' % epoch, test_loss.cpu() / len(test_set), test_loss.cpu().sum().item() / len(test_set))\n",
    "    \n",
    "    running_loss = torch.zeros(4).to(device)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(train_dataloader, 0), total=len(train_dataloader)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        image_target, image_cond, T_gt = \\\n",
    "            batch['image_target'].to(device), batch['image_cond'].to(device), batch['T'].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        T_pred = model(image_cond, image_target)\n",
    "        loss = ((T_pred - T_gt)**2).mean(dim=0)\n",
    "        l1_loss = ((T_pred - T_gt).abs()).mean(dim=0)\n",
    "        running_loss += l1_loss.detach()\n",
    "        loss = loss.sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'[{i-199}, {i+1:d}] loss: ', running_loss.detach().cpu() / 200, \\\n",
    "                  running_loss.detach().cpu().sum() / 200)\n",
    "            running_loss = torch.zeros(4).to(device)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ae96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c7f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40efcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glowcurve",
   "language": "python",
   "name": "glowcurve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
